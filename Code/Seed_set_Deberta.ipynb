{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fd53271ea82463ba3e1945d453aef4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_617a74191b2a461cb8eb989b166d4848",
              "IPY_MODEL_0b1e6280ed394e3386b45f4bcddb2656",
              "IPY_MODEL_236181175b6e46d6b5287ab3385ce4bc"
            ],
            "layout": "IPY_MODEL_c0e9b08840c9408889193284ea030136"
          }
        },
        "617a74191b2a461cb8eb989b166d4848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e808084836483fb1655e57dbac7f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea76f6fb7a64a8ba59b754dbe662222",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0b1e6280ed394e3386b45f4bcddb2656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efb657a44a04ee486d9d5d6ba5e528d",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1296fd6a5828465e9118100b84384b9a",
            "value": 52
          }
        },
        "236181175b6e46d6b5287ab3385ce4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d802d4e9ef349beabdefd2a8f324bde",
            "placeholder": "​",
            "style": "IPY_MODEL_258fdf4e7ae24a1a8bd557f9db4ba1c9",
            "value": " 52.0/52.0 [00:00&lt;00:00, 6.08kB/s]"
          }
        },
        "c0e9b08840c9408889193284ea030136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e808084836483fb1655e57dbac7f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea76f6fb7a64a8ba59b754dbe662222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6efb657a44a04ee486d9d5d6ba5e528d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1296fd6a5828465e9118100b84384b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d802d4e9ef349beabdefd2a8f324bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258fdf4e7ae24a1a8bd557f9db4ba1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d1d83be8e604f999a8517296b24d2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5a37183a9fe4b9aac9de330ff7c1673",
              "IPY_MODEL_b22b36245b0c47d3b34e404b84cf3130",
              "IPY_MODEL_c1d2bd23e9754407b74564ddf849493c"
            ],
            "layout": "IPY_MODEL_7f1013b13d9c4842875f143221235883"
          }
        },
        "d5a37183a9fe4b9aac9de330ff7c1673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7950f7e576224aa48039e8dbfbb4061a",
            "placeholder": "​",
            "style": "IPY_MODEL_b1148e22f1fe496fb8c56576673169ac",
            "value": "config.json: 100%"
          }
        },
        "b22b36245b0c47d3b34e404b84cf3130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f39847b954d4b3da9a320f0dd938c91",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89a9110a145b47ed80c8289d5bbad8b7",
            "value": 578
          }
        },
        "c1d2bd23e9754407b74564ddf849493c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2501998801a4e179c05b7a57d7f639b",
            "placeholder": "​",
            "style": "IPY_MODEL_1465cac851a549f095130ee491bc7e1a",
            "value": " 578/578 [00:00&lt;00:00, 69.6kB/s]"
          }
        },
        "7f1013b13d9c4842875f143221235883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7950f7e576224aa48039e8dbfbb4061a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1148e22f1fe496fb8c56576673169ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f39847b954d4b3da9a320f0dd938c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a9110a145b47ed80c8289d5bbad8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2501998801a4e179c05b7a57d7f639b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1465cac851a549f095130ee491bc7e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58f5b2293b6942c2a0b603e3073cfd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b396d072e6a437c9109c9c51aadd8f3",
              "IPY_MODEL_6073b26794ca4a1489961afb1bc1dd51",
              "IPY_MODEL_75f34a1956d74ed083a829b38d5eb3bb"
            ],
            "layout": "IPY_MODEL_2dbd35e27e7b4b8797c4087f75ea938a"
          }
        },
        "2b396d072e6a437c9109c9c51aadd8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32fea476cba400a8bf201706d417eed",
            "placeholder": "​",
            "style": "IPY_MODEL_50f341a5565c4da5af29bd618ecd3030",
            "value": "spm.model: 100%"
          }
        },
        "6073b26794ca4a1489961afb1bc1dd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e0c0e1597c4fa8aade0e6ef84e3d44",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec8b2d6cfdda4130b1cdca468ef5c784",
            "value": 2464616
          }
        },
        "75f34a1956d74ed083a829b38d5eb3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6128ce6aba42fe89587362ab7652ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1c89e316594b87a8caa049f4ea11bb",
            "value": " 2.46M/2.46M [00:01&lt;00:00, 62.3kB/s]"
          }
        },
        "2dbd35e27e7b4b8797c4087f75ea938a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32fea476cba400a8bf201706d417eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f341a5565c4da5af29bd618ecd3030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e0c0e1597c4fa8aade0e6ef84e3d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8b2d6cfdda4130b1cdca468ef5c784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e6128ce6aba42fe89587362ab7652ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1c89e316594b87a8caa049f4ea11bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d34177b5d6ec4abc9b274ef11ba31679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_983085a2c22d4c3b8e191deddc404ded",
              "IPY_MODEL_0785484a30a7460aa4d319071db40c18",
              "IPY_MODEL_56b11fd236c84bcdbc3e103d305584f0"
            ],
            "layout": "IPY_MODEL_8228f24f6fc94084a96318088b265dfa"
          }
        },
        "983085a2c22d4c3b8e191deddc404ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca626e4172564d8395767a1be6f6ebd3",
            "placeholder": "​",
            "style": "IPY_MODEL_97e60efb4e504036a2694a07ce7148f6",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0785484a30a7460aa4d319071db40c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fa7397cb5f49f5846a7e477a3b769d",
            "max": 286059269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d702bd743454541bf230494abe6724e",
            "value": 286059269
          }
        },
        "56b11fd236c84bcdbc3e103d305584f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed446d86e534e228ea50ca955a8ef9c",
            "placeholder": "​",
            "style": "IPY_MODEL_3f26a2168b584deea2c52eac78fa18c4",
            "value": " 286M/286M [00:01&lt;00:00, 141MB/s]"
          }
        },
        "8228f24f6fc94084a96318088b265dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca626e4172564d8395767a1be6f6ebd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e60efb4e504036a2694a07ce7148f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02fa7397cb5f49f5846a7e477a3b769d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d702bd743454541bf230494abe6724e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aed446d86e534e228ea50ca955a8ef9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f26a2168b584deea2c52eac78fa18c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0326aa31c7d4ec4bdf33e49a182fd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_266089a9e500413491cde210bd994e53",
              "IPY_MODEL_70910d62aa744d90b25eed7a593affbf",
              "IPY_MODEL_19ef64eb42f3498d8c3ddf48c7763f32"
            ],
            "layout": "IPY_MODEL_515bee1818e04a78977a4aa893d5a388"
          }
        },
        "266089a9e500413491cde210bd994e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a11da735619f4dd19fed1d585b7e79af",
            "placeholder": "​",
            "style": "IPY_MODEL_12b3ffd8a33a4c9b949e9d0b1fc6ca6d",
            "value": "model.safetensors: 100%"
          }
        },
        "70910d62aa744d90b25eed7a593affbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55dd62e504fc4c51b35bb8d050d9fe6d",
            "max": 286034994,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d4fbd858d9c46e38293f6ca04565a0f",
            "value": 286034994
          }
        },
        "19ef64eb42f3498d8c3ddf48c7763f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe575068cb94cb186cf111ebef1b352",
            "placeholder": "​",
            "style": "IPY_MODEL_37637b8c818341ef9356d91669630a6b",
            "value": " 286M/286M [00:01&lt;00:00, 201MB/s]"
          }
        },
        "515bee1818e04a78977a4aa893d5a388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11da735619f4dd19fed1d585b7e79af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b3ffd8a33a4c9b949e9d0b1fc6ca6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55dd62e504fc4c51b35bb8d050d9fe6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4fbd858d9c46e38293f6ca04565a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fe575068cb94cb186cf111ebef1b352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37637b8c818341ef9356d91669630a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##DEBERTA"
      ],
      "metadata": {
        "id": "eFiqw1KEHnDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U accelerate transformers\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMN4UhuN7krL",
        "outputId": "18b88a85-fc6a-482d-edcb-4c47cfee24f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "Successfully installed accelerate-1.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "\n",
        "print(\" Upload FRAUD MD&A files:\")\n",
        "fraud_files = files.upload()\n",
        "\n",
        "print(\" Upload NON-FRAUD MD&A files:\")\n",
        "nonfraud_files = files.upload()\n",
        "\n",
        "\n",
        "mdna_samples = []\n",
        "\n",
        "\n",
        "for fname in fraud_files:\n",
        "    with open(fname, 'r', encoding='utf-8') as f:\n",
        "        mdna_samples.append({\"text\": f.read(), \"true_label\": \"Fraud\"})\n",
        "\n",
        "\n",
        "for fname in nonfraud_files:\n",
        "    with open(fname, 'r', encoding='utf-8') as f:\n",
        "        mdna_samples.append({\"text\": f.read(), \"true_label\": \"Non-Fraud\"})\n",
        "\n",
        "print(f\" Loaded {len(mdna_samples)} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0_4kq7er7pln",
        "outputId": "d044d3ee-e0ad-4e8e-9971-9ac532a4e92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Upload FRAUD MD&A files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da5a56c4-49ee-4803-9ded-84d2795ffc98\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da5a56c4-49ee-4803-9ded-84d2795ffc98\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2135_2004.txt to 2135_2004.txt\n",
            "Saving 2135_2005.txt to 2135_2005.txt\n",
            "Saving 2135_2009.txt to 2135_2009.txt\n",
            "Saving 3449_1995.txt to 3449_1995.txt\n",
            "Saving 5272_2000.txt to 5272_2000.txt\n",
            "Saving 5272_2001.txt to 5272_2001.txt\n",
            "Saving 5272_2002.txt to 5272_2002.txt\n",
            "Saving 5272_2003.txt to 5272_2003.txt\n",
            "Saving 23082_2009.txt to 23082_2009.txt\n",
            "Saving 23082_2010.txt to 23082_2010.txt\n",
            "Saving 23082_2011.txt to 23082_2011.txt\n",
            "Saving 23217_2005.txt to 23217_2005.txt\n",
            "Saving 26780_2004.txt to 26780_2004.txt\n",
            "Saving 49196_2001.txt to 49196_2001.txt\n",
            "Saving 51644_2002.txt to 51644_2002.txt\n",
            "Saving 51644_2003.txt to 51644_2003.txt\n",
            "Saving 70318_2004.txt to 70318_2004.txt\n",
            "Saving 72911_2000.txt to 72911_2000.txt\n",
            "Saving 72911_2001.txt to 72911_2001.txt\n",
            "Saving 72911_2002.txt to 72911_2002.txt\n",
            "Saving 73088_2001.txt to 73088_2001.txt\n",
            "Saving 75208_2003.txt to 75208_2003.txt\n",
            "Saving 75208_2005.txt to 75208_2005.txt\n",
            "Saving 75208_2006.txt to 75208_2006.txt\n",
            "Saving 75208_2009.txt to 75208_2009.txt\n",
            "Saving 75208_2010.txt to 75208_2010.txt\n",
            "Saving 75208_2011.txt to 75208_2011.txt\n",
            "Saving 97216_2002.txt to 97216_2002.txt\n",
            "Saving 97216_2003.txt to 97216_2003.txt\n",
            "Saving 99771_2010.txt to 99771_2010.txt\n",
            "Saving 99771_2011.txt to 99771_2011.txt\n",
            "Saving 103872_2007.txt to 103872_2007.txt\n",
            "Saving 216228_2002.txt to 216228_2002.txt\n",
            "Saving 216228_2003.txt to 216228_2003.txt\n",
            "Saving 216228_2004.txt to 216228_2004.txt\n",
            "Saving 278352_2002.txt to 278352_2002.txt\n",
            "Saving 310522_2002.txt to 310522_2002.txt\n",
            "Saving 310522_2003.txt to 310522_2003.txt\n",
            "Saving 319815_2012.txt to 319815_2012.txt\n",
            "Saving 352495_1997.txt to 352495_1997.txt\n",
            "Saving 700564_2016.txt to 700564_2016.txt\n",
            "Saving 700564_2017.txt to 700564_2017.txt\n",
            "Saving 710507_2003.txt to 710507_2003.txt\n",
            "Saving 710507_2004.txt to 710507_2004.txt\n",
            "Saving 710507_2005.txt to 710507_2005.txt\n",
            "Saving 710507_2006.txt to 710507_2006.txt\n",
            "Saving 710507_2007.txt to 710507_2007.txt\n",
            "Saving 723527_1999.txt to 723527_1999.txt\n",
            "Saving 723527_2000.txt to 723527_2000.txt\n",
            "Saving 723527_2001.txt to 723527_2001.txt\n",
            "Saving 731766_2004.txt to 731766_2004.txt\n",
            "Saving 731766_2005.txt to 731766_2005.txt\n",
            "Saving 745308_2009.txt to 745308_2009.txt\n",
            "Saving 745308_2010.txt to 745308_2010.txt\n",
            "Saving 784932_1996.txt to 784932_1996.txt\n",
            "Saving 784932_1997.txt to 784932_1997.txt\n",
            "Saving 784932_1998.txt to 784932_1998.txt\n",
            "Saving 796486_1998.txt to 796486_1998.txt\n",
            "Saving 803014_2005.txt to 803014_2005.txt\n",
            "Saving 811671_2002.txt to 811671_2002.txt\n",
            "Saving 811671_2003.txt to 811671_2003.txt\n",
            "Saving 811671_2004.txt to 811671_2004.txt\n",
            "Saving 811671_2005.txt to 811671_2005.txt\n",
            "Saving 811671_2006.txt to 811671_2006.txt\n",
            "Saving 814585_2003.txt to 814585_2003.txt\n",
            "Saving 826154_2010.txt to 826154_2010.txt\n",
            "Saving 826154_2011.txt to 826154_2011.txt\n",
            "Saving 826773_2012.txt to 826773_2012.txt\n",
            "Saving 834408_2007.txt to 834408_2007.txt\n",
            "Saving 835012_2008.txt to 835012_2008.txt\n",
            "Saving 835012_2009.txt to 835012_2009.txt\n",
            "Saving 844161_2017.txt to 844161_2017.txt\n",
            "Saving 846815_2002.txt to 846815_2002.txt\n",
            "Saving 846815_2003.txt to 846815_2003.txt\n",
            "Saving 846909_2000.txt to 846909_2000.txt\n",
            "Saving 859475_2006.txt to 859475_2006.txt\n",
            "Saving 866535_2003.txt to 866535_2003.txt\n",
            "Saving 867058_2001.txt to 867058_2001.txt\n",
            "Saving 867058_2002.txt to 867058_2002.txt\n",
            "Saving 867058_2003.txt to 867058_2003.txt\n",
            "Saving 867058_2004.txt to 867058_2004.txt\n",
            "Saving 867058_2005.txt to 867058_2005.txt\n",
            "Saving 872821_2009.txt to 872821_2009.txt\n",
            "Saving 876889_1996.txt to 876889_1996.txt\n",
            "Saving 878522_2001.txt to 878522_2001.txt\n",
            "Saving 878522_2002.txt to 878522_2002.txt\n",
            "Saving 878522_2003.txt to 878522_2003.txt\n",
            "Saving 878522_2004.txt to 878522_2004.txt\n",
            "Saving 883902_2000.txt to 883902_2000.txt\n",
            "Saving 884624_2010.txt to 884624_2010.txt\n",
            "Saving 886035_2009.txt to 886035_2009.txt\n",
            "Saving 886035_2010.txt to 886035_2010.txt\n",
            "Saving 886035_2011.txt to 886035_2011.txt\n",
            "Saving 887919_2001.txt to 887919_2001.txt\n",
            "Saving 887919_2002.txt to 887919_2002.txt\n",
            "Saving 888919_2004.txt to 888919_2004.txt\n",
            "Saving 888919_2005.txt to 888919_2005.txt\n",
            "Saving 890923_2007.txt to 890923_2007.txt\n",
            "Saving 892535_2007.txt to 892535_2007.txt\n",
            "Saving 895421_2000.txt to 895421_2000.txt\n",
            "Saving 895421_2001.txt to 895421_2001.txt\n",
            "Saving 895421_2002.txt to 895421_2002.txt\n",
            "Saving 900091_1997.txt to 900091_1997.txt\n",
            "Saving 908255_2015.txt to 908255_2015.txt\n",
            "Saving 908255_2016.txt to 908255_2016.txt\n",
            "Saving 912603_2004.txt to 912603_2004.txt\n",
            "Saving 913144_2002.txt to 913144_2002.txt\n",
            "Saving 913144_2003.txt to 913144_2003.txt\n",
            "Saving 913760_2010.txt to 913760_2010.txt\n",
            "Saving 913760_2011.txt to 913760_2011.txt\n",
            "Saving 913760_2012.txt to 913760_2012.txt\n",
            "Saving 914712_2007.txt to 914712_2007.txt\n",
            "Saving 914712_2008.txt to 914712_2008.txt\n",
            "Saving 914712_2009.txt to 914712_2009.txt\n",
            "Saving 914712_2010.txt to 914712_2010.txt\n",
            "Saving 914712_2011.txt to 914712_2011.txt\n",
            "Saving 915840_2007.txt to 915840_2007.txt\n",
            "Saving 919742_2005.txt to 919742_2005.txt\n",
            "Saving 923282_2001.txt to 923282_2001.txt\n",
            "Saving 923796_2005.txt to 923796_2005.txt\n",
            "Saving 929994_2009.txt to 929994_2009.txt\n",
            "Saving 929994_2010.txt to 929994_2010.txt\n",
            "Saving 929994_2011.txt to 929994_2011.txt\n",
            "Saving 933974_2001.txt to 933974_2001.txt\n",
            "Saving 933974_2002.txt to 933974_2002.txt\n",
            "Saving 933974_2003.txt to 933974_2003.txt\n",
            "Saving 933974_2004.txt to 933974_2004.txt\n",
            "Saving 933974_2005.txt to 933974_2005.txt\n",
            "Saving 939930_2014.txt to 939930_2014.txt\n",
            "Saving 944765_2005.txt to 944765_2005.txt\n",
            "Saving 946581_2001.txt to 946581_2001.txt\n",
            "Saving 946581_2003.txt to 946581_2003.txt\n",
            "Saving 1002131_1999.txt to 1002131_1999.txt\n",
            "Saving 1004945_2002.txt to 1004945_2002.txt\n",
            "Saving 1006892_2008.txt to 1006892_2008.txt\n",
            "Saving 1006892_2009.txt to 1006892_2009.txt\n",
            "Saving 1007800_2003.txt to 1007800_2003.txt\n",
            "Saving 1009304_2001.txt to 1009304_2001.txt\n",
            "Saving 1012482_2002.txt to 1012482_2002.txt\n",
            "Saving 1013243_2003.txt to 1013243_2003.txt\n",
            "Saving 1020416_1997.txt to 1020416_1997.txt\n",
            "Saving 1024401_1998.txt to 1024401_1998.txt\n",
            "Saving 1030471_2000.txt to 1030471_2000.txt\n",
            "Saving 1030471_2001.txt to 1030471_2001.txt\n",
            "Saving 1030471_2004.txt to 1030471_2004.txt\n",
            "Saving 1030471_2005.txt to 1030471_2005.txt\n",
            "Saving 1032975_2009.txt to 1032975_2009.txt\n",
            "Saving 1032975_2010.txt to 1032975_2010.txt\n",
            "Saving 1032975_2011.txt to 1032975_2011.txt\n",
            "Saving 1032975_2012.txt to 1032975_2012.txt\n",
            "Saving 1039101_2011.txt to 1039101_2011.txt\n",
            "Saving 1039101_2012.txt to 1039101_2012.txt\n",
            "Saving 1039101_2013.txt to 1039101_2013.txt\n",
            "Saving 1050446_1999.txt to 1050446_1999.txt\n",
            "Saving 1053112_2001.txt to 1053112_2001.txt\n",
            "Saving 1054374_1998.txt to 1054374_1998.txt\n",
            "Saving 1054374_1999.txt to 1054374_1999.txt\n",
            "Saving 1054374_2000.txt to 1054374_2000.txt\n",
            "Saving 1054374_2001.txt to 1054374_2001.txt\n",
            "Saving 1054374_2002.txt to 1054374_2002.txt\n",
            "Saving 1054374_2003.txt to 1054374_2003.txt\n",
            "Saving 1054374_2004.txt to 1054374_2004.txt\n",
            "Saving 1054374_2005.txt to 1054374_2005.txt\n",
            "Saving 1061580_2008.txt to 1061580_2008.txt\n",
            "Saving 1065298_2009.txt to 1065298_2009.txt\n",
            "Saving 1065332_2003.txt to 1065332_2003.txt\n",
            "Saving 1065860_2010.txt to 1065860_2010.txt\n",
            "Saving 1066107_2001.txt to 1066107_2001.txt\n",
            "Saving 1067701_2003.txt to 1067701_2003.txt\n",
            "Saving 1076930_2004.txt to 1076930_2004.txt\n",
            "Saving 1076930_2005.txt to 1076930_2005.txt\n",
            "Saving 1081661_2000.txt to 1081661_2000.txt\n",
            "Saving 1082084_2007.txt to 1082084_2007.txt\n",
            "Saving 1084408_2001.txt to 1084408_2001.txt\n",
            "Saving 1084408_2002.txt to 1084408_2002.txt\n",
            "Saving 1084408_2003.txt to 1084408_2003.txt\n",
            "Saving 1088033_2003.txt to 1088033_2003.txt\n",
            "Saving 1088033_2004.txt to 1088033_2004.txt\n",
            "Saving 1089567_2000.txt to 1089567_2000.txt\n",
            "Saving 1089567_2001.txt to 1089567_2001.txt\n",
            "Saving 1091667_2000.txt to 1091667_2000.txt\n",
            "Saving 1092367_2002.txt to 1092367_2002.txt\n",
            "Saving 1092367_2003.txt to 1092367_2003.txt\n",
            "Saving 1092367_2004.txt to 1092367_2004.txt\n",
            "Saving 1092367_2005.txt to 1092367_2005.txt\n",
            "Saving 1099219_2000.txt to 1099219_2000.txt\n",
            "Saving 1099219_2001.txt to 1099219_2001.txt\n",
            "Saving 1099219_2002.txt to 1099219_2002.txt\n",
            "Saving 1099219_2003.txt to 1099219_2003.txt\n",
            "Saving 1102329_2002.txt to 1102329_2002.txt\n",
            "Saving 1107112_2002.txt to 1107112_2002.txt\n",
            "Saving 1107112_2004.txt to 1107112_2004.txt\n",
            "Saving 1110783_2009.txt to 1110783_2009.txt\n",
            "Saving 1111345_2002.txt to 1111345_2002.txt\n",
            "Saving 1123028_2001.txt to 1123028_2001.txt\n",
            "Saving 1123337_2000.txt to 1123337_2000.txt\n",
            "Saving 1123337_2001.txt to 1123337_2001.txt\n",
            "Saving 1126294_2001.txt to 1126294_2001.txt\n",
            "Saving 1129633_2009.txt to 1129633_2009.txt\n",
            "Saving 1129633_2010.txt to 1129633_2010.txt\n",
            " Upload NON-FRAUD MD&A files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a87e49f-2eff-4106-a3d5-0b4f304b7556\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a87e49f-2eff-4106-a3d5-0b4f304b7556\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2135_2006.txt to 2135_2006.txt\n",
            "Saving 2135_2007.txt to 2135_2007.txt\n",
            "Saving 3906_2006.txt to 3906_2006.txt\n",
            "Saving 3906_2007.txt to 3906_2007.txt\n",
            "Saving 3906_2008.txt to 3906_2008.txt\n",
            "Saving 3906_2009.txt to 3906_2009.txt\n",
            "Saving 5272_1996.txt to 5272_1996.txt\n",
            "Saving 5272_1998.txt to 5272_1998.txt\n",
            "Saving 5272_1999.txt to 5272_1999.txt\n",
            "Saving 5272_2004.txt to 5272_2004.txt\n",
            "Saving 5272_2005.txt to 5272_2005.txt\n",
            "Saving 5272_2006.txt to 5272_2006.txt\n",
            "Saving 5272_2007.txt to 5272_2007.txt\n",
            "Saving 5272_2010.txt to 5272_2010.txt\n",
            "Saving 5272_2011.txt to 5272_2011.txt\n",
            "Saving 5272_2014.txt to 5272_2014.txt\n",
            "Saving 5272_2015.txt to 5272_2015.txt\n",
            "Saving 5272_2016.txt to 5272_2016.txt\n",
            "Saving 5272_2017.txt to 5272_2017.txt\n",
            "Saving 5272_2018.txt to 5272_2018.txt\n",
            "Saving 5272_2019.txt to 5272_2019.txt\n",
            "Saving 8868_2014.txt to 8868_2014.txt\n",
            "Saving 8868_2015.txt to 8868_2015.txt\n",
            "Saving 8868_2016.txt to 8868_2016.txt\n",
            "Saving 14272_2004.txt to 14272_2004.txt\n",
            "Saving 14272_2005.txt to 14272_2005.txt\n",
            "Saving 14272_2006.txt to 14272_2006.txt\n",
            "Saving 14272_2007.txt to 14272_2007.txt\n",
            "Saving 14272_2008.txt to 14272_2008.txt\n",
            "Saving 14272_2009.txt to 14272_2009.txt\n",
            "Saving 14272_2010.txt to 14272_2010.txt\n",
            "Saving 21344_2008.txt to 21344_2008.txt\n",
            "Saving 21344_2009.txt to 21344_2009.txt\n",
            "Saving 21344_2010.txt to 21344_2010.txt\n",
            "Saving 21344_2011.txt to 21344_2011.txt\n",
            "Saving 21344_2012.txt to 21344_2012.txt\n",
            "Saving 21344_2013.txt to 21344_2013.txt\n",
            "Saving 21344_2014.txt to 21344_2014.txt\n",
            "Saving 21344_2015.txt to 21344_2015.txt\n",
            "Saving 21344_2016.txt to 21344_2016.txt\n",
            "Saving 21344_2017.txt to 21344_2017.txt\n",
            "Saving 21344_2018.txt to 21344_2018.txt\n",
            "Saving 21344_2019.txt to 21344_2019.txt\n",
            "Saving 29915_2008.txt to 29915_2008.txt\n",
            "Saving 29915_2009.txt to 29915_2009.txt\n",
            "Saving 29915_2010.txt to 29915_2010.txt\n",
            "Saving 29915_2011.txt to 29915_2011.txt\n",
            "Saving 29915_2012.txt to 29915_2012.txt\n",
            "Saving 29915_2013.txt to 29915_2013.txt\n",
            "Saving 29915_2014.txt to 29915_2014.txt\n",
            "Saving 29915_2015.txt to 29915_2015.txt\n",
            "Saving 29915_2016.txt to 29915_2016.txt\n",
            "Saving 29915_2019.txt to 29915_2019.txt\n",
            "Saving 35527_2018.txt to 35527_2018.txt\n",
            "Saving 35527_2019.txt to 35527_2019.txt\n",
            "Saving 40545_2008.txt to 40545_2008.txt\n",
            "Saving 40545_2009.txt to 40545_2009.txt\n",
            "Saving 40545_2010.txt to 40545_2010.txt\n",
            "Saving 40545_2011.txt to 40545_2011.txt\n",
            "Saving 40545_2012.txt to 40545_2012.txt\n",
            "Saving 40545_2013.txt to 40545_2013.txt\n",
            "Saving 49196_2009.txt to 49196_2009.txt\n",
            "Saving 49196_2010.txt to 49196_2010.txt\n",
            "Saving 49196_2011.txt to 49196_2011.txt\n",
            "Saving 49196_2012.txt to 49196_2012.txt\n",
            "Saving 49196_2013.txt to 49196_2013.txt\n",
            "Saving 49196_2014.txt to 49196_2014.txt\n",
            "Saving 49196_2015.txt to 49196_2015.txt\n",
            "Saving 49196_2016.txt to 49196_2016.txt\n",
            "Saving 49196_2017.txt to 49196_2017.txt\n",
            "Saving 49196_2018.txt to 49196_2018.txt\n",
            "Saving 49196_2019.txt to 49196_2019.txt\n",
            "Saving 51644_2004.txt to 51644_2004.txt\n",
            "Saving 51644_2005.txt to 51644_2005.txt\n",
            "Saving 60714_2000.txt to 60714_2000.txt\n",
            "Saving 70318_2005.txt to 70318_2005.txt\n",
            "Saving 70318_2006.txt to 70318_2006.txt\n",
            "Saving 70318_2007.txt to 70318_2007.txt\n",
            "Saving 70318_2008.txt to 70318_2008.txt\n",
            "Saving 70318_2009.txt to 70318_2009.txt\n",
            "Saving 70318_2010.txt to 70318_2010.txt\n",
            "Saving 70318_2011.txt to 70318_2011.txt\n",
            "Saving 70318_2012.txt to 70318_2012.txt\n",
            "Saving 70318_2013.txt to 70318_2013.txt\n",
            "Saving 70318_2014.txt to 70318_2014.txt\n",
            "Saving 70318_2015.txt to 70318_2015.txt\n",
            "Saving 70318_2016.txt to 70318_2016.txt\n",
            "Saving 70318_2017.txt to 70318_2017.txt\n",
            "Saving 70318_2018.txt to 70318_2018.txt\n",
            "Saving 70318_2019.txt to 70318_2019.txt\n",
            "Saving 72911_2004.txt to 72911_2004.txt\n",
            "Saving 72911_2005.txt to 72911_2005.txt\n",
            "Saving 72911_2006.txt to 72911_2006.txt\n",
            "Saving 72911_2007.txt to 72911_2007.txt\n",
            "Saving 72911_2008.txt to 72911_2008.txt\n",
            "Saving 72911_2009.txt to 72911_2009.txt\n",
            "Saving 72911_2010.txt to 72911_2010.txt\n",
            "Saving 72911_2011.txt to 72911_2011.txt\n",
            "Saving 73887_2018.txt to 73887_2018.txt\n",
            "Saving 73887_2019.txt to 73887_2019.txt\n",
            "Saving 98222_2010.txt to 98222_2010.txt\n",
            "Saving 98222_2011.txt to 98222_2011.txt\n",
            "Saving 98222_2012.txt to 98222_2012.txt\n",
            "Saving 98222_2013.txt to 98222_2013.txt\n",
            "Saving 98222_2014.txt to 98222_2014.txt\n",
            "Saving 98222_2015.txt to 98222_2015.txt\n",
            "Saving 98222_2016.txt to 98222_2016.txt\n",
            "Saving 98222_2017.txt to 98222_2017.txt\n",
            "Saving 98222_2018.txt to 98222_2018.txt\n",
            "Saving 103872_2012.txt to 103872_2012.txt\n",
            "Saving 103872_2013.txt to 103872_2013.txt\n",
            "Saving 108772_2017.txt to 108772_2017.txt\n",
            "Saving 310522_2006.txt to 310522_2006.txt\n",
            "Saving 310522_2007.txt to 310522_2007.txt\n",
            "Saving 310522_2008.txt to 310522_2008.txt\n",
            "Saving 310522_2009.txt to 310522_2009.txt\n",
            "Saving 310522_2010.txt to 310522_2010.txt\n",
            "Saving 310522_2011.txt to 310522_2011.txt\n",
            "Saving 310522_2012.txt to 310522_2012.txt\n",
            "Saving 310522_2013.txt to 310522_2013.txt\n",
            "Saving 310522_2014.txt to 310522_2014.txt\n",
            "Saving 310522_2015.txt to 310522_2015.txt\n",
            "Saving 310522_2016.txt to 310522_2016.txt\n",
            "Saving 310522_2017.txt to 310522_2017.txt\n",
            "Saving 310522_2018.txt to 310522_2018.txt\n",
            "Saving 310522_2019.txt to 310522_2019.txt\n",
            "Saving 352495_2000.txt to 352495_2000.txt\n",
            "Saving 352949_1999.txt to 352949_1999.txt\n",
            "Saving 709283_2002.txt to 709283_2002.txt\n",
            "Saving 709283_2003.txt to 709283_2003.txt\n",
            "Saving 710507_2002.txt to 710507_2002.txt\n",
            "Saving 710507_2008.txt to 710507_2008.txt\n",
            "Saving 710507_2009.txt to 710507_2009.txt\n",
            "Saving 710507_2010.txt to 710507_2010.txt\n",
            "Saving 710507_2011.txt to 710507_2011.txt\n",
            "Saving 710507_2012.txt to 710507_2012.txt\n",
            "Saving 710507_2013.txt to 710507_2013.txt\n",
            "Saving 723612_2002.txt to 723612_2002.txt\n",
            "Saving 726513_2006.txt to 726513_2006.txt\n",
            "Saving 726513_2014.txt to 726513_2014.txt\n",
            "Saving 726513_2015.txt to 726513_2015.txt\n",
            "Saving 726513_2016.txt to 726513_2016.txt\n",
            "Saving 726513_2017.txt to 726513_2017.txt\n",
            "Saving 785161_2004.txt to 785161_2004.txt\n",
            "Saving 785161_2005.txt to 785161_2005.txt\n",
            "Saving 785161_2006.txt to 785161_2006.txt\n",
            "Saving 785161_2008.txt to 785161_2008.txt\n",
            "Saving 799089_2002.txt to 799089_2002.txt\n",
            "Saving 803014_2009.txt to 803014_2009.txt\n",
            "Saving 803014_2010.txt to 803014_2010.txt\n",
            "Saving 803014_2011.txt to 803014_2011.txt\n",
            "Saving 803014_2012.txt to 803014_2012.txt\n",
            "Saving 805676_2019.txt to 805676_2019.txt\n",
            "Saving 808450_2007.txt to 808450_2007.txt\n",
            "Saving 808450_2008.txt to 808450_2008.txt\n",
            "Saving 808450_2009.txt to 808450_2009.txt\n",
            "Saving 808450_2010.txt to 808450_2010.txt\n",
            "Saving 808450_2011.txt to 808450_2011.txt\n",
            "Saving 808450_2012.txt to 808450_2012.txt\n",
            "Saving 808450_2013.txt to 808450_2013.txt\n",
            "Saving 811156_1995.txt to 811156_1995.txt\n",
            "Saving 811156_1996.txt to 811156_1996.txt\n",
            "Saving 814585_2008.txt to 814585_2008.txt\n",
            "Saving 814585_2009.txt to 814585_2009.txt\n",
            "Saving 814585_2010.txt to 814585_2010.txt\n",
            "Saving 814585_2011.txt to 814585_2011.txt\n",
            "Saving 814585_2012.txt to 814585_2012.txt\n",
            "Saving 814585_2013.txt to 814585_2013.txt\n",
            "Saving 814585_2014.txt to 814585_2014.txt\n",
            "Saving 814585_2015.txt to 814585_2015.txt\n",
            "Saving 814585_2016.txt to 814585_2016.txt\n",
            "Saving 814585_2017.txt to 814585_2017.txt\n",
            "Saving 826083_2009.txt to 826083_2009.txt\n",
            "Saving 826154_2012.txt to 826154_2012.txt\n",
            "Saving 826154_2013.txt to 826154_2013.txt\n",
            "Saving 835012_2010.txt to 835012_2010.txt\n",
            "Saving 840889_1998.txt to 840889_1998.txt\n",
            "Saving 840889_2005.txt to 840889_2005.txt\n",
            "Saving 840889_2006.txt to 840889_2006.txt\n",
            "Saving 840889_2007.txt to 840889_2007.txt\n",
            "Saving 840889_2008.txt to 840889_2008.txt\n",
            "Saving 840889_2009.txt to 840889_2009.txt\n",
            "Saving 840889_2010.txt to 840889_2010.txt\n",
            "Saving 840889_2012.txt to 840889_2012.txt\n",
            "Saving 840889_2013.txt to 840889_2013.txt\n",
            "Saving 851726_2012.txt to 851726_2012.txt\n",
            "Saving 851726_2013.txt to 851726_2013.txt\n",
            "Saving 872821_2010.txt to 872821_2010.txt\n",
            "Saving 880446_2009.txt to 880446_2009.txt\n",
            "Saving 885590_2009.txt to 885590_2009.txt\n",
            "Saving 885590_2010.txt to 885590_2010.txt\n",
            "Saving 885590_2011.txt to 885590_2011.txt\n",
            "Saving 885590_2012.txt to 885590_2012.txt\n",
            "Saving 885590_2016.txt to 885590_2016.txt\n",
            "Saving 885590_2017.txt to 885590_2017.txt\n",
            "Saving 885590_2018.txt to 885590_2018.txt\n",
            "Saving 885590_2019.txt to 885590_2019.txt\n",
            "Saving 885725_1999.txt to 885725_1999.txt\n",
            "Saving 885725_2009.txt to 885725_2009.txt\n",
            "Saving 885725_2010.txt to 885725_2010.txt\n",
            " Loaded 400 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Colab file‑upload → deterministic mdna_samples.json\n",
        "# ---------------------------------------------------------------\n",
        "from google.colab import files\n",
        "import json, pathlib, random, numpy as np, torch, collections\n",
        "\n",
        "SEED = 42  # keep same seed as training script\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "print(\"🔼  Upload *FRAUD* MD&A files:\")\n",
        "fraud_files_dict = files.upload()    # returns an unordered dict\n",
        "\n",
        "print(\"🔼  Upload *NON‑FRAUD* MD&A files:\")\n",
        "nonfraud_files_dict = files.upload()\n",
        "\n",
        "# 1️⃣  Alphabetical order gives deterministic behaviour\n",
        "fraud_filenames      = sorted(fraud_files_dict.keys())\n",
        "nonfraud_filenames   = sorted(nonfraud_files_dict.keys())\n",
        "\n",
        "mdna_samples = []\n",
        "\n",
        "for fn in fraud_filenames:\n",
        "    with open(fn, \"r\", encoding=\"utf‑8\") as f:\n",
        "        mdna_samples.append({\"text\": f.read(), \"true_label\": \"Fraud\", \"filename\": fn})\n",
        "\n",
        "for fn in nonfraud_filenames:\n",
        "    with open(fn, \"r\", encoding=\"utf‑8\") as f:\n",
        "        mdna_samples.append({\"text\": f.read(), \"true_label\": \"Non‑Fraud\", \"filename\": fn})\n",
        "\n",
        "print(f\"✅  Loaded {len(mdna_samples)} documents \"\n",
        "      f\"({sum(s['true_label']=='Fraud' for s in mdna_samples)} Fraud / \"\n",
        "      f\"{sum(s['true_label']=='Non‑Fraud' for s in mdna_samples)} Non‑Fraud)\")\n",
        "\n",
        "# 2️⃣  Save once so training/eval scripts can reuse without re‑uploading\n",
        "with open(\"mdna_samples.json\", \"w\") as f:\n",
        "    json.dump(mdna_samples, f)\n",
        "\n",
        "print(\"💾  Saved to mdna_samples.json — ready for training script\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9AY6ZKST-_lk",
        "outputId": "4a6eaeec-0193-4cd2-df0e-7dbbeca629b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔼  Upload *FRAUD* MD&A files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d921979-a68c-4bc4-9281-ca51d8111dc3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3d921979-a68c-4bc4-9281-ca51d8111dc3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2135_2004.txt to 2135_2004.txt\n",
            "Saving 2135_2005.txt to 2135_2005.txt\n",
            "Saving 2135_2009.txt to 2135_2009.txt\n",
            "Saving 3449_1995.txt to 3449_1995.txt\n",
            "Saving 5272_2000.txt to 5272_2000.txt\n",
            "Saving 5272_2001.txt to 5272_2001.txt\n",
            "Saving 5272_2002.txt to 5272_2002.txt\n",
            "Saving 5272_2003.txt to 5272_2003.txt\n",
            "Saving 23082_2009.txt to 23082_2009.txt\n",
            "Saving 23082_2010.txt to 23082_2010.txt\n",
            "Saving 23082_2011.txt to 23082_2011.txt\n",
            "Saving 23217_2005.txt to 23217_2005.txt\n",
            "Saving 26780_2004.txt to 26780_2004.txt\n",
            "Saving 49196_2001.txt to 49196_2001.txt\n",
            "Saving 51644_2002.txt to 51644_2002.txt\n",
            "Saving 51644_2003.txt to 51644_2003.txt\n",
            "Saving 70318_2004.txt to 70318_2004.txt\n",
            "Saving 72911_2000.txt to 72911_2000.txt\n",
            "Saving 72911_2001.txt to 72911_2001.txt\n",
            "Saving 72911_2002.txt to 72911_2002.txt\n",
            "Saving 73088_2001.txt to 73088_2001.txt\n",
            "Saving 75208_2003.txt to 75208_2003.txt\n",
            "Saving 75208_2005.txt to 75208_2005.txt\n",
            "Saving 75208_2006.txt to 75208_2006.txt\n",
            "Saving 75208_2009.txt to 75208_2009.txt\n",
            "Saving 75208_2010.txt to 75208_2010.txt\n",
            "Saving 75208_2011.txt to 75208_2011.txt\n",
            "Saving 97216_2002.txt to 97216_2002.txt\n",
            "Saving 97216_2003.txt to 97216_2003.txt\n",
            "Saving 99771_2010.txt to 99771_2010.txt\n",
            "Saving 99771_2011.txt to 99771_2011.txt\n",
            "Saving 103872_2007.txt to 103872_2007.txt\n",
            "Saving 216228_2002.txt to 216228_2002.txt\n",
            "Saving 216228_2003.txt to 216228_2003.txt\n",
            "Saving 216228_2004.txt to 216228_2004.txt\n",
            "Saving 278352_2002.txt to 278352_2002.txt\n",
            "Saving 310522_2002.txt to 310522_2002.txt\n",
            "Saving 310522_2003.txt to 310522_2003.txt\n",
            "Saving 319815_2012.txt to 319815_2012.txt\n",
            "Saving 352495_1997.txt to 352495_1997.txt\n",
            "Saving 700564_2016.txt to 700564_2016.txt\n",
            "Saving 700564_2017.txt to 700564_2017.txt\n",
            "Saving 710507_2003.txt to 710507_2003.txt\n",
            "Saving 710507_2004.txt to 710507_2004.txt\n",
            "Saving 710507_2005.txt to 710507_2005.txt\n",
            "Saving 710507_2006.txt to 710507_2006.txt\n",
            "Saving 710507_2007.txt to 710507_2007.txt\n",
            "Saving 723527_1999.txt to 723527_1999.txt\n",
            "Saving 723527_2000.txt to 723527_2000.txt\n",
            "Saving 723527_2001.txt to 723527_2001.txt\n",
            "Saving 731766_2004.txt to 731766_2004.txt\n",
            "Saving 731766_2005.txt to 731766_2005.txt\n",
            "Saving 745308_2009.txt to 745308_2009.txt\n",
            "Saving 745308_2010.txt to 745308_2010.txt\n",
            "Saving 784932_1996.txt to 784932_1996.txt\n",
            "Saving 784932_1997.txt to 784932_1997.txt\n",
            "Saving 784932_1998.txt to 784932_1998.txt\n",
            "Saving 796486_1998.txt to 796486_1998.txt\n",
            "Saving 803014_2005.txt to 803014_2005.txt\n",
            "Saving 811671_2002.txt to 811671_2002.txt\n",
            "Saving 811671_2003.txt to 811671_2003.txt\n",
            "Saving 811671_2004.txt to 811671_2004.txt\n",
            "Saving 811671_2005.txt to 811671_2005.txt\n",
            "Saving 811671_2006.txt to 811671_2006.txt\n",
            "Saving 814585_2003.txt to 814585_2003.txt\n",
            "Saving 826154_2010.txt to 826154_2010.txt\n",
            "Saving 826154_2011.txt to 826154_2011.txt\n",
            "Saving 826773_2012.txt to 826773_2012.txt\n",
            "Saving 834408_2007.txt to 834408_2007.txt\n",
            "Saving 835012_2008.txt to 835012_2008.txt\n",
            "Saving 835012_2009.txt to 835012_2009.txt\n",
            "Saving 844161_2017.txt to 844161_2017.txt\n",
            "Saving 846815_2002.txt to 846815_2002.txt\n",
            "Saving 846815_2003.txt to 846815_2003.txt\n",
            "Saving 846909_2000.txt to 846909_2000.txt\n",
            "Saving 859475_2006.txt to 859475_2006.txt\n",
            "Saving 866535_2003.txt to 866535_2003.txt\n",
            "Saving 867058_2001.txt to 867058_2001.txt\n",
            "Saving 867058_2002.txt to 867058_2002.txt\n",
            "Saving 867058_2003.txt to 867058_2003.txt\n",
            "Saving 867058_2004.txt to 867058_2004.txt\n",
            "Saving 867058_2005.txt to 867058_2005.txt\n",
            "Saving 872821_2009.txt to 872821_2009.txt\n",
            "Saving 876889_1996.txt to 876889_1996.txt\n",
            "Saving 878522_2001.txt to 878522_2001.txt\n",
            "Saving 878522_2002.txt to 878522_2002.txt\n",
            "Saving 878522_2003.txt to 878522_2003.txt\n",
            "Saving 878522_2004.txt to 878522_2004.txt\n",
            "Saving 883902_2000.txt to 883902_2000.txt\n",
            "Saving 884624_2010.txt to 884624_2010.txt\n",
            "Saving 886035_2009.txt to 886035_2009.txt\n",
            "Saving 886035_2010.txt to 886035_2010.txt\n",
            "Saving 886035_2011.txt to 886035_2011.txt\n",
            "Saving 887919_2001.txt to 887919_2001.txt\n",
            "Saving 887919_2002.txt to 887919_2002.txt\n",
            "Saving 888919_2004.txt to 888919_2004.txt\n",
            "Saving 888919_2005.txt to 888919_2005.txt\n",
            "Saving 890923_2007.txt to 890923_2007.txt\n",
            "Saving 892535_2007.txt to 892535_2007.txt\n",
            "Saving 895421_2000.txt to 895421_2000.txt\n",
            "Saving 895421_2001.txt to 895421_2001.txt\n",
            "Saving 895421_2002.txt to 895421_2002.txt\n",
            "Saving 900091_1997.txt to 900091_1997.txt\n",
            "Saving 908255_2015.txt to 908255_2015.txt\n",
            "Saving 908255_2016.txt to 908255_2016.txt\n",
            "Saving 912603_2004.txt to 912603_2004.txt\n",
            "Saving 913144_2002.txt to 913144_2002.txt\n",
            "Saving 913144_2003.txt to 913144_2003.txt\n",
            "Saving 913760_2010.txt to 913760_2010.txt\n",
            "Saving 913760_2011.txt to 913760_2011.txt\n",
            "Saving 913760_2012.txt to 913760_2012.txt\n",
            "Saving 914712_2007.txt to 914712_2007.txt\n",
            "Saving 914712_2008.txt to 914712_2008.txt\n",
            "Saving 914712_2009.txt to 914712_2009.txt\n",
            "Saving 914712_2010.txt to 914712_2010.txt\n",
            "Saving 914712_2011.txt to 914712_2011.txt\n",
            "Saving 915840_2007.txt to 915840_2007.txt\n",
            "Saving 919742_2005.txt to 919742_2005.txt\n",
            "Saving 923282_2001.txt to 923282_2001.txt\n",
            "Saving 923796_2005.txt to 923796_2005.txt\n",
            "Saving 929994_2009.txt to 929994_2009.txt\n",
            "Saving 929994_2010.txt to 929994_2010.txt\n",
            "Saving 929994_2011.txt to 929994_2011.txt\n",
            "Saving 933974_2001.txt to 933974_2001.txt\n",
            "Saving 933974_2002.txt to 933974_2002.txt\n",
            "Saving 933974_2003.txt to 933974_2003.txt\n",
            "Saving 933974_2004.txt to 933974_2004.txt\n",
            "Saving 933974_2005.txt to 933974_2005.txt\n",
            "Saving 939930_2014.txt to 939930_2014.txt\n",
            "Saving 944765_2005.txt to 944765_2005.txt\n",
            "Saving 946581_2001.txt to 946581_2001.txt\n",
            "Saving 946581_2003.txt to 946581_2003.txt\n",
            "Saving 1002131_1999.txt to 1002131_1999.txt\n",
            "Saving 1004945_2002.txt to 1004945_2002.txt\n",
            "Saving 1006892_2008.txt to 1006892_2008.txt\n",
            "Saving 1006892_2009.txt to 1006892_2009.txt\n",
            "Saving 1007800_2003.txt to 1007800_2003.txt\n",
            "Saving 1009304_2001.txt to 1009304_2001.txt\n",
            "Saving 1012482_2002.txt to 1012482_2002.txt\n",
            "Saving 1013243_2003.txt to 1013243_2003.txt\n",
            "Saving 1020416_1997.txt to 1020416_1997.txt\n",
            "Saving 1024401_1998.txt to 1024401_1998.txt\n",
            "Saving 1030471_2000.txt to 1030471_2000.txt\n",
            "Saving 1030471_2001.txt to 1030471_2001.txt\n",
            "Saving 1030471_2004.txt to 1030471_2004.txt\n",
            "Saving 1030471_2005.txt to 1030471_2005.txt\n",
            "Saving 1032975_2009.txt to 1032975_2009.txt\n",
            "Saving 1032975_2010.txt to 1032975_2010.txt\n",
            "Saving 1032975_2011.txt to 1032975_2011.txt\n",
            "Saving 1032975_2012.txt to 1032975_2012.txt\n",
            "Saving 1039101_2011.txt to 1039101_2011.txt\n",
            "Saving 1039101_2012.txt to 1039101_2012.txt\n",
            "Saving 1039101_2013.txt to 1039101_2013.txt\n",
            "Saving 1050446_1999.txt to 1050446_1999.txt\n",
            "Saving 1053112_2001.txt to 1053112_2001.txt\n",
            "Saving 1054374_1998.txt to 1054374_1998.txt\n",
            "Saving 1054374_1999.txt to 1054374_1999.txt\n",
            "Saving 1054374_2000.txt to 1054374_2000.txt\n",
            "Saving 1054374_2001.txt to 1054374_2001.txt\n",
            "Saving 1054374_2002.txt to 1054374_2002.txt\n",
            "Saving 1054374_2003.txt to 1054374_2003.txt\n",
            "Saving 1054374_2004.txt to 1054374_2004.txt\n",
            "Saving 1054374_2005.txt to 1054374_2005.txt\n",
            "Saving 1061580_2008.txt to 1061580_2008.txt\n",
            "Saving 1065298_2009.txt to 1065298_2009.txt\n",
            "Saving 1065332_2003.txt to 1065332_2003.txt\n",
            "Saving 1065860_2010.txt to 1065860_2010.txt\n",
            "Saving 1066107_2001.txt to 1066107_2001.txt\n",
            "Saving 1067701_2003.txt to 1067701_2003.txt\n",
            "Saving 1076930_2004.txt to 1076930_2004.txt\n",
            "Saving 1076930_2005.txt to 1076930_2005.txt\n",
            "Saving 1081661_2000.txt to 1081661_2000.txt\n",
            "Saving 1082084_2007.txt to 1082084_2007.txt\n",
            "Saving 1084408_2001.txt to 1084408_2001.txt\n",
            "Saving 1084408_2002.txt to 1084408_2002.txt\n",
            "Saving 1084408_2003.txt to 1084408_2003.txt\n",
            "Saving 1088033_2003.txt to 1088033_2003.txt\n",
            "Saving 1088033_2004.txt to 1088033_2004.txt\n",
            "Saving 1089567_2000.txt to 1089567_2000.txt\n",
            "Saving 1089567_2001.txt to 1089567_2001.txt\n",
            "Saving 1091667_2000.txt to 1091667_2000.txt\n",
            "Saving 1092367_2002.txt to 1092367_2002.txt\n",
            "Saving 1092367_2003.txt to 1092367_2003.txt\n",
            "Saving 1092367_2004.txt to 1092367_2004.txt\n",
            "Saving 1092367_2005.txt to 1092367_2005.txt\n",
            "Saving 1099219_2000.txt to 1099219_2000.txt\n",
            "Saving 1099219_2001.txt to 1099219_2001.txt\n",
            "Saving 1099219_2002.txt to 1099219_2002.txt\n",
            "Saving 1099219_2003.txt to 1099219_2003.txt\n",
            "Saving 1102329_2002.txt to 1102329_2002.txt\n",
            "Saving 1107112_2002.txt to 1107112_2002.txt\n",
            "Saving 1107112_2004.txt to 1107112_2004.txt\n",
            "Saving 1110783_2009.txt to 1110783_2009.txt\n",
            "Saving 1111345_2002.txt to 1111345_2002.txt\n",
            "Saving 1123028_2001.txt to 1123028_2001.txt\n",
            "Saving 1123337_2000.txt to 1123337_2000.txt\n",
            "Saving 1123337_2001.txt to 1123337_2001.txt\n",
            "Saving 1126294_2001.txt to 1126294_2001.txt\n",
            "Saving 1129633_2009.txt to 1129633_2009.txt\n",
            "Saving 1129633_2010.txt to 1129633_2010.txt\n",
            "🔼  Upload *NON‑FRAUD* MD&A files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3fc5eaa7-fc71-4cf7-9f8c-daf70570b2e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3fc5eaa7-fc71-4cf7-9f8c-daf70570b2e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2135_2006.txt to 2135_2006.txt\n",
            "Saving 2135_2007.txt to 2135_2007.txt\n",
            "Saving 3906_2006.txt to 3906_2006.txt\n",
            "Saving 3906_2007.txt to 3906_2007.txt\n",
            "Saving 3906_2008.txt to 3906_2008.txt\n",
            "Saving 3906_2009.txt to 3906_2009.txt\n",
            "Saving 5272_1996.txt to 5272_1996.txt\n",
            "Saving 5272_1998.txt to 5272_1998.txt\n",
            "Saving 5272_1999.txt to 5272_1999.txt\n",
            "Saving 5272_2004.txt to 5272_2004.txt\n",
            "Saving 5272_2005.txt to 5272_2005.txt\n",
            "Saving 5272_2006.txt to 5272_2006.txt\n",
            "Saving 5272_2007.txt to 5272_2007.txt\n",
            "Saving 5272_2010.txt to 5272_2010.txt\n",
            "Saving 5272_2011.txt to 5272_2011.txt\n",
            "Saving 5272_2014.txt to 5272_2014.txt\n",
            "Saving 5272_2015.txt to 5272_2015.txt\n",
            "Saving 5272_2016.txt to 5272_2016.txt\n",
            "Saving 5272_2017.txt to 5272_2017.txt\n",
            "Saving 5272_2018.txt to 5272_2018.txt\n",
            "Saving 5272_2019.txt to 5272_2019.txt\n",
            "Saving 8868_2014.txt to 8868_2014.txt\n",
            "Saving 8868_2015.txt to 8868_2015.txt\n",
            "Saving 8868_2016.txt to 8868_2016.txt\n",
            "Saving 14272_2004.txt to 14272_2004.txt\n",
            "Saving 14272_2005.txt to 14272_2005.txt\n",
            "Saving 14272_2006.txt to 14272_2006.txt\n",
            "Saving 14272_2007.txt to 14272_2007.txt\n",
            "Saving 14272_2008.txt to 14272_2008.txt\n",
            "Saving 14272_2009.txt to 14272_2009.txt\n",
            "Saving 14272_2010.txt to 14272_2010.txt\n",
            "Saving 21344_2008.txt to 21344_2008.txt\n",
            "Saving 21344_2009.txt to 21344_2009.txt\n",
            "Saving 21344_2010.txt to 21344_2010.txt\n",
            "Saving 21344_2011.txt to 21344_2011.txt\n",
            "Saving 21344_2012.txt to 21344_2012.txt\n",
            "Saving 21344_2013.txt to 21344_2013.txt\n",
            "Saving 21344_2014.txt to 21344_2014.txt\n",
            "Saving 21344_2015.txt to 21344_2015.txt\n",
            "Saving 21344_2016.txt to 21344_2016.txt\n",
            "Saving 21344_2017.txt to 21344_2017.txt\n",
            "Saving 21344_2018.txt to 21344_2018.txt\n",
            "Saving 21344_2019.txt to 21344_2019.txt\n",
            "Saving 29915_2008.txt to 29915_2008.txt\n",
            "Saving 29915_2009.txt to 29915_2009.txt\n",
            "Saving 29915_2010.txt to 29915_2010.txt\n",
            "Saving 29915_2011.txt to 29915_2011.txt\n",
            "Saving 29915_2012.txt to 29915_2012.txt\n",
            "Saving 29915_2013.txt to 29915_2013.txt\n",
            "Saving 29915_2014.txt to 29915_2014.txt\n",
            "Saving 29915_2015.txt to 29915_2015.txt\n",
            "Saving 29915_2016.txt to 29915_2016.txt\n",
            "Saving 29915_2019.txt to 29915_2019.txt\n",
            "Saving 35527_2018.txt to 35527_2018.txt\n",
            "Saving 35527_2019.txt to 35527_2019.txt\n",
            "Saving 40545_2008.txt to 40545_2008.txt\n",
            "Saving 40545_2009.txt to 40545_2009.txt\n",
            "Saving 40545_2010.txt to 40545_2010.txt\n",
            "Saving 40545_2011.txt to 40545_2011.txt\n",
            "Saving 40545_2012.txt to 40545_2012.txt\n",
            "Saving 40545_2013.txt to 40545_2013.txt\n",
            "Saving 49196_2009.txt to 49196_2009.txt\n",
            "Saving 49196_2010.txt to 49196_2010.txt\n",
            "Saving 49196_2011.txt to 49196_2011.txt\n",
            "Saving 49196_2012.txt to 49196_2012.txt\n",
            "Saving 49196_2013.txt to 49196_2013.txt\n",
            "Saving 49196_2014.txt to 49196_2014.txt\n",
            "Saving 49196_2015.txt to 49196_2015.txt\n",
            "Saving 49196_2016.txt to 49196_2016.txt\n",
            "Saving 49196_2017.txt to 49196_2017.txt\n",
            "Saving 49196_2018.txt to 49196_2018.txt\n",
            "Saving 49196_2019.txt to 49196_2019.txt\n",
            "Saving 51644_2004.txt to 51644_2004.txt\n",
            "Saving 51644_2005.txt to 51644_2005.txt\n",
            "Saving 60714_2000.txt to 60714_2000.txt\n",
            "Saving 70318_2005.txt to 70318_2005.txt\n",
            "Saving 70318_2006.txt to 70318_2006.txt\n",
            "Saving 70318_2007.txt to 70318_2007.txt\n",
            "Saving 70318_2008.txt to 70318_2008.txt\n",
            "Saving 70318_2009.txt to 70318_2009.txt\n",
            "Saving 70318_2010.txt to 70318_2010.txt\n",
            "Saving 70318_2011.txt to 70318_2011.txt\n",
            "Saving 70318_2012.txt to 70318_2012.txt\n",
            "Saving 70318_2013.txt to 70318_2013.txt\n",
            "Saving 70318_2014.txt to 70318_2014.txt\n",
            "Saving 70318_2015.txt to 70318_2015.txt\n",
            "Saving 70318_2016.txt to 70318_2016.txt\n",
            "Saving 70318_2017.txt to 70318_2017.txt\n",
            "Saving 70318_2018.txt to 70318_2018.txt\n",
            "Saving 70318_2019.txt to 70318_2019.txt\n",
            "Saving 72911_2004.txt to 72911_2004.txt\n",
            "Saving 72911_2005.txt to 72911_2005.txt\n",
            "Saving 72911_2006.txt to 72911_2006.txt\n",
            "Saving 72911_2007.txt to 72911_2007.txt\n",
            "Saving 72911_2008.txt to 72911_2008.txt\n",
            "Saving 72911_2009.txt to 72911_2009.txt\n",
            "Saving 72911_2010.txt to 72911_2010.txt\n",
            "Saving 72911_2011.txt to 72911_2011.txt\n",
            "Saving 73887_2018.txt to 73887_2018.txt\n",
            "Saving 73887_2019.txt to 73887_2019.txt\n",
            "Saving 98222_2010.txt to 98222_2010.txt\n",
            "Saving 98222_2011.txt to 98222_2011.txt\n",
            "Saving 98222_2012.txt to 98222_2012.txt\n",
            "Saving 98222_2013.txt to 98222_2013.txt\n",
            "Saving 98222_2014.txt to 98222_2014.txt\n",
            "Saving 98222_2015.txt to 98222_2015.txt\n",
            "Saving 98222_2016.txt to 98222_2016.txt\n",
            "Saving 98222_2017.txt to 98222_2017.txt\n",
            "Saving 98222_2018.txt to 98222_2018.txt\n",
            "Saving 103872_2012.txt to 103872_2012.txt\n",
            "Saving 103872_2013.txt to 103872_2013.txt\n",
            "Saving 108772_2017.txt to 108772_2017.txt\n",
            "Saving 310522_2006.txt to 310522_2006.txt\n",
            "Saving 310522_2007.txt to 310522_2007.txt\n",
            "Saving 310522_2008.txt to 310522_2008.txt\n",
            "Saving 310522_2009.txt to 310522_2009.txt\n",
            "Saving 310522_2010.txt to 310522_2010.txt\n",
            "Saving 310522_2011.txt to 310522_2011.txt\n",
            "Saving 310522_2012.txt to 310522_2012.txt\n",
            "Saving 310522_2013.txt to 310522_2013.txt\n",
            "Saving 310522_2014.txt to 310522_2014.txt\n",
            "Saving 310522_2015.txt to 310522_2015.txt\n",
            "Saving 310522_2016.txt to 310522_2016.txt\n",
            "Saving 310522_2017.txt to 310522_2017.txt\n",
            "Saving 310522_2018.txt to 310522_2018.txt\n",
            "Saving 310522_2019.txt to 310522_2019.txt\n",
            "Saving 352495_2000.txt to 352495_2000.txt\n",
            "Saving 352949_1999.txt to 352949_1999.txt\n",
            "Saving 709283_2002.txt to 709283_2002.txt\n",
            "Saving 709283_2003.txt to 709283_2003.txt\n",
            "Saving 710507_2002.txt to 710507_2002.txt\n",
            "Saving 710507_2008.txt to 710507_2008.txt\n",
            "Saving 710507_2009.txt to 710507_2009.txt\n",
            "Saving 710507_2010.txt to 710507_2010.txt\n",
            "Saving 710507_2011.txt to 710507_2011.txt\n",
            "Saving 710507_2012.txt to 710507_2012.txt\n",
            "Saving 710507_2013.txt to 710507_2013.txt\n",
            "Saving 723612_2002.txt to 723612_2002.txt\n",
            "Saving 726513_2006.txt to 726513_2006.txt\n",
            "Saving 726513_2014.txt to 726513_2014.txt\n",
            "Saving 726513_2015.txt to 726513_2015.txt\n",
            "Saving 726513_2016.txt to 726513_2016.txt\n",
            "Saving 726513_2017.txt to 726513_2017.txt\n",
            "Saving 785161_2004.txt to 785161_2004.txt\n",
            "Saving 785161_2005.txt to 785161_2005.txt\n",
            "Saving 785161_2006.txt to 785161_2006.txt\n",
            "Saving 785161_2008.txt to 785161_2008.txt\n",
            "Saving 799089_2002.txt to 799089_2002.txt\n",
            "Saving 803014_2009.txt to 803014_2009.txt\n",
            "Saving 803014_2010.txt to 803014_2010.txt\n",
            "Saving 803014_2011.txt to 803014_2011.txt\n",
            "Saving 803014_2012.txt to 803014_2012.txt\n",
            "Saving 805676_2019.txt to 805676_2019.txt\n",
            "Saving 808450_2007.txt to 808450_2007.txt\n",
            "Saving 808450_2008.txt to 808450_2008.txt\n",
            "Saving 808450_2009.txt to 808450_2009.txt\n",
            "Saving 808450_2010.txt to 808450_2010.txt\n",
            "Saving 808450_2011.txt to 808450_2011.txt\n",
            "Saving 808450_2012.txt to 808450_2012.txt\n",
            "Saving 808450_2013.txt to 808450_2013.txt\n",
            "Saving 811156_1995.txt to 811156_1995.txt\n",
            "Saving 811156_1996.txt to 811156_1996.txt\n",
            "Saving 814585_2008.txt to 814585_2008.txt\n",
            "Saving 814585_2009.txt to 814585_2009.txt\n",
            "Saving 814585_2010.txt to 814585_2010.txt\n",
            "Saving 814585_2011.txt to 814585_2011.txt\n",
            "Saving 814585_2012.txt to 814585_2012.txt\n",
            "Saving 814585_2013.txt to 814585_2013.txt\n",
            "Saving 814585_2014.txt to 814585_2014.txt\n",
            "Saving 814585_2015.txt to 814585_2015.txt\n",
            "Saving 814585_2016.txt to 814585_2016.txt\n",
            "Saving 814585_2017.txt to 814585_2017.txt\n",
            "Saving 826083_2009.txt to 826083_2009.txt\n",
            "Saving 826154_2012.txt to 826154_2012.txt\n",
            "Saving 826154_2013.txt to 826154_2013.txt\n",
            "Saving 835012_2010.txt to 835012_2010.txt\n",
            "Saving 840889_1998.txt to 840889_1998.txt\n",
            "Saving 840889_2005.txt to 840889_2005.txt\n",
            "Saving 840889_2006.txt to 840889_2006.txt\n",
            "Saving 840889_2007.txt to 840889_2007.txt\n",
            "Saving 840889_2008.txt to 840889_2008.txt\n",
            "Saving 840889_2009.txt to 840889_2009.txt\n",
            "Saving 840889_2010.txt to 840889_2010.txt\n",
            "Saving 840889_2012.txt to 840889_2012.txt\n",
            "Saving 840889_2013.txt to 840889_2013.txt\n",
            "Saving 851726_2012.txt to 851726_2012.txt\n",
            "Saving 851726_2013.txt to 851726_2013.txt\n",
            "Saving 872821_2010.txt to 872821_2010.txt\n",
            "Saving 880446_2009.txt to 880446_2009.txt\n",
            "Saving 885590_2009.txt to 885590_2009.txt\n",
            "Saving 885590_2010.txt to 885590_2010.txt\n",
            "Saving 885590_2011.txt to 885590_2011.txt\n",
            "Saving 885590_2012.txt to 885590_2012.txt\n",
            "Saving 885590_2016.txt to 885590_2016.txt\n",
            "Saving 885590_2017.txt to 885590_2017.txt\n",
            "Saving 885590_2018.txt to 885590_2018.txt\n",
            "Saving 885590_2019.txt to 885590_2019.txt\n",
            "Saving 885725_1999.txt to 885725_1999.txt\n",
            "Saving 885725_2009.txt to 885725_2009.txt\n",
            "Saving 885725_2010.txt to 885725_2010.txt\n",
            "✅  Loaded 400 documents (200 Fraud / 200 Non‑Fraud)\n",
            "💾  Saved to mdna_samples.json — ready for training script\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enhanced_deberta_mdna_sliding.py — Sliding window + optimized fine‑tuning\n",
        "# ---------------------------------------------------------------\n",
        "import json, torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "\n",
        "# 0️⃣ Load preprocessed mdna_samples.json\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    mdna_samples = json.load(f)\n",
        "\n",
        "texts = [s[\"text\"] for s in mdna_samples]\n",
        "labels = [1 if s[\"true_label\"] == \"Fraud\" else 0 for s in mdna_samples]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# 1️⃣ Tokenizer and model\n",
        "model_name = \"microsoft/deberta-v3-small\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
        "model      = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# 2️⃣ Sliding-window chunking function\n",
        "def sliding_chunk_text(text, label, tokenizer, max_length=512, stride=128):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = start + max_length\n",
        "        chunk = tokens[start:end]\n",
        "        if len(chunk) < max_length:\n",
        "            chunk += [tokenizer.pad_token_id] * (max_length - len(chunk))\n",
        "        chunks.append((chunk, label))\n",
        "        if end >= len(tokens):\n",
        "            break\n",
        "        start += max_length - stride\n",
        "    return chunks\n",
        "\n",
        "# 3️⃣ Dataset class\n",
        "class ChunkedMDNADataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512, stride=128):\n",
        "        self.samples = []\n",
        "        for text, label in zip(texts, labels):\n",
        "            self.samples.extend(sliding_chunk_text(text, label, tokenizer, max_length, stride))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, label = self.samples[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(chunk),\n",
        "            \"attention_mask\": torch.tensor([1 if t != tokenizer.pad_token_id else 0 for t in chunk]),\n",
        "            \"labels\": torch.tensor(label)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "train_dataset = ChunkedMDNADataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset   = ChunkedMDNADataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "# 4️⃣ Training arguments (enhanced)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./deberta-mdna-sliding\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    label_smoothing_factor=0.1,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 5️⃣ Metrics\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=-1)\n",
        "    labels = p.label_ids\n",
        "    return {\n",
        "        \"accuracy\":  accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "        \"recall\":    recall_score(labels, preds, zero_division=0),\n",
        "        \"f1\":        f1_score(labels, preds, zero_division=0),\n",
        "    }\n",
        "\n",
        "# 6️⃣ Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# 7️⃣ Train & save\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "trainer.save_model(\"./deberta-mdna-sliding\")\n",
        "tokenizer.save_pretrained(\"./deberta-mdna-sliding\")\n",
        "print(f\"✅ DeBERTa fine-tuned and saved in {(time.time() - start)/60:.1f} min.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582,
          "referenced_widgets": [
            "1fd53271ea82463ba3e1945d453aef4b",
            "617a74191b2a461cb8eb989b166d4848",
            "0b1e6280ed394e3386b45f4bcddb2656",
            "236181175b6e46d6b5287ab3385ce4bc",
            "c0e9b08840c9408889193284ea030136",
            "34e808084836483fb1655e57dbac7f0d",
            "9ea76f6fb7a64a8ba59b754dbe662222",
            "6efb657a44a04ee486d9d5d6ba5e528d",
            "1296fd6a5828465e9118100b84384b9a",
            "8d802d4e9ef349beabdefd2a8f324bde",
            "258fdf4e7ae24a1a8bd557f9db4ba1c9",
            "9d1d83be8e604f999a8517296b24d2d4",
            "d5a37183a9fe4b9aac9de330ff7c1673",
            "b22b36245b0c47d3b34e404b84cf3130",
            "c1d2bd23e9754407b74564ddf849493c",
            "7f1013b13d9c4842875f143221235883",
            "7950f7e576224aa48039e8dbfbb4061a",
            "b1148e22f1fe496fb8c56576673169ac",
            "1f39847b954d4b3da9a320f0dd938c91",
            "89a9110a145b47ed80c8289d5bbad8b7",
            "e2501998801a4e179c05b7a57d7f639b",
            "1465cac851a549f095130ee491bc7e1a",
            "58f5b2293b6942c2a0b603e3073cfd73",
            "2b396d072e6a437c9109c9c51aadd8f3",
            "6073b26794ca4a1489961afb1bc1dd51",
            "75f34a1956d74ed083a829b38d5eb3bb",
            "2dbd35e27e7b4b8797c4087f75ea938a",
            "d32fea476cba400a8bf201706d417eed",
            "50f341a5565c4da5af29bd618ecd3030",
            "40e0c0e1597c4fa8aade0e6ef84e3d44",
            "ec8b2d6cfdda4130b1cdca468ef5c784",
            "6e6128ce6aba42fe89587362ab7652ff",
            "4d1c89e316594b87a8caa049f4ea11bb",
            "d34177b5d6ec4abc9b274ef11ba31679",
            "983085a2c22d4c3b8e191deddc404ded",
            "0785484a30a7460aa4d319071db40c18",
            "56b11fd236c84bcdbc3e103d305584f0",
            "8228f24f6fc94084a96318088b265dfa",
            "ca626e4172564d8395767a1be6f6ebd3",
            "97e60efb4e504036a2694a07ce7148f6",
            "02fa7397cb5f49f5846a7e477a3b769d",
            "7d702bd743454541bf230494abe6724e",
            "aed446d86e534e228ea50ca955a8ef9c",
            "3f26a2168b584deea2c52eac78fa18c4",
            "e0326aa31c7d4ec4bdf33e49a182fd2f",
            "266089a9e500413491cde210bd994e53",
            "70910d62aa744d90b25eed7a593affbf",
            "19ef64eb42f3498d8c3ddf48c7763f32",
            "515bee1818e04a78977a4aa893d5a388",
            "a11da735619f4dd19fed1d585b7e79af",
            "12b3ffd8a33a4c9b949e9d0b1fc6ca6d",
            "55dd62e504fc4c51b35bb8d050d9fe6d",
            "3d4fbd858d9c46e38293f6ca04565a0f",
            "3fe575068cb94cb186cf111ebef1b352",
            "37637b8c818341ef9356d91669630a6b"
          ]
        },
        "id": "IfgqGmNmfDtN",
        "outputId": "9caea91a-2512-4fa8-db05-716a90d42787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fd53271ea82463ba3e1945d453aef4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d1d83be8e604f999a8517296b24d2d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58f5b2293b6942c2a0b603e3073cfd73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d34177b5d6ec4abc9b274ef11ba31679"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0326aa31c7d4ec4bdf33e49a182fd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-2719414933.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5709' max='7612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5709/7612 14:39 < 04:53, 6.49 it/s, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>0.502846</td>\n",
              "      <td>0.851118</td>\n",
              "      <td>0.845361</td>\n",
              "      <td>0.727343</td>\n",
              "      <td>0.781924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.245800</td>\n",
              "      <td>0.505522</td>\n",
              "      <td>0.861308</td>\n",
              "      <td>0.809359</td>\n",
              "      <td>0.813729</td>\n",
              "      <td>0.811538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.233400</td>\n",
              "      <td>0.525836</td>\n",
              "      <td>0.857911</td>\n",
              "      <td>0.817166</td>\n",
              "      <td>0.789433</td>\n",
              "      <td>0.803060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DeBERTa fine-tuned and saved in 14.7 min.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import json\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Load validation data\n",
        "# ----------------------------------------\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    mdna_samples = json.load(f)\n",
        "\n",
        "texts = [s[\"text\"] for s in mdna_samples]\n",
        "labels = [1 if s[\"true_label\"] == \"Fraud\" else 0 for s in mdna_samples]\n",
        "filenames = [s[\"filename\"] for s in mdna_samples]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "_, val_texts, _, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Load fine-tuned model & tokenizer\n",
        "# ----------------------------------------\n",
        "model_path = \"./deberta-mdna-sliding\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Majority-vote inference function\n",
        "# ----------------------------------------\n",
        "def predict_document_majority(text, max_len=512):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_len):\n",
        "        chunk = tokens[i:i + max_len]\n",
        "        if len(chunk) < max_len:\n",
        "            chunk += [tokenizer.pad_token_id] * (max_len - len(chunk))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    votes = []\n",
        "    with torch.no_grad():\n",
        "        for chunk in chunks:\n",
        "            input_ids = torch.tensor(chunk).unsqueeze(0).to(device)\n",
        "            attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            pred = torch.argmax(probs, dim=1).item()\n",
        "            votes.append(pred)\n",
        "\n",
        "    return Counter(votes).most_common(1)[0][0]\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Predict on all validation texts\n",
        "# ----------------------------------------\n",
        "print(\"🔎 Predicting documents (majority vote)...\")\n",
        "val_preds = [predict_document_majority(text) for text in val_texts]\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Evaluation Metrics\n",
        "# ----------------------------------------\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(val_labels, val_preds, target_names=[\"Non-Fraud\", \"Fraud\"]))\n",
        "\n",
        "# ----------------------------------------\n",
        "# ✅ Confusion Matrix\n",
        "# ----------------------------------------\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Non-Fraud\", \"Fraud\"],\n",
        "            yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - DeBERTa (Majority Vote)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "fV6jIVXTQdio",
        "outputId": "22dfab77-3e4d-4262-9d49-adfa87d902e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 Predicting documents (majority vote)...\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Fraud       0.85      0.88      0.86        40\n",
            "       Fraud       0.87      0.85      0.86        40\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.86      0.86      0.86        80\n",
            "weighted avg       0.86      0.86      0.86        80\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAHqCAYAAAAj28XgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT+hJREFUeJzt3XlcVOX7//H3gDIgCIobmgoqpiiuWKbmlru5b6WZaGZWWrkrnzJ3UUtzSbFVzaTMXErN3Jc0tTLN3VzTcs0FwwUUzu+Pfsy3EVTQgdlezx7zeDT3Oec+10EYLq77vs8xGYZhCAAAwAl42DsAAACA9CJxAQAAToPEBQAAOA0SFwAA4DRIXAAAgNMgcQEAAE6DxAUAADgNEhcAAOA0SFwAAIDTIHFxcYcPH1bDhg0VEBAgk8mkJUuW2LT/EydOyGQyafbs2Tbt15nVqVNHderUsXcYyKDk5GSFh4drzJgxWXrekJAQde3a1aZ9btiwQSaTSRs2bLBpv87g4sWL8vX11XfffWfvUJBJSFyywNGjR9WzZ08VL15c3t7e8vf3V40aNTRlyhTduHEjU88dGRmpPXv2aMyYMZo7d66qVKmSqefLSl27dpXJZJK/v3+aX8fDhw/LZDLJZDLp3XffzXD/p0+f1vDhw7Vr1y4bRJs1QkJCLNfs4eGhXLlyqVy5cnrppZe0ffv2h+q7Tp06lr5NJpO8vLxUrFgxvfTSSzp16pTVvrNnz7ba987Xtm3bLPveuc3f31+1a9fW8uXLJf3fL+H0vB7GF198oVOnTql3795pXsfmzZtTHWMYhooUKSKTyaRmzZo91PkzW2xsrCZPnmyz/hYtWiSTyaSPP/74rvusXr1aJpNJU6dOTXe/M2bMeKg/hPLkyaMXX3xRQ4cOfeA+4Niy2TsAV7d8+XK1b99eZrNZXbp0UXh4uBITE7V582YNHDhQ+/bt04cffpgp575x44a2bt2qN9980+rD2JaCg4N148YNZc+ePVP6v59s2bLp+vXrWrp0qTp06GC1bd68efL29tbNmzcfqO/Tp09rxIgRCgkJUcWKFdN93KpVqx7ofLZSsWJF9e/fX5L0zz//6MCBA1qwYIE++ugj9e3bV5MmTXrgvgsXLqzo6GhJUmJiovbv36+ZM2dq5cqVOnDggHLkyGG1/8iRI1WsWLFU/YSGhlq9b9Cggbp06SLDMPTHH38oJiZGzZs314oVK1SxYkXNnTvXav+oqCj5+fnpzTfffOBrudM777yjZ599VgEBAam2eXt7KzY2Vk8++aRV+8aNG/Xnn3/KbDY/8HkPHTokDw/b/g1Zq1Yt3bhxQ15eXpa22NhY7d27V3369LHJOZ5++mkFBAQoNjZWL774Ypr7xMbGytPTU88++2y6+50xY4by5s37UFWol19+WVOnTtW6dev01FNPPXA/cFAGMs2xY8cMPz8/o3Tp0sbp06dTbT98+LAxefLkTDv/H3/8YUgy3nnnnUw7hz1FRkYavr6+RsOGDY1WrVql2l6yZEmjbdu2D/w1+Pnnnw1JxqxZs9K1/7Vr1zJ8DlsLDg42nn766VTt169fN1q1amVIMmbMmPFAfdeuXdsoW7Zsqvb333/fkGSsWrXK0jZr1ixDkvHzzz/ft19JRq9evaza9u/fb0gymjRpkuYxZcuWNWrXrp2xC7iHX3/91ZBkrFmzxqo95TratGlj5M2b17h165bV9h49ehgRERF3/bpntRs3bhhJSUlpbnv66aeN4OBgm56ve/fuhoeHh/HXX3+lGUtAQIDRuHHjDPVpq3/b8PBw4/nnn3/ofuB4GCrKRBMmTFB8fLw++eQTFSxYMNX20NBQvfHGG5b3t2/f1qhRo1SiRAmZzWaFhITof//7nxISEqyOCwkJUbNmzbR582Y9/vjj8vb2VvHixfXZZ59Z9hk+fLiCg4MlSQMHDpTJZFJISIikf4dYUv7/v4YPH56q3L569Wo9+eSTypUrl/z8/FSqVCn973//s2y/2xyXdevWqWbNmvL19VWuXLnUsmVLHThwIM3zHTlyRF27dlWuXLkUEBCgbt266fr163f/wt6hU6dOWrFiha5cuWJp+/nnn3X48GF16tQp1f6XLl3SgAEDVK5cOfn5+cnf319NmjTRb7/9Ztlnw4YNeuyxxyRJ3bp1swwXpFxnnTp1FB4erh07dqhWrVrKkSOH5ety5xyXyMhIeXt7p7r+Ro0aKXfu3Dp9+nS6r/VB+fj4aO7cuQoMDNSYMWNk/Oeh8MnJyZo8ebLKli0rb29vFShQQD179tTly5fT1XdQUJCkf6tfthIWFqa8efPq6NGj6do/MTFRb7/9tiIiIhQQECBfX1/VrFlT69evT9fxS5YskZeXl2rVqpXm9o4dO+rixYtavXq11Tm//vrrNL/HJOndd99V9erVlSdPHvn4+CgiIkJff/11qv3SmuNy7NgxtW/fXoGBgcqRI4eeeOIJy9BZipQhtC+//FJvvfWWHnnkEeXIkUNXr15NNcelTp06Wr58uf744w/L93JISIji4+Pl6+tr9TmU4s8//5Snp6elwpaWzp07Kzk5WV9++WWqbcuXL1dcXJyee+45Sen7fAsJCdG+ffu0ceNGS5z//Vm6cuWK+vTpoyJFishsNis0NFTjx49XcnJyqvM3aNBAS5cutfpeh2sgcclES5cuVfHixVW9evV07f/iiy/q7bffVuXKlfXee++pdu3aio6OTrPMeuTIEbVr104NGjTQxIkTlTt3bnXt2lX79u2TJLVp00bvvfeepH8/dOfOnZvh8e19+/apWbNmSkhI0MiRIzVx4kS1aNFCW7Zsuedxa9asUaNGjXT+/HkNHz5c/fr1048//qgaNWroxIkTqfbv0KGD/vnnH0VHR6tDhw6aPXu2RowYke4427RpI5PJpEWLFlnaYmNjVbp0aVWuXDnV/seOHdOSJUvUrFkzTZo0SQMHDtSePXtUu3ZtSxIRFhamkSNHSpJeeuklzZ07V3PnzrX6xXbx4kU1adJEFStW1OTJk1W3bt0045syZYry5cunyMhIJSUlSZI++OADrVq1StOmTVOhQoXSfa0Pw8/PT61bt9Zff/2l/fv3W9p79uypgQMHWuZddevWTfPmzVOjRo1069Ytqz6SkpL0999/6++//9aZM2e0bt06DRs2TKGhoapRo0aqc8bFxVn2T3ldvHjxvrHGxcXp8uXLyp07d7qu7erVq/r4449Vp04djR8/XsOHD9eFCxfUqFGjdM1R+vHHHxUeHn7XIc+QkBBVq1ZNX3zxhaVtxYoViouLu+swyJQpU1SpUiWNHDlSY8eOVbZs2dS+fftUCcidzp07p+rVq2vlypV69dVXNWbMGN28eVMtWrTQ4sWLU+0/atQoLV++XAMGDNDYsWOthodSvPnmm6pYsaLy5s1r+V6ePHmy5Xti/vz5lu/NFF988YUMw7AkHmmpVauWChcurNjY2FTbYmNjlSNHDrVq1UpS+j7fJk+erMKFC6t06dKWOFOGA69fv67atWvr888/V5cuXTR16lTVqFFDUVFR6tevX6rzR0RE6MqVK5bPRLgQO1d8XFZcXJwhyWjZsmW69t+1a5chyXjxxRet2gcMGGBIMtatW2dpCw4ONiQZmzZtsrSdP3/eMJvNRv/+/S1tx48fT3OYJDIyMs2S8bBhw4z/fku89957hiTjwoULd4075Rz/HU6pWLGikT9/fuPixYuWtt9++83w8PAwunTpkup8L7zwglWfrVu3NvLkyXPXc/73Onx9fQ3DMIx27doZ9erVMwzDMJKSkoygoCBjxIgRaX4Nbt68maqcfvz4ccNsNhsjR460tN1rqKh27dqGJGPmzJlpbruz1L1y5UpDkjF69GjLEGJaw1sP635DFin/pt98841hGIbxww8/GJKMefPmWe33/fffp2pPueY7X2FhYcaxY8esjk8ZYknrZTabrfaVZHTv3t24cOGCcf78eeOXX34xGjdufM8hvjuHE27fvm0kJCRY7XP58mWjQIECqb6/0lK4cGGjbdu2qdr/O+T1/vvvGzlz5jSuX79uGIZhtG/f3qhbt65hGGl/3VP2S5GYmGiEh4cbTz31lFV7cHCwERkZaXnfp08fQ5Lxww8/WNr++ecfo1ixYkZISIjle3f9+vWGJKN48eKpzpWybf369Za2uw0VpXxvrlixwqq9fPny6RqyGThwoCHJOHTokKUtLi7O8Pb2Njp27GgYRsY+3+42VDRq1CjD19fX+P33363ahwwZYnh6ehonT560av/xxx8NScb8+fPvew1wLlRcMsnVq1clSTlz5kzX/ilL9+78yyFlkuWdf6WVKVNGNWvWtLzPly+fSpUqpWPHjj1wzHfKlSuXJOmbb75JsxSbljNnzmjXrl3q2rWrAgMDLe3ly5dXgwYN0lyi+PLLL1u9r1mzpi5evGj5GqZHp06dtGHDBp09e1br1q3T2bNn71rCN5vNlsmQSUlJunjxomUY7Ndff033Oc1ms7p165aufRs2bKiePXtq5MiRatOmjby9vfXBBx+k+1y24ufnJ+nfSbuStGDBAgUEBKhBgwZWVZGIiAj5+fmlGmoJCQnR6tWrtXr1aq1YsUKTJ09WXFycmjRpogsXLqQ63/Tp0y37//e4O33yySfKly+f8ufPrypVqmjt2rUaNGhQmn9Jp8XT09NSaUhOTtalS5d0+/ZtValSJV3/phcvXrxvdadDhw66ceOGli1bpn/++UfLli276/eY9O/wXIrLly8rLi5ONWvWvG883333nR5//HGricB+fn566aWXdOLECatqmfTvUOR/z5VR9evXV6FChTRv3jxL2969e7V792517tz5vsen7PPfqsvChQt18+ZNS7Umo59vaVmwYIFq1qyp3LlzW32v1q9fX0lJSdq0aZPV/in/nn///fd9+4ZzYVVRJvH395f0f78g7uePP/6Qh4dHqtUWQUFBypUrl/744w+r9qJFi6bqI3fu3Omel5AezzzzjD7++GO9+OKLGjJkiOrVq6c2bdqoXbt2d10FkRJnqVKlUm0LCwvTypUrde3aNfn6+lra77yWlA+cy5cvW76O99O0aVPlzJlT8+fP165du/TYY48pNDQ0zaGp5ORkTZkyRTNmzNDx48etSuR58uRJ1/kk6ZFHHkmzLH837777rr755hvt2rVLsbGxyp8//32PuXDhglV8fn5+luTjQcTHx0v6v4T68OHDiouLu2ss58+ft3rv6+ur+vXrW943btxYTz75pKpUqaJx48Zp4sSJVvs//vjj6VqC37JlS/Xu3VuJiYn6+eefNXbsWF2/fj1Dq23mzJmjiRMn6uDBg1ZDXGmtakqLcZ+5EPny5VP9+vUVGxur69evKykpSe3atbvr/suWLdPo0aO1a9cuq3kc91u2/ccff6hq1aqp2sPCwizbw8PDLe3pvb678fDw0HPPPaeYmBhdv35dOXLksKzIa9++/X2PL1++vMLDw/XFF19o+PDhkv5NYvLmzatGjRpZYs7I51taDh8+rN27dytfvnxpbr/zezXl3/Nhl8nD8ZC4ZBJ/f38VKlRIe/fuzdBx6f0h8/T0TLP9fh++9zrHnWPcPj4+2rRpk9avX6/ly5fr+++/1/z58/XUU09p1apVd40hox7mWlKYzWa1adNGc+bM0bFjxywfoGkZO3ashg4dqhdeeEGjRo1SYGCgPDw81KdPn3RXliRl+K/cnTt3Wj5c9+zZo44dO973mMcee8zqQ33YsGH3vLb7Sfl+TPkFkpycrPz581v9tf1fd/sl8V8pE2Lv/Is3IwoXLmxJiJo2baq8efOqd+/eqlu3rtq0aXPf4z///HN17dpVrVq10sCBA5U/f37LxNL0TPDNkydPupL+Tp06qUePHjp79qyaNGliqUre6YcfflCLFi1Uq1YtzZgxQwULFlT27Nk1a9asNOeDPIyHqbak6NKli9555x0tWbJEHTt2VGxsrJo1a5bm0vC0dO7cWUOGDNEvv/yiwoULa/369erZs2eqCdsPk0QkJyerQYMGGjRoUJrbH330Uav3Kf+eefPmfeBzwjGRuGSiZs2a6cMPP9TWrVtVrVq1e+4bHBys5ORkHT582PKXlfTvRL0rV65YVgjZQu7cua1W4KRI668eDw8P1atXT/Xq1dOkSZM0duxYvfnmm1q/fr3VX97/vQ7p33tT3OngwYPKmzevVbXFljp16qRPP/1UHh4e97xvxNdff626devqk08+sWq/cuWK1YecLf9Su3btmrp166YyZcqoevXqmjBhglq3bm1ZuXQ38+bNs7q5XvHixR84hvj4eC1evFhFihSxfI+VKFFCa9asUY0aNR7qF2BSUpKlmmMLPXv21Hvvvae33npLrVu3vu+/xddff63ixYtbboqWYtiwYek6X+nSpXX8+PH77te6dWv17NlT27Zt0/z58++638KFC+Xt7a2VK1da3eNl1qxZ9z1HcHDwXX9+UrY/iHt9DcPDw1WpUiXNmzdPhQsX1smTJzVt2rR0992xY0dFRUUpNjZWwcHBSkpKsprUm5HPt7vFWaJECcXHx6f5uZOWlH/P/54ProE5Lplo0KBB8vX11Ysvvqhz586l2n706FFNmTJF0r9/ZUpKtfIn5WZhTz/9tM3iKlGihOLi4rR7925L25kzZ1KtWLh06VKqY1NuxHbnEu0UBQsWVMWKFTVnzhyr5Gjv3r1atWqV5TozQ926dTVq1Ci9//77liW6afH09ExVzVmwYIH++usvq7aUBCutJC+jBg8erJMnT2rOnDmaNGmSQkJCFBkZedevY4oaNWqofv36lteDJi43btzQ888/r0uXLunNN9+0/HLo0KGDkpKSNGrUqFTH3L59O13Xvn79esXHx6tChQoPFFtasmXLpv79++vAgQP65ptv7rt/StXuv/+u27dv19atW9N1vmrVqmnv3r33/ffw8/NTTEyMhg8frubNm98zHpPJZFXFPHHiRLoeudG0aVP99NNPVrFfu3ZNH374oUJCQlSmTJn7X1AafH19FRcXd9ftzz//vFatWqXJkycrT548atKkSbr7Llq0qGrWrKn58+fr888/V7FixaxWU2bk883X1zfN77sOHTpo69atWrlyZaptV65c0e3bt63aduzYoYCAAJUtWzbd1wHnQMUlE5UoUUKxsbF65plnFBYWZnXn3B9//FELFiyw3L+hQoUKioyM1IcffqgrV66odu3a+umnnzRnzhy1atXqrkttH8Szzz6rwYMHq3Xr1nr99dd1/fp1xcTE6NFHH7WaODhy5Eht2rRJTz/9tIKDg3X+/HnNmDFDhQsXTnUH0f9655131KRJE1WrVk3du3fXjRs3NG3aNAUEBDzUMMf9eHh46K233rrvfs2aNdPIkSPVrVs3Va9eXXv27NG8efNSJQUlSpRQrly5NHPmTOXMmVO+vr6qWrVqhucUrFu3TjNmzNCwYcMsy7NnzZqlOnXqaOjQoZowYUKG+rufv/76S59//rmkf6ss+/fv14IFC3T27Fn1799fPXv2tOxbu3Zt9ezZU9HR0dq1a5caNmyo7Nmz6/Dhw1qwYIGmTJliNY8jLi7O0vft27d16NAhxcTEyMfHR0OGDEkVy4oVKyyVgv+qXr36fZOwrl276u2339b48eMtS2rvplmzZlq0aJFat26tp59+WsePH9fMmTNVpkyZdFWCWrZsqVGjRmnjxo1q2LDhPfeNjIy8b39PP/20Jk2apMaNG6tTp046f/68pk+frtDQUKs/GNIyZMgQffHFF2rSpIlef/11BQYGas6cOTp+/LgWLlz4wHfZjYiI0Pz589WvXz899thj8vPzs0q+OnXqpEGDBmnx4sV65ZVXMnw37M6dO+ull17S6dOnU93ROCOfbxEREYqJidHo0aMVGhqq/Pnz66mnntLAgQP17bffqlmzZuratasiIiJ07do17dmzR19//bVOnDhhVTFdvXq1mjdvzhwXV2TPJU3u4vfffzd69OhhhISEGF5eXkbOnDmNGjVqGNOmTTNu3rxp2e/WrVvGiBEjjGLFihnZs2c3ihQpYkRFRVntYxh3X/J65zLcuy2HNgzDWLVqlREeHm54eXkZpUqVMj7//PNUy6HXrl1rtGzZ0ihUqJDh5eVlFCpUyOjYsaPVcsS0lkMbhmGsWbPGqFGjhuHj42P4+/sbzZs3N/bv32+1T8r57lxunbIE9fjx43f9mhqG9XLou7nbcuj+/fsbBQsWNHx8fIwaNWoYW7duTXMZ8zfffGOUKVPGyJYtm9V13u0usinbUvq5evWqERwcbFSuXDnVXVf79u1reHh4GFu3br3nNWREylJ5SYbJZDL8/f2NsmXLGj169DC2b99+1+M+/PBDIyIiwvDx8TFy5sxplCtXzhg0aJDVHZ/vXA5tMpmMwMBAo0WLFsaOHTus+rvXcug7v1+Uxp1zUwwfPjzVsl7DSL1kNjk52Rg7dqwRHBxsmM1mo1KlSsayZcvuuvQ/LeXLlze6d++e5nXc7w7Aaf1MfvLJJ0bJkiUNs9lslC5d2pg1a1aqn7GUY/+7HNowDOPo0aNGu3btjFy5chne3t7G448/bixbtsxqn5QlzwsWLEgVT1rLoePj441OnToZuXLlMiSl+XVp2rSpIcn48ccf73m9abl06ZJhNpsNSal+1g0j/Z9vZ8+eNZ5++mkjZ86chiSrf+d//vnHiIqKMkJDQw0vLy8jb968RvXq1Y13333XSExMtOx34MCBNO+EDNdgMgxuKwgAc+fOVa9evXTy5Mm7TrrNDEWKFFGjRo3u+bDCrNK6dWvt2bNHR44csXcoD6VPnz7atGmTduzYQcXFBTHHBQAkPffccypatKimT5+eZee8deuWLl686BArX86cOaPly5fr+eeft3coD+XixYv6+OOPNXr0aJIWF8UcFwDQv3OkMnr7goexcuVKffnll7px44bq1auXZee90/Hjx7VlyxZ9/PHHyp49u9UcKGeUJ08em65wg+MhcQEAOxg3bpyOHDmiMWPGqEGDBnaLY+PGjerWrZuKFi2qOXPm3HNFHuAImOMCAAAeWkxMjGJiYix3LC9btqzefvtty9L6OnXqaOPGjVbH9OzZUzNnzszQeUhcAADAQ1u6dKk8PT1VsmRJGYahOXPm6J133tHOnTtVtmxZ1alTR48++qhGjhxpOSZHjhzpfrRLCoaKAADAQ7vzpoxjxoxRTEyMtm3bZrkRYI4cOR56OJJVRQAAIE0JCQm6evWq1et+d5iW/n0MyJdffqlr165ZPfJm3rx5yps3r8LDwxUVFaXr169nOCaXrLj4VOpt7xAAl3D55/ftHQLgEryz6LetrX//DW6ZVyNGjLBqu9fDXvfs2aNq1arp5s2b8vPz0+LFiy2PqejUqZOCg4NVqFAh7d69W4MHD9ahQ4e0aNGiDMXkknNcSFwA2yBxAWzDWROXK9smpqqwmM1mq4eH/ldiYqJOnjypuLg4ff311/r444+1cePGNJ+xtW7dOtWrV09HjhxRiRIl0h2TS1ZcAABwSybbzgC5V5KSFi8vL4WGhkr697lTP//8s6ZMmaIPPvgg1b5Vq1aVJBIXAADcloPdLTg5Ofmuc2J27dolSSpYsGCG+iRxAQAADy0qKkpNmjRR0aJF9c8//yg2NlYbNmzQypUrdfToUcXGxqpp06bKkyePdu/erb59+6pWrVoqX758hs5D4gIAgKuw8VBRRpw/f15dunTRmTNnFBAQoPLly2vlypVq0KCBTp06pTVr1mjy5Mm6du2aihQporZt2+qtt97K8HlIXAAAwEP75JNP7rqtSJEiqe6a+6BIXAAAcBUONsclM5C4AADgKuw4VJRVXP8KAQCAy6DiAgCAq2CoCAAAOA2GigAAABwHFRcAAFyFGwwVUXEBAABOg4oLAACuwg3muJC4AADgKhgqAgAAcBxUXAAAcBUMFQEAAKfBUBEAAIDjoOICAICrYKgIAAA4DTdIXFz/CgEAgMug4gIAgKvwYHIuAACAw6DiAgCAq3CDOS4kLgAAuAru4wIAAOA4qLgAAOAqGCoCAABOg6EiAAAAx0HFBQAAV+EGQ0Wuf4UAAMBlUHEBAMBVuMEcFxIXAABcBUNFAAAAjoOKCwAAroKhIgAA4DQYKgIAAHAcVFwAAHAVDBUBAACnwVARAACA46DiAgCAq6DiAgAA4DiouAAA4CqYnAsAAJwGQ0UAAACOg4oLAACugqEiAADgNBgqAgAAcBxUXAAAcBUMFQEAAGdhcoPEhaEiAADgNKi4AADgIqi4AAAAOBAqLgAAuArXL7iQuAAA4CoYKgIAAHAgVFwAAHAR7lBxIXEBAMBFuEPiwlARAABwGlRcAABwEVRcAAAA0iEmJkbly5eXv7+//P39Va1aNa1YscKy/ebNm+rVq5fy5MkjPz8/tW3bVufOncvweUhcAABwFSYbvzKgcOHCGjdunHbs2KFffvlFTz31lFq2bKl9+/ZJkvr27aulS5dqwYIF2rhxo06fPq02bdpk/BINwzAyfJSD86nU294hAC7h8s/v2zsEwCV4Z9HEjFzPfW7T/q7M6/xQxwcGBuqdd95Ru3btlC9fPsXGxqpdu3aSpIMHDyosLExbt27VE088ke4+qbgAAACbSkpK0pdffqlr166pWrVq2rFjh27duqX69etb9ildurSKFi2qrVu3ZqhvJucCAOAibD05NyEhQQkJCVZtZrNZZrM5zf337NmjatWq6ebNm/Lz89PixYtVpkwZ7dq1S15eXsqVK5fV/gUKFNDZs2czFBMVFwAAXITJZLLpKzo6WgEBAVav6Ojou56/VKlS2rVrl7Zv365XXnlFkZGR2r9/v02v0W4Vl927d6d73/Lly2diJAAAIC1RUVHq16+fVdvdqi2S5OXlpdDQUElSRESEfv75Z02ZMkXPPPOMEhMTdeXKFauqy7lz5xQUFJShmOyWuFSsWFEmk0mGYdy3tJWUlJRFUQEA4LxsPVR0r2Gh9EhOTlZCQoIiIiKUPXt2rV27Vm3btpUkHTp0SCdPnlS1atUy1KfdEpfjx49b/n/nzp0aMGCABg4caLmArVu3auLEiZowYYK9QgQAwLnY8f5zUVFRatKkiYoWLap//vlHsbGx2rBhg1auXKmAgAB1795d/fr1U2BgoPz9/fXaa6+pWrVqGVpRJNkxcQkODrb8f/v27TV16lQ1bdrU0la+fHkVKVJEQ4cOVatWrewQIQAASK/z58+rS5cuOnPmjAICAlS+fHmtXLlSDRo0kCS999578vDwUNu2bZWQkKBGjRppxowZGT6PQ9zHxcfHR7/++qvCwsKs2g8cOKDKlSvrxo0bGeuP+7gANsF9XADbyKr7uOTt+qVN+/t79rM27c8WHGJVUVhYmKKjo5WYmGhpS0xMVHR0dKpkBgAAuC+HuI/LzJkz1bx5cxUuXNiygmj37t0ymUxaunSpnaMDAMA5uMNDFh0icXn88cd17NgxzZs3TwcPHpQkPfPMM+rUqZN8fX3tHB0AAM6BxCUL+fr66qWXXrJ3GAAAwIE5ROLy2Wef3XN7ly5dsigSAACcmOsXXBwjcXnjjTes3t+6dUvXr1+Xl5eXcuTIQeICAEA6uMNQkUOsKrp8+bLVKz4+XocOHdKTTz6pL774wt7hAQAAB+EQiUtaSpYsqXHjxqWqxgAAgLTZ+iGLjsghhoruJlu2bDp9+rS9wwAAwCk4arJhSw6RuHz77bdW7w3D0JkzZ/T++++rRo0adooKAAA4GodIXO58FpHJZFK+fPn01FNPaeLEifYJCgAAJ0PFJYskJyfbOwQAAOAEHCJxAQAANuD6BRfHSVz+/PNPffvttzp58qTVwxYladKkSXaKCgAA58FQURZZu3atWrRooeLFi+vgwYMKDw/XiRMnZBiGKleubO/wAACAg3CI+7hERUVpwIAB2rNnj7y9vbVw4UKdOnVKtWvXVvv27e0dHgAATsEd7uPiEInLgQMHLLf1z5Ytm27cuCE/Pz+NHDlS48ePt3N0AAA4BxKXLOLr62uZ11KwYEEdPXrUsu3vv/+2V1gAAMDBOMQclyeeeEKbN29WWFiYmjZtqv79+2vPnj1atGiRnnjiCXuHBwCAc3DMIolNOUTiMmnSJMXHx0uSRowYofj4eM2fP18lS5ZkRREAALCwe+KSlJSkP//8U+XLl5f077DRzJkz7RwVAADOx1HnpdiS3RMXT09PNWzYUAcOHFCuXLnsHQ5sqEf7J9WjXU0FFwqUJB04dlZjP1yhVVv2S5JWfvSGalUpaXXMR19v1utjvszyWAFnEjN9mmbOeN+qLaRYMX2z7Hs7RQRHQeKSRcLDw3Xs2DEVK1bM3qHAhv46d0VDp32jIycvyCSTOjevqgXvvaQnnh2nA8fOSpI+WbhFo2KWWY65fvOWvcIFnEqJ0JL68ONZlvee2TztGA2QdRwicRk9erQGDBigUaNGKSIiQr6+vlbb/f397RQZHsZ3m/ZavR8+fal6tH9Sj5cvZklcbtxM1LmL/9gjPMCpZfP0VN58+ewdBhwMFZcs0rRpU0lSixYtrL7ohmHIZDIpKSnJXqHBRjw8TGrboLJ8fby0ffdxS/szTavo2aaP6dzFq/pu015Ff7RCN6i6APf1x8k/VL/Ok/Iym1WhQkW93qe/ChYqZO+wYGckLllk/fr19g4BmaRsaCFtmNNf3l7ZFH8jQc/0/0gH/3+1Zf6KX3TyzCWduRCnciULafQbLfVocH49O+BjO0cNOLZy5ctr1JhohYQU04ULF/RBzHR16/KcFn6zVL6+fvYOD8hUJsMwDHudvEuXLpo+fbpy5swpSfrtt99UpkwZZc+ePd19JCQkKCEhwaotf83BMnkw3usIsmfzVJGCuRXg56PW9Supa+tqavjiFEvy8l+1H3tU33/4uso0H67jf3LjQUdw+ef3778T7O7q1atq0qCu+g8aojZteUyKI/LOojJBsb7Lbdrf8feetml/tmDXO+fOmzdPN27csLyvWbOmTp06laE+oqOjFRAQYPW6fW6HrUPFA7p1O0nHTv2tnQdO6e1p32rP73+pV8c6ae77854TkqQSRRi3BzLC399fwcEhOnXypL1DgZ1xy/9Mdmex50GKP1FRUYqLi7N6ZSsQYasQYWMeJpPMXmn/6VGhVGFJ0tm/47IyJMDpXb92TadOnWKyLtyCQ8xxeRhms1lms9mqjWEixzDytRZauWWfTp25rJy+3nqmSRXVqlJSzV+doWKF8+qZJlW0cvM+XbxyTeUefUQT+rfRDzsOa+/h0/YOHXBoE98Zr9p16qpgoUK6cP68YqZPk6enh5o0bWbv0GBnjlolsSW7Jy779+/X2bP/zncwDEMHDx603P4/RcpddeFc8gX66ZNRXRSU119x8Te19/Bfav7qDK3bflCFC+TSU1VLqXenuvL18dKf5y5rydpdGvfxSnuHDTi8c+fOasjAfrpy5YpyBwaqUuUIzY39SoGBgfYODch0dp2c6+HhIZPJlOYQUUr7gyyH9qnU21YhAm6NybmAbWTV5NzQASts2t+Rd5vYtD9bsGvF5fjx4/ffCQAApAtDRZksODjYnqcHAABOxq6ritJSrly5DC+JBgAAkslk25cjsvvk3DudOHFCt25xy3cAADLKHYaKHK7iAgAAcDcOV3GpWbOmfHx87B0GAABOxw0KLo6XuHz33Xf2DgEAAKfk4eH6mYvDJC6HDx/W+vXrdf78eSUnJ1tte/vtt+0UFQAAcCQOkbh89NFHeuWVV5Q3b14FBQVZTS4ymUwkLgAApANDRVlk9OjRGjNmjAYPHmzvUAAAgANziMTl8uXLat++vb3DAADAqbEcOou0b99eq1atsncYAAA4NW5Al0VCQ0M1dOhQbdu2TeXKlVP27Nmttr/++ut2igwAADgSuz4dOkWxYsXuus1kMunYsWMZ6o+nQwO2wdOhAdvIqqdDl397jU372z2yvk37swWHqLjwlGgAAB4ec1zswDAMOUARCAAAOCCHSVw+++wzlStXTj4+PvLx8VH58uU1d+5ce4cFAIDTYHJuFpk0aZKGDh2q3r17q0aNGpKkzZs36+WXX9bff/+tvn372jlCAADgCBwicZk2bZpiYmLUpUsXS1uLFi1UtmxZDR8+nMQFAIB0cIc5Lg6RuJw5c0bVq1dP1V69enWdOXPGDhEBAOB83CBvcYw5LqGhofrqq69Stc+fP18lS5a0Q0QAAMAROUTFZcSIEXrmmWe0adMmyxyXLVu2aO3atWkmNAAAIDWGirJI27ZttX37dk2aNElLliyRJIWFhemnn35SpUqV7BscAABOwg3yFsdIXCQpIiJC8+bNs3cYAADAgdk1cfHw8LhvWctkMun27dtZFBEAAM6LoaJMtnjx4rtu27p1q6ZOnark5OQsjAgAAOdlz7wlOjpaixYt0sGDB+Xj46Pq1atr/PjxKlWqlGWfOnXqaOPGjVbH9ezZUzNnzkz3eeyauLRs2TJV26FDhzRkyBAtXbpUzz33nEaOHGmHyAAAQEZs3LhRvXr10mOPPabbt2/rf//7nxo2bKj9+/fL19fXsl+PHj2sfrfnyJEjQ+dxmDkup0+f1rBhwzRnzhw1atRIu3btUnh4uL3DAgDAadhzqOj777+3ej979mzlz59fO3bsUK1atSztOXLkUFBQ0AOfx+73cYmLi9PgwYMVGhqqffv2ae3atVq6dClJCwAAdpaQkKCrV69avRISEtJ1bFxcnCQpMDDQqn3evHnKmzevwsPDFRUVpevXr2coJrsmLhMmTFDx4sW1bNkyffHFF/rxxx9Vs2ZNe4YEAIDTsvVDFqOjoxUQEGD1io6Ovm8cycnJ6tOnj2rUqGFViOjUqZM+//xzrV+/XlFRUZo7d646d+6csWs0DMPI8FfGRjw8POTj46P69evL09PzrvstWrQoQ/36VOr9sKEBkHT55/ftHQLgEryzaGJGtfGbbNrfhj5VU1VYzGazzGbzPY975ZVXtGLFCm3evFmFCxe+637r1q1TvXr1dOTIEZUoUSJdMdl1jkuXLl3cYukWAADOKD1Jyp169+6tZcuWadOmTfdMWiSpatWqkuQ8icvs2bPteXoAAFyKPWsBhmHotdde0+LFi7VhwwYVK1bsvsfs2rVLklSwYMF0n8dhVhUBAICHY89RjF69eik2NlbffPONcubMqbNnz0qSAgIC5OPjo6NHjyo2NlZNmzZVnjx5tHv3bvXt21e1atVS+fLl030eEhcAAPDQYmJiJP17k7n/mjVrlrp27SovLy+tWbNGkydP1rVr11SkSBG1bdtWb731VobOQ+ICAICLsPdQ0b0UKVIk1V1zH4Td7+MCAACQXlRcAABwEe6wUpfEBQAAF+EOiQtDRQAAwGlQcQEAwEW4QcGFxAUAAFfBUBEAAIADoeICAICLcIOCC4kLAACugqEiAAAAB0LFBQAAF+EGBRcqLgAAwHlQcQEAwEV4uEHJhcQFAAAX4QZ5C0NFAADAeVBxAQDARbjDcmgSFwAAXISH6+ctDBUBAADnQcUFAAAXwVARAABwGm6QtzBUBAAAnAcVFwAAXIRJrl9yoeICAACcBhUXAABchDsshyZxAQDARbjDqiKGigAAgNOg4gIAgItwg4ILiQsAAK7Cww0yF4aKAACA06DiAgCAi3CDggsVFwAA4DyouAAA4CLcYTk0iQsAAC7CDfIWhooAAIDzoOICAICLcIfl0CQuAAC4CNdPWxgqAgAAToSKCwAALoJVRQAAwGl4uH7ewlARAABwHlRcAABwEe4wVETFBQAAOA0qLgAAuAg3KLiQuAAA4CoYKgIAAHAgVFwAAHAR7rAcmsQFAAAXwVDRXfzwww/q3LmzqlWrpr/++kuSNHfuXG3evNmmwQEAAPxXhhOXhQsXqlGjRvLx8dHOnTuVkJAgSYqLi9PYsWNtHiAAAEgfk41fjijDicvo0aM1c+ZMffTRR8qePbulvUaNGvr1119tGhwAAEg/D5PJpi9HlOHE5dChQ6pVq1aq9oCAAF25csUWMQEAAKQpw4lLUFCQjhw5kqp98+bNKl68uE2CAgAAGWcy2fbliDKcuPTo0UNvvPGGtm/fLpPJpNOnT2vevHkaMGCAXnnllcyIEQAAQNIDLIceMmSIkpOTVa9ePV2/fl21atWS2WzWgAED9Nprr2VGjAAAIB3cYTl0hhMXk8mkN998UwMHDtSRI0cUHx+vMmXKyM/PLzPiAwAA6eQGecuD34DOy8tLZcqUsWUsAAAA95ThxKVu3br3LEWtW7fuoQICAAAPxp5LmKOjo7Vo0SIdPHhQPj4+ql69usaPH69SpUpZ9rl586b69++vL7/8UgkJCWrUqJFmzJihAgUKpPs8GZ6cW7FiRVWoUMHyKlOmjBITE/Xrr7+qXLlyGe0OAADYiD1XFW3cuFG9evXStm3btHr1at26dUsNGzbUtWvXLPv07dtXS5cu1YIFC7Rx40adPn1abdq0ydB5Mlxxee+999JsHz58uOLj4zPaHQAAcAHff/+91fvZs2crf/782rFjh2rVqqW4uDh98sknio2N1VNPPSVJmjVrlsLCwrRt2zY98cQT6TrPAz2rKC2dO3fWp59+aqvuAABABplMJpu+HkZcXJwkKTAwUJK0Y8cO3bp1S/Xr17fsU7p0aRUtWlRbt25Nd782ezr01q1b5e3tbavuAACAnSUkJFieSZjCbDbLbDbf87jk5GT16dNHNWrUUHh4uCTp7Nmz8vLyUq5cuaz2LVCggM6ePZvumDKcuNw5FmUYhs6cOaNffvlFQ4cOzWh3meLc1qn2DgFwCblrDrF3CIBLuLF1XJacx2bDKP9fdHS0RowYYdU2bNgwDR8+/J7H9erVS3v37tXmzZttHNEDJC4BAQFW7z08PFSqVCmNHDlSDRs2tFlgAAAgY2x9A7qoqCj169fPqu1+1ZbevXtr2bJl2rRpkwoXLmxpDwoKUmJioq5cuWJVdTl37pyCgoLSHVOGEpekpCR169ZN5cqVU+7cuTNyKAAAcDLpGRZKYRiGXnvtNS1evFgbNmxQsWLFrLZHREQoe/bsWrt2rdq2bSvp3wc3nzx5UtWqVUt3TBlKXDw9PdWwYUMdOHCAxAUAAAfjYcc75/bq1UuxsbH65ptvlDNnTsu8lYCAAPn4+CggIEDdu3dXv379FBgYKH9/f7322muqVq1aulcUSQ8wVBQeHq5jx46lyqQAAIB92TNxiYmJkSTVqVPHqn3WrFnq2rWrpH9vqeLh4aG2bdta3YAuIzKcuIwePVoDBgzQqFGjFBERIV9fX6vt/v7+Ge0SAAA4OcMw7ruPt7e3pk+frunTpz/wedKduIwcOVL9+/dX06ZNJUktWrSwmgRkGIZMJpOSkpIeOBgAAPDgeDr0f4wYMUIvv/yy1q9fn5nxAACAB2TPoaKsku7EJaUEVLt27UwLBgAA4F4yNMfFHUpQAAA4K3f4NZ2hxOXRRx+9b/Jy6dKlhwoIAADgbjKUuIwYMSLVnXMBAIBj8HCDkkuGEpdnn31W+fPnz6xYAADAQ7D1s4ocUbqvkfktAADA3jK8qggAADgmd6gxpDtxSU5Ozsw4AADAQ3KHOS7uMBwGAABcRIafVQQAAByTGxRcSFwAAHAV7nDLf4aKAACA06DiAgCAi2ByLgAAgAOh4gIAgItwg4ILiQsAAK6CybkAAAAOhIoLAAAuwiTXL7mQuAAA4CIYKgIAAHAgVFwAAHARVFwAAAAcCBUXAABchMkNbuRC4gIAgItgqAgAAMCBUHEBAMBFuMFIEYkLAACugqdDAwAAOBAqLgAAuAh3mJxL4gIAgItwg5EihooAAIDzoOICAICL8HCDp0NTcQEAAE6DigsAAC7CHea4kLgAAOAi3GFVEUNFAADAaVBxAQDARbjDnXNJXAAAcBFukLcwVAQAAJwHFRcAAFwEQ0UAAMBpuEHewlARAABwHlRcAABwEe5QjXCHawQAAC6CigsAAC7C5AaTXEhcAABwEa6ftjBUBAAAnAgVFwAAXAT3cQEAAE7D9dMWhooAAIAToeICAICLcIORIiouAADAeVBxAQDARXAfFwAA4DTcYRjFHa4RAABksk2bNql58+YqVKiQTCaTlixZYrW9a9euMplMVq/GjRtn+DxUXAAAcBH2HCq6du2aKlSooBdeeEFt2rRJc5/GjRtr1qxZlvdmsznD5yFxAQDARdhzhkuTJk3UpEmTe+5jNpsVFBT0UOdhqAgAAGSJDRs2KH/+/CpVqpReeeUVXbx4McN9UHEBAMBF2HqoKCEhQQkJCVZtZrP5gYZ4GjdurDZt2qhYsWI6evSo/ve//6lJkybaunWrPD09090PFRcAAFyEh41f0dHRCggIsHpFR0c/UGzPPvusWrRooXLlyqlVq1ZatmyZfv75Z23YsCHD1wgAAJBKVFSU4uLirF5RUVE26bt48eLKmzevjhw5kqHjGCoCAMBF2Hqo6EGHhdLjzz//1MWLF1WwYMEMHUfiAgAAHlp8fLxV9eT48ePatWuXAgMDFRgYqBEjRqht27YKCgrS0aNHNWjQIIWGhqpRo0YZOg+JCwAALsKey6F/+eUX1a1b1/K+X79+kqTIyEjFxMRo9+7dmjNnjq5cuaJChQqpYcOGGjVqVIYrOiQuAAC4CHs+qqhOnToyDOOu21euXGmT8zA5FwAAOA0qLgAAuAgPuw4WZQ0SFwAAXIQ9h4qyCkNFAADAaVBxAQDARZjcYKiIigsAAHAaVFwAAHAR7jDHhcQFAAAX4Q6rihgqAgAAToOKCwAALoKhIgAA4DTcIXFhqAgAADgNu1Vc2rRpk+59Fy1alImRAADgGtzhPi52S1wCAgIs/28YhhYvXqyAgABVqVJFkrRjxw5duXIlQwkOAADuzMP18xb7JS6zZs2y/P/gwYPVoUMHzZw5U56enpKkpKQkvfrqq/L397dXiAAAwME4xByXTz/9VAMGDLAkLZLk6empfv366dNPP7VjZAAAOA+Tjf9zRA6RuNy+fVsHDx5M1X7w4EElJyfbISIAAOCIHGI5dLdu3dS9e3cdPXpUjz/+uCRp+/btGjdunLp162bn6AAAcA7usBzaIRKXd999V0FBQZo4caLOnDkjSSpYsKAGDhyo/v372zk6AACcg6MO79iSyTAMw95B/NfVq1cl6aEm5V69yfASYAsF6v7P3iEALuHG1nFZcp4Nhy7ZtL86pQJt2p8tOETF5b9YRQQAwINhOXQWKVasmEz3GJg7duxYFkYDAIBzcoehIodIXPr06WP1/tatW9q5c6e+//57DRw40D5BIVOcP3dO0yZP1NYtm3Tz5k0VLlJUb48cqzJlw+0dGuCwerSuqh5tnlBwwdySpAPHzmnsp2u1atvvqfZdMqmbGlUrpQ6DP9PSTfuzOlQg0zlE4vLGG2+k2T59+nT98ssvWRwNMsvVq3F6sWsnRVSpqinTP1Su3IE6dfIPhgeB+/jrwlUNnfG9jpz6WyaTSZ2bVtaCCV30RORUHTh+3rLfa88+KQebtogs5g6rihziPi5306RJEy1cuNDeYcBG5nz6sQoUKKhho8aqbLnyeqRwYT1RvYYKFylq79AAh/bd5gNaufWQjv55UUdO/a3hH6xS/I1EPR7+fz875UsW1Bsda+rlMV/bMVLYm8nGL0fk0InL119/rcBAx5vRjAfzw8b1CitbVkMG9FHDOjX0XIc2WrzwK3uHBTgVDw+T2tcvL19vL23fc1KS5GPOrtkjnlWfd7/RuUvxdo4QyFwOMVRUqVIlq8m5hmHo7NmzunDhgmbMmGHHyGBLf/15Sgu/+lKdnu+qbt1f0r59ezVx/Fhlz+6lZi1a2Ts8wKGVLVFAGz58Vd5e2RR/I1HPDJmrgyf+HSaa0KeZtu05qWU/MKfF3Xm4wViRQyQurVq1snrv4eGhfPnyqU6dOipduvQ9j01ISFBCQoJ1m5FdZrPZ1mHiISUnGworW1a9Xu8rSSoVVkbHjhzWogVfkrgA9/H7H3+rauRUBfh6q/VT4fpoaHs1fPVDlSicR3UiSuiJyKn2DhHIEg6RuAwbNuyBj42OjtaIESOs2oa8+bai3nrwPpE58ubLq+LFS1i1hRQvrnVrVtkpIsB53LqdpGN/XpQk7Tz0lyLCCqvXMzV0M+GWij8SqLOrrD/zvhjbWVt+O6FGvT60R7iwE9evtzhI4vJfN2/eVGJiolXbvVadREVFqV+/flZtCUb2TIkND6dCxcr648QJq7aTf5xQUKFC9gkIcGIeJg+Zs2fT6I9Wa9a3P1tt2zGvrwZNWablmw/YKTrYjRtkLg6RuFy7dk2DBw/WV199pYsXL6banpSUdNdjzWZzqmEhbvnvmDp2jlT3yE6a9fEHqt+wsfbt3aPFXy/Q/94ecf+DATc28pVGWrn1d506e0U5fb30TMOKqlW5mJr3+VTnLsWnOSH31Lkr+uPMZTtEC2Quh0hcBg0apPXr1ysmJkbPP/+8pk+frr/++ksffPCBxo3Lmuc7IPOVDS+ndyZN1fSp7+njD2ao0COF1W/QEDV5urm9QwMcWr7cfvrk7Q4KypNTcfE3tffoGTXv86nW/XzE3qHBwbjDnXMd4iGLRYsW1WeffaY6derI399fv/76q0JDQzV37lx98cUX+u677zLUHxUXwDZ4yCJgG1n1kMWfjsXZtL/HiwfYtD9bcIj7uFy6dEnFixeX9O98lkuX/n265ZNPPqlNmzbZMzQAAOBAHCJxKV68uI4fPy5JKl26tL766t+bki1dulS5cuWyY2QAADgP7pybRbp166bffvtNkjRkyBBNnz5d3t7e6tu3Lw9ZBAAAFg4xObdv376W/69fv74OHjyoHTt2KDQ0VOXLl7djZAAAOBFHLZPYkN0Tl1u3bqlx48aaOXOmSpYsKUkKDg5WcHCwnSMDAMC5uMOqIrsPFWXPnl27d++2dxgAAMAJ2D1xkaTOnTvrk08+sXcYAAA4NZPJti9HZPehIkm6ffu2Pv30U61Zs0YRERHy9fW12j5p0iQ7RQYAgPNw0FzDpuyauBw7dkwhISHau3evKleuLEn6/fffrfYxOWrKBwAAspxdE5eSJUvqzJkzWr9+vSTpmWee0dSpU1WgQAF7hgUAgHNyg7/17Zq43Pm0gRUrVujatWt2igYAAOfGqqIs5gCPTQIAAA7MrhUXk8mUag4Lc1oAAHgw7vAr1O5DRV27dpXZbJYk3bx5Uy+//HKqVUWLFi2yR3gAAMDB2DVxiYyMtHrfuXNnO0UCAIDzc4OCi30Tl1mzZtnz9AAAuBY3yFwcanIuAADAvTjEnXMBAMDDc4fl0CQuAAC4CHdYVcRQEQAAcBpUXAAAcBFuUHAhcQEAwGW4QebCUBEAAHAaVFwAAHAR7rCqiIoLAAB4aJs2bVLz5s1VqFAhmUwmLVmyxGq7YRh6++23VbBgQfn4+Kh+/fo6fPhwhs9D4gIAgIswmWz7yohr166pQoUKmj59eprbJ0yYoKlTp2rmzJnavn27fH191ahRI928eTND52GoCAAAF2HPgaImTZqoSZMmaW4zDEOTJ0/WW2+9pZYtW0qSPvvsMxUoUEBLlizRs88+m+7zUHEBAABpSkhI0NWrV61eCQkJGe7n+PHjOnv2rOrXr29pCwgIUNWqVbV169YM9UXiAgCAqzDZ9hUdHa2AgACrV3R0dIbDOnv2rCSpQIECVu0FChSwbEsvhooAAHARtl5VFBUVpX79+lm1mc1mm54jo0hcAABAmsxms00SlaCgIEnSuXPnVLBgQUv7uXPnVLFixQz1xVARAAAuwp6riu6lWLFiCgoK0tq1ay1tV69e1fbt21WtWrUM9UXFBQAAPLT4+HgdOXLE8v748ePatWuXAgMDVbRoUfXp00ejR49WyZIlVaxYMQ0dOlSFChVSq1atMnQeEhcAAFyEPZdD//LLL6pbt67lfcrcmMjISM2ePVuDBg3StWvX9NJLL+nKlSt68skn9f3338vb2ztD5zEZhmHYNHIHcPVmsr1DAFxCgbr/s3cIgEu4sXVclpzn93PXbdrfowVy2LQ/W2COCwAAcBoMFQEA4CLc4SGLJC4AALgIW64EclQMFQEAAKdBxQUAABfhBgUXEhcAAFyGG2QuDBUBAACnQcUFAAAX4Q6riqi4AAAAp0HFBQAAF+EOy6FJXAAAcBFukLcwVAQAAJwHFRcAAFyFG5RcSFwAAHARrCoCAABwIFRcAABwEawqAgAATsMN8haGigAAgPOg4gIAgItwh6EiKi4AAMBpUHEBAMBluH7JhcQFAAAXwVARAACAA6HiAgCAi3CDgguJCwAAroKhIgAAAAdCxQUAABfBQxYBAAAcCBUXAABchesXXEhcAABwFW6QtzBUBAAAnAcVFwAAXIQ7LIcmcQEAwEWwqggAAMCBUHEBAMBVuH7BhcQFAABX4QZ5C0NFAADAeVBxAQDARbjDqiIqLgAAwGlQcQEAwEW4w3JoEhcAAFwEQ0UAAAAOhMQFAAA4DYaKAABwEQwVAQAAOBAqLgAAuAh3WFVExQUAADgNKi4AALgId5jjQuICAICLcIO8haEiAADgPKi4AADgKtyg5ELiAgCAi2BVEQAAgAOh4gIAgItgVREAAHAabpC3MFQEAACcB4kLAACuwmTjVwYMHz5cJpPJ6lW6dGkbXJQ1hooAAIBNlC1bVmvWrLG8z5bN9mkGiQsAAC7C3suhs2XLpqCgoEw9B0NFAAC4CJPJtq+MOnz4sAoVKqTixYvrueee08mTJ21+jVRcAABAmhISEpSQkGDVZjabZTabU+1btWpVzZ49W6VKldKZM2c0YsQI1axZU3v37lXOnDltFpPJMAzDZr0B6ZSQkKDo6GhFRUWl+QMA4P74OUJmGz58uEaMGGHVNmzYMA0fPvy+x165ckXBwcGaNGmSunfvbrOYSFxgF1evXlVAQIDi4uLk7+9v73AAp8TPETJbRiouaXnsscdUv359RUdH2ywm5rgAAIA0mc1m+fv7W73Sm7TEx8fr6NGjKliwoE1jInEBAAAPbcCAAdq4caNOnDihH3/8Ua1bt5anp6c6duxo0/MwORcAADy0P//8Ux07dtTFixeVL18+Pfnkk9q2bZvy5ctn0/OQuMAuzGazhg0bxoRC4CHwcwRH8uWXX2bJeZicCwAAnAZzXAAAgNMgcQEAAE6DxAVu6cSJEzKZTNq1a5e9QwHsqmvXrmrVqpW9wwDSjcTFzXTt2lUmk0njxo2zal+yZIlMD/JgigxISRbufHXu3DlTzws4opSfxTtfR44csXdogENjVZEb8vb21vjx49WzZ0/lzp07y8+/Zs0alS1b1vLex8cn1T6GYSgpKSlTHokOOIrGjRtr1qxZVm13Lh1NTEyUl5dXVoYFODQqLm6ofv36CgoKuuctmBcuXKiyZcvKbDYrJCREEydOtNoeEhKisWPH6oUXXlDOnDlVtGhRffjhh+k6f548eRQUFGR5BQQEaMOGDTKZTFqxYoUiIiJkNpu1efNmHT16VC1btlSBAgXk5+enxx57TGvWrLHqz2QyacmSJVZtuXLl0uzZsy3vf/rpJ1WqVEne3t6qUqWKdu7cma5YgcxkNputfhaCgoJUr1499e7dW3369FHevHnVqFEjSdKkSZNUrlw5+fr6qkiRInr11VcVHx9v6Wv48OGqWLGiVf+TJ09WSEiI5X1SUpL69eunXLlyKU+ePBo0aJBYWApnQ+Lihjw9PTV27FhNmzZNf/75Z6rtO3bsUIcOHfTss89qz549Gj58uIYOHWqVCEjSxIkTLUnAq6++qldeeUWHDh16qNiGDBmicePG6cCBAypfvrzi4+PVtGlTrV27Vjt37lTjxo3VvHnzDD0qPT4+Xs2aNVOZMmW0Y8cODR8+XAMGDHioOIHMNGfOHHl5eWnLli2aOXOmJMnDw0NTp07Vvn37NGfOHK1bt06DBg3KUL8TJ07U7Nmz9emnn2rz5s26dOmSFi9enBmXAGQeA24lMjLSaNmypWEYhvHEE08YL7zwgmEYhrF48WIj5duhU6dORoMGDayOGzhwoFGmTBnL++DgYKNz586W98nJyUb+/PmNmJiYu577+PHjhiTDx8fH8PX1tbx+/fVXY/369YYkY8mSJfe9hrJlyxrTpk2zvJdkLF682GqfgIAAY9asWYZhGMYHH3xg5MmTx7hx44Zle0xMjCHJ2Llz533PB2SGyMhIw9PT0+pnoV27dkbt2rWNSpUq3ff4BQsWGHny5LG8HzZsmFGhQgWrfd577z0jODjY8r5gwYLGhAkTLO9v3bplFC5c2PKZADgDKi5ubPz48ZozZ44OHDhg1X7gwAHVqFHDqq1GjRo6fPiwkpKSLG3ly5e3/L/JZFJQUJDOnz8vSWrSpIn8/Pzk5+dnNZ9FkubPn69du3ZZXmXKlLFsq1KlitW+8fHxGjBggMLCwpQrVy75+fnpwIEDGaq4pFRvvL29LW3VqlVL9/FAZqlbt67Vz8LUqVMlSREREan2XbNmjerVq6dHHnlEOXPm1PPPP6+LFy/q+vXr6TpXXFyczpw5o6pVq1rasmXLlupnDnB0zHx0Y7Vq1VKjRo0UFRWlrl27Zvj47NmzW703mUxKTk6WJH388ce6ceNGmvsVKVJEoaGhafbp6+tr9X7AgAFavXq13n33XYWGhsrHx0ft2rVTYmKi1XmNO8bpb926leHrAbKar69vmj8Ld/4cnDhxQs2aNdMrr7yiMWPGKDAwUJs3b1b37t2VmJioHDlyyMPDg58DuAUSFzc3btw4VaxYUaVKlbK0hYWFacuWLVb7bdmyRY8++qg8PT3T1e8jjzxik/i2bNmirl27qnXr1pL+rcCcOHHCap98+fLpzJkzlveHDx+2+is0LCxMc+fO1c2bNy1Vl23bttkkPiAr7NixQ8nJyZo4caI8PP4tlH/11VdW++TLl09nz56VYRiWWxv89z5FAQEBKliwoLZv365atWpJkm7fvq0dO3aocuXKWXMhgA0wVOTmypUrp+eee85Sopak/v37a+3atRo1apR+//13zZkzR++//75dJrSWLFlSixYt0q5du/Tbb7+pU6dOlqpOiqeeekrvv/++du7cqV9++UUvv/yyVZWnU6dOMplM6tGjh/bv36/vvvtO7777blZfCvDAQkNDdevWLU2bNk3Hjh3T3LlzLZN2U9SpU0cXLlzQhAkTdPToUU2fPl0rVqyw2ueNN97QuHHjtGTJEh08eFCvvvqqrly5koVXAjw8Ehdo5MiRVslA5cqV9dVXX+nLL79UeHi43n77bY0cOfKBhpMe1qRJk5Q7d25Vr15dzZs3V6NGjVL9dThx4kQVKVJENWvWVKdOnTRgwADlyJHDst3Pz09Lly7Vnj17VKlSJb355psaP358Vl8K8MAqVKigSZMmafz48QoPD9e8efNS3c4gLCxMM2bM0PTp01WhQgX99NNPqf7Y6N+/v55//nlFRkaqWrVqypkzp6WaCTgLng4NAACcBhUXAADgNEhcAACA0yBxAQAAToPEBQAAOA0SFwAA4DRIXAAAgNMgcQEAAE6DxAUAADgNEhcAkqSuXbuqVatWlvd16tRRnz59sjyODRs2yGQycSt6AGkicQEcXNeuXWUymWQymeTl5aXQ0FCNHDlSt2/fztTzLlq0SKNGjUrXviQbALIKT4cGnEDjxo01a9YsJSQk6LvvvlOvXr2UPXt2RUVFWe2XmJgoLy8vm5wzMDDQJv0AgC1RcQGcgNlsVlBQkIKDg/XKK6+ofv36+vbbby3DO2PGjFGhQoVUqlQpSdKpU6fUoUMH5cqVS4GBgWrZsqVOnDhh6S8pKUn9+vVTrly5lCdPHg0aNEh3PrbszqGihIQEDR48WEWKFJHZbFZoaKg++eQTnThxQnXr1pUk5c6dWyaTyfJAzuTkZEVHR6tYsWLy8fFRhQoV9PXXX1ud57vvvtOjjz4qHx8f1a1b1ypOALgTiQvghHx8fJSYmChJWrt2rQ4dOqTVq1dr2bJlunXrlho1aqScOXPqhx9+0JYtW+Tn56fGjRtbjpk4caJmz56tTz/9VJs3b9alS5e0ePHie56zS5cu+uKLLzR16lQdOHBAH3zwgfz8/FSkSBEtXLhQknTo0CGdOXNGU6ZMkSRFR0frs88+08yZM7Vv3z717dtXnTt31saNGyX9m2C1adNGzZs3165du/Tiiy9qyJAhmfVlA+AKDAAOLTIy0mjZsqVhGIaRnJxsrF692jCbzcaAAQOMyMhIo0CBAkZCQoJl/7lz5xqlSpUykpOTLW0JCQmGj4+PsXLlSsMwDKNgwYLGhAkTLNtv3bplFC5c2HIewzCM2rVrG2+88YZhGIZx6NAhQ5KxevXqNGNcv369Icm4fPmype3mzZtGjhw5jB9//NFq3+7duxsdO3Y0DMMwoqKijDJlylhtHzx4cKq+ACAFc1wAJ7Bs2TL5+fnp1q1bSk5OVqdOnTR8+HD16tVL5cqVs5rX8ttvv+nIkSPKmTOnVR83b97U0aNHFRcXpzNnzqhq1aqWbdmyZVOVKlVSDRel2LVrlzw9PVW7du10x3zkyBFdv35dDRo0sGpPTExUpUqVJEkHDhywikOSqlWrlu5zAHA/JC6AE6hbt65iYmLk5eWlQoUKKVu2//vR9fX1tdo3Pj5eERERmjdvXqp+8uXL90Dn9/HxyfAx8fHxkqTly5frkUcesdpmNpsfKA4AIHEBnICvr69CQ0PTtW/lypU1f/585c+fX/7+/mnuU7BgQW3fvl21atWSJN2+fVs7duxQ5cqV09y/XLlySk5O1saNG1W/fv1U21MqPklJSZa2MmXKyGw26+TJk3et1ISFhenbb7+1atu2bdv9LxKA22JyLuBinnvuOeXNm1ctW7bUDz/8oOPHj2vDhg16/fXX9eeff0qS3njjDY0bN05LlizRwYMH9eqrr97zHiwhISGKjIzUCy+8oCVLllj6/OqrryRJwcHBMplMWrZsmS5cuKD4+HjlzJlTAwYMUN++fTVnzhwdPXpUv/76q6ZNm6Y5c+ZIkl5++WUdPnxYAwcO1KFDhxQbG6vZs2dn9pcIgBMjcQFcTI4cObRp0yYVLVpUbdq0UVhYmLp3766bN29aKjD9+/fX888/r8jISFWrVk05c+ZU69at79lvTEyM2rVrp1dffVWlS5dWjx49dO3aNUnSI488ohEjRmjIkCEqUKCAevfuLUkaNWqUhg4dqujoaIWFhalx48Zavny5ihUrJkkqWrSoFi5cqCVLlqhChQqaOXOmxo4dm4lfHQDOzmTcbTYeAACAg6HiAgAAnAaJCwAAcBokLgAAwGmQuAAAAKdB4gIAAJwGiQsAAHAaJC4AAMBpkLgAAACnQeICAACcBokLAABwGiQuAADAaZC4AAAAp/H/AHn1oTrKuxvGAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tier one enhancers"
      ],
      "metadata": {
        "id": "YG_plooBVkyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enhanced_deberta_mdna_sliding.py — Sliding window + optimized fine‑tuning + doc-level eval\n",
        "# ------------------------------------------------------------------------------\n",
        "import json, torch, numpy as np, time\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load preprocessed MD&A text samples\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    mdna_samples = json.load(f)\n",
        "\n",
        "texts = [s[\"text\"] for s in mdna_samples]\n",
        "labels = [1 if s[\"true_label\"] == \"Fraud\" else 0 for s in mdna_samples]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenizer and model\n",
        "model_name = \"microsoft/deberta-v3-small\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
        "model      = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Optional: Freeze early layers to improve speed and reduce overfitting\n",
        "for name, param in model.deberta.encoder.layer[:4].named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Chunking function (sliding window)\n",
        "def sliding_chunk_text(text, label, tokenizer, max_length=512, stride=128):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = start + max_length\n",
        "        chunk = tokens[start:end]\n",
        "        if len(chunk) < max_length:\n",
        "            chunk += [tokenizer.pad_token_id] * (max_length - len(chunk))\n",
        "        chunks.append((chunk, label))\n",
        "        if end >= len(tokens):\n",
        "            break\n",
        "        start += max_length - stride\n",
        "    return chunks\n",
        "\n",
        "# Dataset class\n",
        "class ChunkedMDNADataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512, stride=128):\n",
        "        self.samples = []\n",
        "        for text, label in zip(texts, labels):\n",
        "            self.samples.extend(sliding_chunk_text(text, label, tokenizer, max_length, stride))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, label = self.samples[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(chunk),\n",
        "            \"attention_mask\": torch.tensor([1 if t != tokenizer.pad_token_id else 0 for t in chunk]),\n",
        "            \"labels\": torch.tensor(label)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "train_dataset = ChunkedMDNADataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset   = ChunkedMDNADataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./deberta-mdna-sliding\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    label_smoothing_factor=0.1,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Evaluation metrics\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=-1)\n",
        "    labels = p.label_ids\n",
        "    return {\n",
        "        \"accuracy\":  accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "        \"recall\":    recall_score(labels, preds, zero_division=0),\n",
        "        \"f1\":        f1_score(labels, preds, zero_division=0),\n",
        "    }\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# Train and save\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "trainer.save_model(\"./deberta-mdna-sliding\")\n",
        "tokenizer.save_pretrained(\"./deberta-mdna-sliding\")\n",
        "print(f\"✅ DeBERTa fine-tuned and saved in {(time.time() - start)/60:.1f} min.\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 🔍 Final document-level evaluation with mean-logit aggregation\n",
        "# ---------------------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "def predict_document_mean_logit(text):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=False)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), 384):\n",
        "        chunk = tokens[i:i + 512]\n",
        "        if len(chunk) < 512:\n",
        "            chunk += [tokenizer.pad_token_id] * (512 - len(chunk))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    logits = []\n",
        "    with torch.no_grad():\n",
        "        for chunk in chunks:\n",
        "            input_ids = torch.tensor(chunk).unsqueeze(0).to(device)\n",
        "            attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
        "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits.append(output.logits.squeeze(0).cpu().numpy())\n",
        "\n",
        "    avg_logits = np.mean(logits, axis=0)\n",
        "    return int(np.argmax(avg_logits))\n",
        "\n",
        "# Run predictions on validation set\n",
        "val_preds = [predict_document_mean_logit(text) for text in val_texts]\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n📊 Classification Report (document-level, mean-logit):\")\n",
        "print(classification_report(val_labels, val_preds, target_names=[\"Non-Fraud\", \"Fraud\"]))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Non-Fraud\", \"Fraud\"],\n",
        "            yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - DeBERTa (Mean Logit)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CdqsaVWPVmdn",
        "outputId": "aecc663b-f437-45a4-ba41-561be34bf8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-5-4124538660.py:105: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7612' max='7612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7612/7612 18:48, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.410100</td>\n",
              "      <td>0.535037</td>\n",
              "      <td>0.809086</td>\n",
              "      <td>0.797608</td>\n",
              "      <td>0.642885</td>\n",
              "      <td>0.711937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.322600</td>\n",
              "      <td>0.522080</td>\n",
              "      <td>0.847297</td>\n",
              "      <td>0.834364</td>\n",
              "      <td>0.728500</td>\n",
              "      <td>0.777846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.272300</td>\n",
              "      <td>0.518301</td>\n",
              "      <td>0.856637</td>\n",
              "      <td>0.846188</td>\n",
              "      <td>0.744697</td>\n",
              "      <td>0.792205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.521207</td>\n",
              "      <td>0.858760</td>\n",
              "      <td>0.850549</td>\n",
              "      <td>0.746240</td>\n",
              "      <td>0.794988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DeBERTa fine-tuned and saved in 19.0 min.\n",
            "\n",
            "📊 Classification Report (document-level, mean-logit):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Fraud       0.86      0.93      0.89        40\n",
            "       Fraud       0.92      0.85      0.88        40\n",
            "\n",
            "    accuracy                           0.89        80\n",
            "   macro avg       0.89      0.89      0.89        80\n",
            "weighted avg       0.89      0.89      0.89        80\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}