{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3c8fe13c876425a9116a157f86ba5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_416e30869a8a4ae687e9c002953af2a4",
              "IPY_MODEL_48e53d4b9aec4779a77e7cd3f32cd4c6",
              "IPY_MODEL_0cc8710f98f0455ea758320cc6e99b6c"
            ],
            "layout": "IPY_MODEL_b601eb1ef02a4b758462ca035f8e6ced"
          }
        },
        "416e30869a8a4ae687e9c002953af2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06580a32cd094dd69ef92959caae24f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd90e022e1944dba0355d379108466b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "48e53d4b9aec4779a77e7cd3f32cd4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bdbd838beb54728ae6268584798e7d3",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a15d34491fa4ba68196c7aaab8ebb29",
            "value": 52
          }
        },
        "0cc8710f98f0455ea758320cc6e99b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02705f6f33a74162b191d29412bbe9fc",
            "placeholder": "​",
            "style": "IPY_MODEL_cbe38c203ee9403bbd7e0b1a651992a2",
            "value": " 52.0/52.0 [00:00&lt;00:00, 6.62kB/s]"
          }
        },
        "b601eb1ef02a4b758462ca035f8e6ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06580a32cd094dd69ef92959caae24f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd90e022e1944dba0355d379108466b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bdbd838beb54728ae6268584798e7d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a15d34491fa4ba68196c7aaab8ebb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02705f6f33a74162b191d29412bbe9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe38c203ee9403bbd7e0b1a651992a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe5e95984a746cb90cd416c6c7bb6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e8c59bf18341f0bc263e93cfc88de0",
              "IPY_MODEL_cb68dd6485fb449ca55a1a7cec968d9f",
              "IPY_MODEL_a991586d9a584e1d95faa31bfdd3d273"
            ],
            "layout": "IPY_MODEL_6a8c37896cc64638867f58dae34f3982"
          }
        },
        "b8e8c59bf18341f0bc263e93cfc88de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_914e067bb0e84c178f3f904d8cf14a7f",
            "placeholder": "​",
            "style": "IPY_MODEL_3740ef38a2524f28b0d19491c35c5d4a",
            "value": "config.json: 100%"
          }
        },
        "cb68dd6485fb449ca55a1a7cec968d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51fd5cba10fa413d99d904cda39c8c5c",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_846ad69be7774d85950b82c03ce0f5ec",
            "value": 578
          }
        },
        "a991586d9a584e1d95faa31bfdd3d273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77e4a73f8a546b59bf6cc6a240f0f75",
            "placeholder": "​",
            "style": "IPY_MODEL_64a0f943d49b4d23b237b66ca01d3b6e",
            "value": " 578/578 [00:00&lt;00:00, 75.7kB/s]"
          }
        },
        "6a8c37896cc64638867f58dae34f3982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914e067bb0e84c178f3f904d8cf14a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3740ef38a2524f28b0d19491c35c5d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51fd5cba10fa413d99d904cda39c8c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846ad69be7774d85950b82c03ce0f5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e77e4a73f8a546b59bf6cc6a240f0f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a0f943d49b4d23b237b66ca01d3b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd730031c2ab4df587a5ed754decc697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdc2df91f75d4501bad26d727c56ef0a",
              "IPY_MODEL_60621ed274ae400f95c5bd2f5b804494",
              "IPY_MODEL_de18a8ff73954a61b478da68b4179a02"
            ],
            "layout": "IPY_MODEL_69eec09aa0054bf69e3492e44fe026d6"
          }
        },
        "fdc2df91f75d4501bad26d727c56ef0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea65c9d5ed54d8f81e57db5d4c4b9cd",
            "placeholder": "​",
            "style": "IPY_MODEL_fce74a63c7fe4dfbb4c54620fdde7577",
            "value": "spm.model: 100%"
          }
        },
        "60621ed274ae400f95c5bd2f5b804494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b462df983544bcdb31eb4bbd667a296",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_400dc6e072ba44d8ab78532e2912e52e",
            "value": 2464616
          }
        },
        "de18a8ff73954a61b478da68b4179a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c67326cc2c4118906bf9732534749e",
            "placeholder": "​",
            "style": "IPY_MODEL_af95146f216944338da39cc0a6b753df",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 4.06MB/s]"
          }
        },
        "69eec09aa0054bf69e3492e44fe026d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea65c9d5ed54d8f81e57db5d4c4b9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce74a63c7fe4dfbb4c54620fdde7577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b462df983544bcdb31eb4bbd667a296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400dc6e072ba44d8ab78532e2912e52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12c67326cc2c4118906bf9732534749e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af95146f216944338da39cc0a6b753df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a937f51f82f44089b799feb683cafc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0aac0e8928428eb52051b14fa62e21",
              "IPY_MODEL_86c472c2007c495490ba2e01eb9a8cc0",
              "IPY_MODEL_8a66b08864e940b7b92a4801243247b7"
            ],
            "layout": "IPY_MODEL_8160a4911aca47bc8e92f400570c2e2d"
          }
        },
        "3a0aac0e8928428eb52051b14fa62e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd72c9bc0124c4aaaea29a4fafa626c",
            "placeholder": "​",
            "style": "IPY_MODEL_b0c920e841374f7286b784b8e12e04a3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "86c472c2007c495490ba2e01eb9a8cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d619ee36e2c4110bcd7f7c2aed92a64",
            "max": 286059269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b4e86e0062463cb5ace8becb6c7ff5",
            "value": 286059269
          }
        },
        "8a66b08864e940b7b92a4801243247b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14023b170f294c3fb97181aef2ad152e",
            "placeholder": "​",
            "style": "IPY_MODEL_cc1f52f95ed644e19c3c752efc8be594",
            "value": " 286M/286M [00:02&lt;00:00, 189MB/s]"
          }
        },
        "8160a4911aca47bc8e92f400570c2e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd72c9bc0124c4aaaea29a4fafa626c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c920e841374f7286b784b8e12e04a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d619ee36e2c4110bcd7f7c2aed92a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b4e86e0062463cb5ace8becb6c7ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14023b170f294c3fb97181aef2ad152e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1f52f95ed644e19c3c752efc8be594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15219b67de8146c1a492c54d6f3c67a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93b0ca01cda249d68803ae4b87e72971",
              "IPY_MODEL_bf64a986564c4cb4858134f605229372",
              "IPY_MODEL_c42bf169b337492c9c918e2b192ae4d7"
            ],
            "layout": "IPY_MODEL_77d7c77b5b8a4b27a8c31afc2900cb7c"
          }
        },
        "93b0ca01cda249d68803ae4b87e72971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd605fcc23794e55ad651de26e5073b2",
            "placeholder": "​",
            "style": "IPY_MODEL_0dace0a2bf3a4e99bd95165fd522b242",
            "value": "model.safetensors: 100%"
          }
        },
        "bf64a986564c4cb4858134f605229372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7ec7b4c1d94b4bb7fc8dd6519e8631",
            "max": 286034994,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b88a3f0ffbcb4868821fb74621f18b8c",
            "value": 286034994
          }
        },
        "c42bf169b337492c9c918e2b192ae4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ecea7744a7b453a88534b50bf473e49",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ef0f4ae28b4346a9895547c6319181",
            "value": " 286M/286M [00:01&lt;00:00, 230MB/s]"
          }
        },
        "77d7c77b5b8a4b27a8c31afc2900cb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd605fcc23794e55ad651de26e5073b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dace0a2bf3a4e99bd95165fd522b242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d7ec7b4c1d94b4bb7fc8dd6519e8631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88a3f0ffbcb4868821fb74621f18b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ecea7744a7b453a88534b50bf473e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ef0f4ae28b4346a9895547c6319181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyxHZTY7ThX0",
        "outputId": "fcc676ba-7563-41e2-d894-44201267363c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, accelerate\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.2\n",
            "    Uninstalling transformers-4.55.2:\n",
            "      Successfully uninstalled transformers-4.55.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.0\n",
            "    Uninstalling accelerate-1.10.0:\n",
            "      Successfully uninstalled accelerate-1.10.0\n",
            "Successfully installed accelerate-1.10.1 transformers-4.55.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U accelerate transformers\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Colab: Upload zips -> sample <2001 -> save mdna_sample -> download zip ====\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import tempfile\n",
        "from collections import Counter\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# -----------------------\n",
        "# Config you can tweak\n",
        "# -----------------------\n",
        "MAX_PER_CLASS = 200\n",
        "YEAR_CUTOFF = 2006        # keep strictly < 2001 (i.e., up to 2000)\n",
        "RANDOM_SEED = 42\n",
        "CLASSES = (\"fraud\", \"non_fraud\")\n",
        "OUTPUT_DIR = \"mdna_sample\"\n",
        "\n",
        "# Filename pattern: capture a 4-digit year that is preceded by an underscore, anywhere.\n",
        "# Examples matched: \"5272_2000.txt\", \"acme_1998_v2.txt\", \"abc_1975-anything.TXT\"\n",
        "YEAR_RE = re.compile(r\"_(19\\d{2}|20\\d{2})(?:\\D|$)\", re.IGNORECASE)\n",
        "\n",
        "def parse_year_from_filename(name):\n",
        "    m = YEAR_RE.search(name)     # <-- search, not match\n",
        "    if not m:\n",
        "        return None\n",
        "    return int(m.group(1))\n",
        "\n",
        "def ensure_dir(path):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def infer_class_from_path(path_lower):\n",
        "    # zip internals use forward slashes\n",
        "    if \"/non-fraud/\" in path_lower or \"/non_fraud/\" in path_lower or \"/nonfraud/\" in path_lower:\n",
        "        return \"non_fraud\"\n",
        "    if \"/fraud/\" in path_lower:\n",
        "        return \"fraud\"\n",
        "    return None\n",
        "\n",
        "def infer_class_from_zipname(zip_basename_lower):\n",
        "    if \"non-fraud\" in zip_basename_lower or \"non_fraud\" in zip_basename_lower or \"nonfraud\" in zip_basename_lower:\n",
        "        return \"non_fraud\"\n",
        "    if \"fraud\" in zip_basename_lower:\n",
        "        return \"fraud\"\n",
        "    return None\n",
        "\n",
        "def collect_candidates_from_zip(zippath, tmp_extract_root):\n",
        "    \"\"\"\n",
        "    Extract zip to a dedicated folder and collect eligible files per class.\n",
        "    Returns: { 'fraud': [abs_paths...], 'non_fraud': [...] }\n",
        "    \"\"\"\n",
        "    buckets = {c: [] for c in CLASSES}\n",
        "    base_name = os.path.splitext(os.path.basename(zippath))[0]\n",
        "    extract_here = os.path.join(tmp_extract_root, base_name)\n",
        "    ensure_dir(extract_here)\n",
        "\n",
        "    with zipfile.ZipFile(zippath, \"r\") as zf:\n",
        "        zf.extractall(extract_here)\n",
        "\n",
        "    # Fallback class from the zip filename (handles zips like 'Fraud_MDA-...zip')\n",
        "    zip_class_hint = infer_class_from_zipname(os.path.basename(zippath).lower())\n",
        "\n",
        "    for root, _, files_in_dir in os.walk(extract_here):\n",
        "        root_lower = root.lower()\n",
        "        # Prefer internal path hint; else use zip name hint\n",
        "        cls_hint = infer_class_from_path(root_lower) or zip_class_hint\n",
        "\n",
        "        for fn in files_in_dir:\n",
        "            if not fn.lower().endswith(\".txt\"):\n",
        "                continue\n",
        "            year = parse_year_from_filename(fn)\n",
        "            if year is None or year >= YEAR_CUTOFF:\n",
        "                continue\n",
        "\n",
        "            full = os.path.join(root, fn)\n",
        "            # Light read to ensure file is accessible\n",
        "            try:\n",
        "                with io.open(full, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    _ = f.read(512)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            if cls_hint in buckets:\n",
        "                buckets[cls_hint].append(full)\n",
        "            # If we still can't infer class, we skip (we only want labeled classes)\n",
        "\n",
        "    return buckets\n",
        "\n",
        "def sample_and_copy(files, dst_dir):\n",
        "    random.seed(RANDOM_SEED)\n",
        "    if len(files) > MAX_PER_CLASS:\n",
        "        files = random.sample(files, MAX_PER_CLASS)\n",
        "\n",
        "    ensure_dir(dst_dir)\n",
        "    used = set()\n",
        "    copied = 0\n",
        "    for src in files:\n",
        "        name = os.path.basename(src)\n",
        "        dest = os.path.join(dst_dir, name)\n",
        "        # Avoid collisions\n",
        "        if name in used or os.path.exists(dest):\n",
        "            stem, ext = os.path.splitext(name)\n",
        "            i = 1\n",
        "            while True:\n",
        "                alt = f\"{stem}__dup{i}{ext}\"\n",
        "                dest = os.path.join(dst_dir, alt)\n",
        "                if not os.path.exists(dest):\n",
        "                    name = alt\n",
        "                    break\n",
        "                i += 1\n",
        "        used.add(name)\n",
        "        shutil.copy2(src, dest)\n",
        "        copied += 1\n",
        "    return copied\n",
        "\n",
        "def by_year_counts(folder):\n",
        "    \"\"\"Return Counter of years for files in folder based on filename.\"\"\"\n",
        "    cnt = Counter()\n",
        "    if not os.path.isdir(folder):\n",
        "        return cnt\n",
        "    for fn in os.listdir(folder):\n",
        "        y = parse_year_from_filename(fn)\n",
        "        if y is not None:\n",
        "            cnt[y] += 1\n",
        "    return cnt\n",
        "\n",
        "def zip_dir(dir_path, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files_in_dir in os.walk(dir_path):\n",
        "            for fn in files_in_dir:\n",
        "                abs_p = os.path.join(root, fn)\n",
        "                rel_p = os.path.relpath(abs_p, dir_path)\n",
        "                zf.write(abs_p, rel_p)\n",
        "\n",
        "# =======================\n",
        "# Step 1: Upload ZIPs\n",
        "# =======================\n",
        "uploaded_paths = []\n",
        "if IN_COLAB:\n",
        "    print(\"📤 Upload one or more ZIP files...\")\n",
        "    uploaded = files.upload()  # user selects zips from laptop\n",
        "    for name, data in uploaded.items():\n",
        "        with open(name, \"wb\") as f:\n",
        "            f.write(data)\n",
        "        uploaded_paths.append(os.path.abspath(name))\n",
        "    if not uploaded_paths:\n",
        "        raise SystemExit(\"No files uploaded.\")\n",
        "else:\n",
        "    raise SystemExit(\"This notebook cell is intended for Google Colab (files.upload).\")\n",
        "\n",
        "# =======================\n",
        "# Step 2: Process ZIPs\n",
        "# =======================\n",
        "# Clean any previous output\n",
        "if os.path.isdir(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "ensure_dir(os.path.join(OUTPUT_DIR, \"fraud\"))\n",
        "ensure_dir(os.path.join(OUTPUT_DIR, \"non_fraud\"))\n",
        "\n",
        "totals = {c: [] for c in CLASSES}\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmp_root:\n",
        "    for zp in uploaded_paths:\n",
        "        try:\n",
        "            buckets = collect_candidates_from_zip(zp, tmp_root)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Failed to handle {os.path.basename(zp)}: {e}\")\n",
        "            continue\n",
        "        for c in CLASSES:\n",
        "            totals[c].extend(buckets.get(c, []))\n",
        "\n",
        "    # Deduplicate (within this run) and sample+copy\n",
        "    for c in CLASSES:\n",
        "        unique_files = list(dict.fromkeys(totals[c]))  # preserve order, remove dups\n",
        "        copied = sample_and_copy(unique_files, os.path.join(OUTPUT_DIR, c))\n",
        "        print(f\"{c:>10}: eligible={len(unique_files):4d}, copied={copied:3d} (max {MAX_PER_CLASS})\")\n",
        "\n",
        "print(\"\\n✅ Done sampling. Saved to:\", os.path.abspath(OUTPUT_DIR))\n",
        "\n",
        "# =======================\n",
        "# Step 3: By-year counts\n",
        "# =======================\n",
        "for c in CLASSES:\n",
        "    cnt = by_year_counts(os.path.join(OUTPUT_DIR, c))\n",
        "    if cnt:\n",
        "        print(f\"\\n📅 By-year counts for '{c}' (in sample):\")\n",
        "        for y in sorted(cnt):\n",
        "            print(f\"  {y}: {cnt[y]}\")\n",
        "    else:\n",
        "        print(f\"\\n📅 By-year counts for '{c}': (no files)\")\n",
        "\n",
        "# =======================\n",
        "# Step 4: Downloadable ZIP\n",
        "# =======================\n",
        "zip_name = \"mdna_sample.zip\"\n",
        "zip_dir(OUTPUT_DIR, zip_name)\n",
        "print(\"\\n📦 Created archive:\", os.path.abspath(zip_name))\n",
        "\n",
        "if IN_COLAB:\n",
        "    files.download(zip_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "2Es-NFGfTl35",
        "outputId": "1ff01153-802f-4e60-ce07-c54ed162cccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 Upload one or more ZIP files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f58fda77-dc0b-4da8-931e-2f6ff68f60b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f58fda77-dc0b-4da8-931e-2f6ff68f60b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fraud_MDA_cleaned.zip to Fraud_MDA_cleaned.zip\n",
            "Saving Non-fraud_MDA_cleaned.zip to Non-fraud_MDA_cleaned.zip\n",
            "     fraud: eligible= 276, copied=200 (max 200)\n",
            " non_fraud: eligible= 138, copied=138 (max 200)\n",
            "\n",
            "✅ Done sampling. Saved to: /content/mdna_sample\n",
            "\n",
            "📅 By-year counts for 'fraud' (in sample):\n",
            "  1995: 1\n",
            "  1996: 2\n",
            "  1997: 6\n",
            "  1998: 6\n",
            "  1999: 8\n",
            "  2000: 16\n",
            "  2001: 29\n",
            "  2002: 39\n",
            "  2003: 41\n",
            "  2004: 23\n",
            "  2005: 29\n",
            "\n",
            "📅 By-year counts for 'non_fraud' (in sample):\n",
            "  1995: 2\n",
            "  1996: 4\n",
            "  1998: 4\n",
            "  1999: 8\n",
            "  2000: 4\n",
            "  2002: 20\n",
            "  2003: 22\n",
            "  2004: 36\n",
            "  2005: 38\n",
            "\n",
            "📦 Created archive: /content/mdna_sample.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7a710a93-454a-4b23-ae0c-5afc8e54ad62\", \"mdna_sample.zip\", 7700858)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Build mdna_samples.json from mdna_sample.zip ===\n",
        "import os, io, json, zipfile, shutil\n",
        "\n",
        "ZIP_NAME = \"mdna_sample.zip\"         # <-- must exist in current working dir\n",
        "EXTRACT_DIR = \"./mdna_sample_extracted\"\n",
        "OUTPUT_JSON = \"mdna_samples.json\"\n",
        "\n",
        "# 1) Ensure the zip exists (if not, let you upload it)\n",
        "if not os.path.isfile(ZIP_NAME):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(f\"⚠️ {ZIP_NAME} not found. Please upload it now.\")\n",
        "        uploaded = files.upload()\n",
        "        if ZIP_NAME not in uploaded:\n",
        "            raise FileNotFoundError(f\"'{ZIP_NAME}' was not uploaded.\")\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"{ZIP_NAME} not found and upload failed: {e}\")\n",
        "\n",
        "# 2) Fresh extract\n",
        "if os.path.isdir(EXTRACT_DIR):\n",
        "    shutil.rmtree(EXTRACT_DIR)\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, \"r\") as zf:\n",
        "    zf.extractall(EXTRACT_DIR)\n",
        "\n",
        "# 3) Walk extracted folders -> collect .txt into JSON\n",
        "samples = []\n",
        "per_class_counts = {\"fraud\": 0, \"non_fraud\": 0, \"unknown\": 0}\n",
        "\n",
        "def infer_class_from_path(p: str):\n",
        "    p = p.replace(\"\\\\\", \"/\").lower()\n",
        "    if \"/non_fraud/\" in p or \"/non-fraud/\" in p or \"/nonfraud/\" in p:\n",
        "        return \"non_fraud\"\n",
        "    if \"/fraud/\" in p:\n",
        "        return \"fraud\"\n",
        "    # If structure is mdna_sample/<class>/..., handle that too\n",
        "    parts = p.split(\"/\")\n",
        "    for name in (\"fraud\", \"non_fraud\", \"non-fraud\", \"nonfraud\"):\n",
        "        if name in parts:\n",
        "            return \"non_fraud\" if \"non\" in name else \"fraud\"\n",
        "    return \"unknown\"\n",
        "\n",
        "for root, _, files_in_dir in os.walk(EXTRACT_DIR):\n",
        "    for fn in files_in_dir:\n",
        "        if not fn.lower().endswith(\".txt\"):\n",
        "            continue\n",
        "        fpath = os.path.join(root, fn)\n",
        "        cls = infer_class_from_path(fpath)\n",
        "        try:\n",
        "            with io.open(fpath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                text = f.read().strip()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not text:\n",
        "            continue\n",
        "        label = \"Fraud\" if cls == \"fraud\" else (\"Non-Fraud\" if cls == \"non_fraud\" else None)\n",
        "        if label is None:\n",
        "            per_class_counts[\"unknown\"] += 1\n",
        "            continue\n",
        "        samples.append({\"text\": text, \"true_label\": label})\n",
        "        per_class_counts[cls] += 1\n",
        "\n",
        "# 4) Save JSON\n",
        "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(samples, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Saved {OUTPUT_JSON} with {len(samples)} samples.\")\n",
        "print(\"Counts:\", per_class_counts)\n",
        "\n",
        "# (Optional) peek a couple of records\n",
        "for i, s in enumerate(samples[:2]):\n",
        "    print(f\"\\nSample {i+1}: label={s['true_label']}\\n{text[:200]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv3EzAqAT66E",
        "outputId": "c4ce1caa-71f4-47e3-c4f4-36b5176a0ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved mdna_samples.json with 338 samples.\n",
            "Counts: {'fraud': 200, 'non_fraud': 138, 'unknown': 0}\n",
            "\n",
            "Sample 1: label=Fraud\n",
            "\u0000\u0005\u0016\u0007\u0000\u0002\u0000\u0000Mac OS X        \u0000\u0002\u0000\u0000\u0000\t\u0000\u0000\u00002\u0000\u0000\u0000~\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ATTR\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0015com.apple.quarantine\u0000q/0081;6820d4a7;Chrome;\u0000...\n",
            "\n",
            "Sample 2: label=Fraud\n",
            "\u0000\u0005\u0016\u0007\u0000\u0002\u0000\u0000Mac OS X        \u0000\u0002\u0000\u0000\u0000\t\u0000\u0000\u00002\u0000\u0000\u0000~\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000ATTR\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0015com.apple.quarantine\u0000q/0081;6820d4a7;Chrome;\u0000...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# ---------- 1) Load JSON (array or dict wrapper) ----------\n",
        "with open(\"mdna_samples.json\", \"r\") as f:\n",
        "    raw = json.load(f)\n",
        "\n",
        "# If file is a dict wrapper, pick the first list-like field\n",
        "if isinstance(raw, dict):\n",
        "    # common wrappers\n",
        "    for k in [\"data\", \"records\", \"items\", \"rows\", \"samples\"]:\n",
        "        if k in raw and isinstance(raw[k], list):\n",
        "            raw = raw[k]\n",
        "            break\n",
        "    # if still dict, try any list value\n",
        "    if isinstance(raw, dict):\n",
        "        for v in raw.values():\n",
        "            if isinstance(v, list):\n",
        "                raw = v\n",
        "                break\n",
        "\n",
        "if not isinstance(raw, list):\n",
        "    raise ValueError(\"Expected a list of records in mdna_samples.json\")\n",
        "\n",
        "# ---------- 2) Helpers to find label/text in messy schemas ----------\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\",\"Label\",\"true_label\",\"target\",\"class\",\"Class\",\"y\",\"tag\"]\n",
        "CANDIDATE_TEXT_FIELDS  = [\"text\",\"Text\",\"content\",\"document\",\"body\",\"mdna\",\"mdna_text\",\"md&a\",\"mdna_body\"]\n",
        "\n",
        "def find_field(rec, names):\n",
        "    for n in names:\n",
        "        if n in rec:\n",
        "            return rec[n]\n",
        "    # one-level nested search\n",
        "    for v in rec.values():\n",
        "        if isinstance(v, dict):\n",
        "            for n in names:\n",
        "                if n in v:\n",
        "                    return v[n]\n",
        "    return None\n",
        "\n",
        "def normalize_label(val):\n",
        "    if val is None: return \"unknown\"\n",
        "    s = str(val).strip().lower()\n",
        "    # unify common variants\n",
        "    s = s.replace(\"-\", \"_\").replace(\" \", \"_\")\n",
        "    if s in {\"nonfraud\",\"non_fraud\",\"not_fraud\",\"clean\"}:\n",
        "        return \"non_fraud\"\n",
        "    if s in {\"fraud\",\"is_fraud\",\"positive\"}:\n",
        "        return \"fraud\"\n",
        "    if s in {\"unknown\",\"na\",\"\", \"null\", \"none\"}:\n",
        "        return \"unknown\"\n",
        "    # last resort: if it looks like '0'/'1'\n",
        "    if s.isdigit():\n",
        "        return \"fraud\" if int(s)==1 else \"non_fraud\" if int(s)==0 else \"unknown\"\n",
        "    return s  # keep as-is; we'll validate later\n",
        "\n",
        "def normalize_text(val):\n",
        "    if val is None: return None\n",
        "    s = str(val).strip()\n",
        "    return s if s else None\n",
        "\n",
        "# ---------- 3) Build a clean list; map to ints ----------\n",
        "clean = []\n",
        "bad_schema = 0\n",
        "for rec in raw:\n",
        "    lbl_raw = find_field(rec, CANDIDATE_LABEL_FIELDS)\n",
        "    txt_raw = find_field(rec, CANDIDATE_TEXT_FIELDS)\n",
        "    lbl = normalize_label(lbl_raw)\n",
        "    txt = normalize_text(txt_raw)\n",
        "\n",
        "    if txt is None:\n",
        "        bad_schema += 1\n",
        "        continue\n",
        "\n",
        "    clean.append({\n",
        "        \"text\": txt,\n",
        "        \"label_text\": lbl,     # keep human-readable for audit\n",
        "    })\n",
        "\n",
        "# Counts BEFORE integer mapping\n",
        "pre_counts = Counter([r[\"label_text\"] for r in clean])\n",
        "print(\"Pre-normalized label counts:\", pre_counts, \"| dropped text-missing:\", bad_schema)\n",
        "\n",
        "# Only keep fraud/non_fraud; drop unknowns if any\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "final = []\n",
        "unknown_seen = 0\n",
        "for r in clean:\n",
        "    if r[\"label_text\"] in LABEL_MAP:\n",
        "        r[\"label\"] = LABEL_MAP[r[\"label_text\"]]\n",
        "        final.append({\"text\": r[\"text\"], \"label\": r[\"label\"]})\n",
        "    else:\n",
        "        unknown_seen += 1\n",
        "\n",
        "print(\"Kept:\", len(final), \"Unknown/dropped:\", unknown_seen)\n",
        "print(\"Final counts:\", Counter([r[\"label\"] for r in final]))  # expect {1:188, 0:191} for your file\n",
        "\n",
        "# ---------- 4) Save clean file ----------\n",
        "with open(\"mdna_samples_clean.json\", \"w\") as f:\n",
        "    json.dump(final, f, ensure_ascii=False, indent=2)\n",
        "print(\"✅ Saved mdna_samples_clean.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyBgeYrNUA9J",
        "outputId": "3052b180-73f3-4f1c-82ca-ae3f4cb4b558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-normalized label counts: Counter({'fraud': 200, 'non_fraud': 138}) | dropped text-missing: 0\n",
            "Kept: 338 Unknown/dropped: 0\n",
            "Final counts: Counter({1: 200, 0: 138})\n",
            "✅ Saved mdna_samples_clean.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQGdh-sVUp2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, io, pandas as pd, numpy as np, torch, random\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ✅ Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# 1. Load True and Fake data from disk\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# 📂 Upload both files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ✅ Read them after upload\n",
        "true_df = pd.read_csv(io.BytesIO(uploaded[\"True.csv\"]))\n",
        "fake_df = pd.read_csv(io.BytesIO(uploaded[\"Fake.csv\"]))\n",
        "\n",
        "\n",
        "# 2. Keep only 'text' column and assign labels\n",
        "true_df = true_df[[\"text\"]].copy()\n",
        "true_df[\"label\"] = 0  # Real news\n",
        "\n",
        "fake_df = fake_df[[\"text\"]].copy()\n",
        "fake_df[\"label\"] = 1  # Fake news\n",
        "\n",
        "# 3. Combine and shuffle\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True).dropna()\n",
        "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "GzMQZxnKUp0V",
        "outputId": "685e3fcc-9bf9-41cb-e8df-2cbc2ae13017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-610d206a-0a2d-4c12-9f3b-edd29734662e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-610d206a-0a2d-4c12-9f3b-edd29734662e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fake.csv to Fake.csv\n",
            "Saving True.csv to True.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Stage 1: DeBERTa v3-small on Fake/True News (Transfer Pretrain)\n",
        "# ---------------------------------------------------------------\n",
        "# Usage: run this cell/file. It will:\n",
        "# - Load Fake.csv / True.csv\n",
        "# - Train microsoft/deberta-v3-small with class weights + early stopping\n",
        "# - Tune threshold by F1 on the validation set\n",
        "# - Save to ./deberta-small-fake-news\n",
        "#\n",
        "# Notes:\n",
        "# - Expected Kaggle-style columns: [\"title\", \"text\"]. Adjust TEXT_COLS if needed.\n",
        "# - DeBERTa doesn't use token_type_ids; the code handles that safely.\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "MODEL_NAME = \"microsoft/deberta-v3-small\"     # <-- DeBERTa v3-small\n",
        "OUTPUT_DIR = \"./deberta-small-fake-news\"      # <-- save here\n",
        "FAKE_CSV = \"./Fake.csv\"\n",
        "TRUE_CSV = \"./True.csv\"\n",
        "\n",
        "# If running where you uploaded:\n",
        "if os.path.exists(\"/mnt/data/Fake.csv\") and os.path.exists(\"/mnt/data/True.csv\"):\n",
        "    FAKE_CSV = \"/mnt/data/Fake.csv\"\n",
        "    TRUE_CSV = \"/mnt/data/True.csv\"\n",
        "\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "LR = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_RATIO = 0.06\n",
        "PATIENCE = 1              # Early stopping patience (in eval steps)\n",
        "\n",
        "# Which text columns to concatenate (adjust to your CSV headers)\n",
        "TEXT_COLS = [\"title\", \"text\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def set_all_seeds(seed: int = 42):\n",
        "    set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def read_news_csv(path: str, label: int) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.copy()\n",
        "    df[\"label\"] = label\n",
        "    for col in TEXT_COLS:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"\n",
        "    return df\n",
        "\n",
        "def build_text(row: pd.Series, cols: List[str]) -> str:\n",
        "    parts = []\n",
        "    for c in cols:\n",
        "        val = \"\" if pd.isna(row.get(c, \"\")) else str(row[c])\n",
        "        parts.append(val.strip())\n",
        "    return \"\\n\\n\".join([p for p in parts if p])\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset wrapper\n",
        "# -----------------------------\n",
        "class NewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings: Dict[str, Any], labels: List[int]):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# -----------------------------\n",
        "# Metric function\n",
        "# -----------------------------\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    preds = (probs[:, 1] >= 0.5).astype(int)\n",
        "    report = classification_report(labels, preds, output_dict=True, zero_division=0)\n",
        "    return {\n",
        "        \"precision_macro\": report[\"macro avg\"][\"precision\"],\n",
        "        \"recall_macro\": report[\"macro avg\"][\"recall\"],\n",
        "        \"f1_macro\": report[\"macro avg\"][\"f1-score\"],\n",
        "        \"accuracy\": report[\"accuracy\"],\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    set_all_seeds(SEED)\n",
        "\n",
        "    # 1) Load data\n",
        "    if not os.path.exists(FAKE_CSV) or not os.path.exists(TRUE_CSV):\n",
        "        print(f\"Could not find CSVs at:\\n  FAKE: {FAKE_CSV}\\n  TRUE: {TRUE_CSV}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    fake_df = read_news_csv(FAKE_CSV, label=0)  # 0 = FAKE\n",
        "    true_df = read_news_csv(TRUE_CSV, label=1)  # 1 = TRUE\n",
        "\n",
        "    df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "    df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "    df[\"text_joined\"] = df.apply(lambda r: build_text(r, TEXT_COLS), axis=1)\n",
        "    df = df[[\"text_joined\", \"label\"]].dropna().reset_index(drop=True)\n",
        "    df = df[df[\"text_joined\"].str.strip().str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Total samples: {len(df)}  (FAKE={sum(df.label==0)}, TRUE={sum(df.label==1)})\")\n",
        "\n",
        "    # 2) Train/Val split\n",
        "    train_df, val_df = train_test_split(\n",
        "        df,\n",
        "        test_size=0.15,\n",
        "        random_state=SEED,\n",
        "        stratify=df[\"label\"]\n",
        "    )\n",
        "\n",
        "    # 3) Tokenizer & encodings\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    def tokenize_texts(texts: List[str]):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "\n",
        "    train_enc = tokenize_texts(train_df[\"text_joined\"].tolist())\n",
        "    val_enc = tokenize_texts(val_df[\"text_joined\"].tolist())\n",
        "\n",
        "    train_ds = NewsDataset(train_enc, train_df[\"label\"].astype(int).tolist())\n",
        "    val_ds = NewsDataset(val_enc, val_df[\"label\"].astype(int).tolist())\n",
        "\n",
        "    # 4) Class weights\n",
        "    class_labels = np.array([0, 1])\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=class_labels,\n",
        "        y=train_df[\"label\"].values\n",
        "    )\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    # 5) Model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "    # 6) Training args\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(train_ds) / BATCH_SIZE)\n",
        "    eval_steps = max(1, steps_per_epoch // 2)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        learning_rate=LR,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        eval_strategy=\"steps\",      # <-- correct arg name\n",
        "        eval_steps=eval_steps,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=eval_steps,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        logging_steps=max(1, steps_per_epoch // 4),\n",
        "        report_to=\"none\",\n",
        "        seed=SEED\n",
        "    )\n",
        "\n",
        "    # 7) Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
        "    )\n",
        "\n",
        "    # 8) Patch the loss function to use class weights.\n",
        "    #    Accept num_items_in_batch to match HF Trainer signature.\n",
        "    def compute_loss_with_weights(model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        fwd_kwargs = {\n",
        "            \"input_ids\": inputs[\"input_ids\"],\n",
        "            \"attention_mask\": inputs.get(\"attention_mask\"),\n",
        "        }\n",
        "        # DeBERTa typically doesn't have token_type_ids; pass only if present.\n",
        "        if \"token_type_ids\" in inputs:\n",
        "            fwd_kwargs[\"token_type_ids\"] = inputs[\"token_type_ids\"]\n",
        "\n",
        "        outputs = model(**fwd_kwargs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    trainer.compute_loss = compute_loss_with_weights\n",
        "\n",
        "    # 9) Train\n",
        "    trainer.train()\n",
        "\n",
        "    # 10) Save best model + tokenizer\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    print(f\"✅ Saved DeBERTa fake-news model to: {OUTPUT_DIR}\")\n",
        "\n",
        "    # 11) Evaluation + threshold tuning on validation set\n",
        "    preds = trainer.predict(val_ds)\n",
        "    logits = preds.predictions\n",
        "    labels = preds.label_ids\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()[:, 1]\n",
        "\n",
        "    # (a) Default threshold 0.5\n",
        "    default_preds = (probs >= 0.5).astype(int)\n",
        "    print(\"\\n📊 Classification Report (threshold=0.5):\")\n",
        "    print(classification_report(labels, default_preds, digits=4, zero_division=0))\n",
        "    print(\"📉 Confusion Matrix (threshold=0.5):\")\n",
        "    print(confusion_matrix(labels, default_preds))\n",
        "\n",
        "    # (b) Tune threshold by maximizing F1\n",
        "    precisions, recalls, thresholds = precision_recall_curve(labels, probs)\n",
        "    f1s = 2 * (precisions * recalls) / (precisions + recalls + 1e-12)\n",
        "    best_idx = np.nanargmax(f1s)\n",
        "    best_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "    print(f\"\\n🔧 Tuned threshold for best F1: {best_threshold:.4f}\")\n",
        "    tuned_preds = (probs >= best_threshold).astype(int)\n",
        "    print(\"📊 Classification Report (tuned threshold):\")\n",
        "    print(classification_report(labels, tuned_preds, digits=4, zero_division=0))\n",
        "    print(\"📉 Confusion Matrix (tuned threshold):\")\n",
        "    print(confusion_matrix(labels, tuned_preds))\n",
        "\n",
        "    # Save metadata\n",
        "    meta = {\n",
        "        \"model_name\": MODEL_NAME,\n",
        "        \"output_dir\": OUTPUT_DIR,\n",
        "        \"max_length\": MAX_LENGTH,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"learning_rate\": LR,\n",
        "        \"class_weights\": class_weights.tolist(),\n",
        "        \"seed\": SEED\n",
        "    }\n",
        "    with open(os.path.join(OUTPUT_DIR, \"training_meta.json\"), \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "    print(f\"\\n📝 Saved training metadata to {os.path.join(OUTPUT_DIR, 'training_meta.json')}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d3c8fe13c876425a9116a157f86ba5e3",
            "416e30869a8a4ae687e9c002953af2a4",
            "48e53d4b9aec4779a77e7cd3f32cd4c6",
            "0cc8710f98f0455ea758320cc6e99b6c",
            "b601eb1ef02a4b758462ca035f8e6ced",
            "06580a32cd094dd69ef92959caae24f0",
            "ffd90e022e1944dba0355d379108466b",
            "1bdbd838beb54728ae6268584798e7d3",
            "6a15d34491fa4ba68196c7aaab8ebb29",
            "02705f6f33a74162b191d29412bbe9fc",
            "cbe38c203ee9403bbd7e0b1a651992a2",
            "fbe5e95984a746cb90cd416c6c7bb6cc",
            "b8e8c59bf18341f0bc263e93cfc88de0",
            "cb68dd6485fb449ca55a1a7cec968d9f",
            "a991586d9a584e1d95faa31bfdd3d273",
            "6a8c37896cc64638867f58dae34f3982",
            "914e067bb0e84c178f3f904d8cf14a7f",
            "3740ef38a2524f28b0d19491c35c5d4a",
            "51fd5cba10fa413d99d904cda39c8c5c",
            "846ad69be7774d85950b82c03ce0f5ec",
            "e77e4a73f8a546b59bf6cc6a240f0f75",
            "64a0f943d49b4d23b237b66ca01d3b6e",
            "fd730031c2ab4df587a5ed754decc697",
            "fdc2df91f75d4501bad26d727c56ef0a",
            "60621ed274ae400f95c5bd2f5b804494",
            "de18a8ff73954a61b478da68b4179a02",
            "69eec09aa0054bf69e3492e44fe026d6",
            "bea65c9d5ed54d8f81e57db5d4c4b9cd",
            "fce74a63c7fe4dfbb4c54620fdde7577",
            "6b462df983544bcdb31eb4bbd667a296",
            "400dc6e072ba44d8ab78532e2912e52e",
            "12c67326cc2c4118906bf9732534749e",
            "af95146f216944338da39cc0a6b753df",
            "0a937f51f82f44089b799feb683cafc9",
            "3a0aac0e8928428eb52051b14fa62e21",
            "86c472c2007c495490ba2e01eb9a8cc0",
            "8a66b08864e940b7b92a4801243247b7",
            "8160a4911aca47bc8e92f400570c2e2d",
            "fbd72c9bc0124c4aaaea29a4fafa626c",
            "b0c920e841374f7286b784b8e12e04a3",
            "2d619ee36e2c4110bcd7f7c2aed92a64",
            "f2b4e86e0062463cb5ace8becb6c7ff5",
            "14023b170f294c3fb97181aef2ad152e",
            "cc1f52f95ed644e19c3c752efc8be594",
            "15219b67de8146c1a492c54d6f3c67a0",
            "93b0ca01cda249d68803ae4b87e72971",
            "bf64a986564c4cb4858134f605229372",
            "c42bf169b337492c9c918e2b192ae4d7",
            "77d7c77b5b8a4b27a8c31afc2900cb7c",
            "fd605fcc23794e55ad651de26e5073b2",
            "0dace0a2bf3a4e99bd95165fd522b242",
            "8d7ec7b4c1d94b4bb7fc8dd6519e8631",
            "b88a3f0ffbcb4868821fb74621f18b8c",
            "7ecea7744a7b453a88534b50bf473e49",
            "c2ef0f4ae28b4346a9895547c6319181"
          ]
        },
        "id": "MeZadjtMUEu5",
        "outputId": "74f0e322-5556-45df-d8f0-b64ab1e5f8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 44898  (FAKE=23481, TRUE=21417)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c8fe13c876425a9116a157f86ba5e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbe5e95984a746cb90cd416c6c7bb6cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd730031c2ab4df587a5ed754decc697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a937f51f82f44089b799feb683cafc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-3579108575.py:209: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15219b67de8146c1a492c54d6f3c67a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7156' max='14313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 7156/14313 08:35 < 08:35, 13.87 it/s, Epoch 1.50/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2385</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.999858</td>\n",
              "      <td>0.999844</td>\n",
              "      <td>0.999851</td>\n",
              "      <td>0.999852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4770</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='414' max='842' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [414/842 00:09 < 00:09, 43.80 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7155' max='14313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 7155/14313 08:58 < 08:58, 13.29 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2385</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.999858</td>\n",
              "      <td>0.999844</td>\n",
              "      <td>0.999851</td>\n",
              "      <td>0.999852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4770</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7155</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved DeBERTa fake-news model to: ./deberta-small-fake-news\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Classification Report (threshold=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000      3522\n",
            "           1     1.0000    1.0000    1.0000      3213\n",
            "\n",
            "    accuracy                         1.0000      6735\n",
            "   macro avg     1.0000    1.0000    1.0000      6735\n",
            "weighted avg     1.0000    1.0000    1.0000      6735\n",
            "\n",
            "📉 Confusion Matrix (threshold=0.5):\n",
            "[[3522    0]\n",
            " [   0 3213]]\n",
            "\n",
            "🔧 Tuned threshold for best F1: 0.0009\n",
            "📊 Classification Report (tuned threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9997    0.9999      3522\n",
            "           1     0.9997    1.0000    0.9998      3213\n",
            "\n",
            "    accuracy                         0.9999      6735\n",
            "   macro avg     0.9998    0.9999    0.9999      6735\n",
            "weighted avg     0.9999    0.9999    0.9999      6735\n",
            "\n",
            "📉 Confusion Matrix (tuned threshold):\n",
            "[[3521    1]\n",
            " [   0 3213]]\n",
            "\n",
            "📝 Saved training metadata to ./deberta-small-fake-news/training_meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ mdna_transfer_from_fake_news.py — Enhanced to Improve Non-Fraud Detection Too\n",
        "\n",
        "import os, json, torch, numpy as np, random, re\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 6\n",
        "MAX_CHUNKS_PER_DOC = 7\n",
        "MODEL_PATH = \"./deberta-small-fake-news\"\n",
        "SAVE_PATH = \"./deberta-mdna-transfer\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Set Seeds for Reproducibility\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📚 Load and Clean Data\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw.get(\"data\") if isinstance(raw, dict) else raw\n",
        "\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\", \"Label\", \"true_label\"]\n",
        "CANDIDATE_TEXT_FIELDS = [\"text\", \"Text\", \"content\", \"document\"]\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "\n",
        "cleaned = []\n",
        "for rec in raw:\n",
        "    text = next((rec.get(f) for f in CANDIDATE_TEXT_FIELDS if rec.get(f)), None)\n",
        "    label_raw = next((rec.get(f) for f in CANDIDATE_LABEL_FIELDS if rec.get(f)), None)\n",
        "    if not text: continue\n",
        "    label = str(label_raw).strip().lower().replace(\" \", \"_\")\n",
        "    label = \"fraud\" if label in [\"fraud\", \"1\"] else \"non_fraud\"\n",
        "    cleaned.append({\"text\": text.strip(), \"label\": LABEL_MAP[label]})\n",
        "\n",
        "texts = [r[\"text\"] for r in cleaned]\n",
        "labels = [r[\"label\"] for r in cleaned]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=SEED\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# ✂️ Tokenize & Chunk Texts\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "\n",
        "\n",
        "def chunk_text(text, label):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        chunk = tokens[i:i+MAX_LEN] + [tokenizer.pad_token_id]*(MAX_LEN - len(tokens[i:i+MAX_LEN]))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in chunk]\n",
        "        chunks.append((chunk, mask, label))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "\n",
        "class ChunkedDataset(Dataset):\n",
        "    def __init__(self, texts, labels, cache_file):\n",
        "        if os.path.exists(cache_file):\n",
        "            self.samples = torch.load(cache_file)\n",
        "        else:\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                all_chunks = executor.map(lambda x: chunk_text(*x), zip(texts, labels))\n",
        "                self.samples = [item for sublist in all_chunks for item in sublist]\n",
        "                torch.save(self.samples, cache_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, mask, label = self.samples[idx]\n",
        "        return {\"input_ids\": torch.tensor(chunk), \"attention_mask\": torch.tensor(mask), \"labels\": torch.tensor(label)}\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "train_dataset = ChunkedDataset(train_texts, train_labels, \"train_chunks.pt\")\n",
        "val_dataset = ChunkedDataset(val_texts, val_labels, \"val_chunks.pt\")\n",
        "\n",
        "# -----------------------------\n",
        "# 🧠 Load Model & Partially Unfreeze Last 6 Layers\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    match = re.search(r'encoder\\\\.layer\\\\.(\\\\d+)', name)\n",
        "    if match:\n",
        "        layer = int(match.group(1))\n",
        "        if layer < model.config.num_hidden_layers - 6:\n",
        "            param.requires_grad = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📊 Class Weighting (Balanced)\n",
        "weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=np.array(labels))\n",
        "class_weights = torch.tensor(weights).float().to(DEVICE)\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        loss = torch.nn.CrossEntropyLoss(weight=class_weights)(outputs.logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Metrics\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds),\n",
        "        \"recall\": recall_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# ⚙️ Training Arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=SAVE_PATH,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    seed=SEED,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=2,\n",
        "    dataloader_num_workers=2,\n",
        "    max_grad_norm=1.0\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 🏋️‍♀️ Train\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "print(\"✅ Training complete and model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "c54f6l28UEnE",
        "outputId": "67a6dcba-5616-4e17-f779-9a1941c1e4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3178380519.py:158: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='264' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [264/396 00:42 < 00:21, 6.19 it/s, Epoch 4/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.687398</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.667857</td>\n",
              "      <td>0.925743</td>\n",
              "      <td>0.775934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.466300</td>\n",
              "      <td>0.696937</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.910891</td>\n",
              "      <td>0.793103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.466300</td>\n",
              "      <td>0.880464</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.603960</td>\n",
              "      <td>0.681564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.471100</td>\n",
              "      <td>1.099018</td>\n",
              "      <td>0.646875</td>\n",
              "      <td>0.740541</td>\n",
              "      <td>0.678218</td>\n",
              "      <td>0.708010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ evaluate_chunks.py — Mean-Softmax, Max-Prob Aggregation, Threshold Tuning\n",
        "import json, torch, numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "MAX_CHUNKS_PER_DOC = 7\n",
        "AGG_METHOD = \"mean_softmax\"  # or \"max_prob\"\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# Load Data + Tokenizer + Model\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw[\"data\"] if isinstance(raw, dict) else raw\n",
        "\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "INV_LABEL = {0: \"non_fraud\", 1: \"fraud\"}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./deberta-mdna-transfer\").to(DEVICE)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./deberta-mdna-transfer\")\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------\n",
        "def chunk_text(text):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        chunk = tokens[i:i+MAX_LEN]\n",
        "        chunk += [tokenizer.pad_token_id] * (MAX_LEN - len(chunk))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in chunk]\n",
        "        chunks.append((chunk, mask))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "def aggregate(logits_list, method=\"mean_softmax\"):\n",
        "    logits = torch.stack(logits_list)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    if method == \"mean_softmax\":\n",
        "        return probs.mean(dim=0)\n",
        "    elif method == \"max_prob\":\n",
        "        max_idx = probs[:, 1].argmax()\n",
        "        return probs[max_idx]\n",
        "    else:\n",
        "        raise ValueError(\"Unknown aggregation method.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Predict document-level labels\n",
        "all_labels, all_probs = [], []\n",
        "for rec in tqdm(raw, desc=\"Evaluating...\"):\n",
        "    label_str = rec.get(\"label\", rec.get(\"true_label\", rec.get(\"Label\", \"\")))\n",
        "    label_cleaned = str(label_str).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "    label = LABEL_MAP[label_cleaned]\n",
        "    chunks = chunk_text(rec[\"text\"])\n",
        "    chunk_logits = []\n",
        "\n",
        "    for chunk, mask in chunks:\n",
        "        inputs = {\n",
        "            \"input_ids\": torch.tensor([chunk]).to(DEVICE),\n",
        "            \"attention_mask\": torch.tensor([mask]).to(DEVICE)\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            out = model(**inputs).logits.squeeze()\n",
        "        chunk_logits.append(out)\n",
        "\n",
        "    prob = aggregate(chunk_logits, method=AGG_METHOD)\n",
        "    all_labels.append(label)\n",
        "    all_probs.append(prob.cpu().numpy())\n",
        "\n",
        "# -----------------------------\n",
        "# Tune threshold using PR curve\n",
        "all_probs_np = np.array(all_probs)\n",
        "true = np.array(all_labels)\n",
        "probs_fraud = all_probs_np[:, 1]\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(true, probs_fraud)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(f\"\\n🏁 Best threshold by F1: {best_thresh:.4f}\")\n",
        "print(f\"📈 Precision: {prec[best_idx]:.3f} | Recall: {rec[best_idx]:.3f} | F1: {f1_scores[best_idx]:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Report at best threshold\n",
        "preds = (probs_fraud >= best_thresh).astype(int)\n",
        "\n",
        "print(\"\\n📊 Classification Report (Tuned Threshold):\")\n",
        "print(classification_report(true, preds, target_names=[\"non_fraud\", \"fraud\"]))\n",
        "\n",
        "print(\"📌 Confusion Matrix:\")\n",
        "print(confusion_matrix(true, preds))\n",
        "\n",
        "# -----------------------------\n",
        "# ROC-AUC\n",
        "roc_auc = roc_auc_score(true, probs_fraud)\n",
        "print(f\"🎯 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "hiXNgF7cYcdU",
        "outputId": "cb92d613-b90c-4337-e3dd-3623c1b91b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating...: 100%|██████████| 338/338 [00:39<00:00,  8.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏁 Best threshold by F1: 0.5442\n",
            "📈 Precision: 0.896 | Recall: 0.990 | F1: 0.941\n",
            "\n",
            "📊 Classification Report (Tuned Threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   non_fraud       0.98      0.83      0.90       138\n",
            "       fraud       0.90      0.99      0.94       200\n",
            "\n",
            "    accuracy                           0.93       338\n",
            "   macro avg       0.94      0.91      0.92       338\n",
            "weighted avg       0.93      0.93      0.92       338\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[115  23]\n",
            " [  2 198]]\n",
            "🎯 ROC-AUC Score: 0.9001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G83gsS31cxw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXvS73VgcxuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Colab: Upload zips -> sample <2001 -> save mdna_sample -> download zip ====\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import tempfile\n",
        "from collections import Counter\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# -----------------------\n",
        "# Config you can tweak\n",
        "# -----------------------\n",
        "MAX_PER_CLASS = 200\n",
        "YEAR_CUTOFF = 2006        # keep strictly < 2001 (i.e., up to 2000)\n",
        "RANDOM_SEED = 42\n",
        "CLASSES = (\"fraud\", \"non_fraud\")\n",
        "OUTPUT_DIR = \"mdna_sample\"\n",
        "\n",
        "# Filename pattern: capture a 4-digit year that is preceded by an underscore, anywhere.\n",
        "# Examples matched: \"5272_2000.txt\", \"acme_1998_v2.txt\", \"abc_1975-anything.TXT\"\n",
        "YEAR_RE = re.compile(r\"_(19\\d{2}|20\\d{2})(?:\\D|$)\", re.IGNORECASE)\n",
        "\n",
        "def parse_year_from_filename(name):\n",
        "    m = YEAR_RE.search(name)     # <-- search, not match\n",
        "    if not m:\n",
        "        return None\n",
        "    return int(m.group(1))\n",
        "\n",
        "def ensure_dir(path):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def infer_class_from_path(path_lower):\n",
        "    # zip internals use forward slashes\n",
        "    if \"/non-fraud/\" in path_lower or \"/non_fraud/\" in path_lower or \"/nonfraud/\" in path_lower:\n",
        "        return \"non_fraud\"\n",
        "    if \"/fraud/\" in path_lower:\n",
        "        return \"fraud\"\n",
        "    return None\n",
        "\n",
        "def infer_class_from_zipname(zip_basename_lower):\n",
        "    if \"non-fraud\" in zip_basename_lower or \"non_fraud\" in zip_basename_lower or \"nonfraud\" in zip_basename_lower:\n",
        "        return \"non_fraud\"\n",
        "    if \"fraud\" in zip_basename_lower:\n",
        "        return \"fraud\"\n",
        "    return None\n",
        "\n",
        "def collect_candidates_from_zip(zippath, tmp_extract_root):\n",
        "    \"\"\"\n",
        "    Extract zip to a dedicated folder and collect eligible files per class.\n",
        "    Returns: { 'fraud': [abs_paths...], 'non_fraud': [...] }\n",
        "    \"\"\"\n",
        "    buckets = {c: [] for c in CLASSES}\n",
        "    base_name = os.path.splitext(os.path.basename(zippath))[0]\n",
        "    extract_here = os.path.join(tmp_extract_root, base_name)\n",
        "    ensure_dir(extract_here)\n",
        "\n",
        "    with zipfile.ZipFile(zippath, \"r\") as zf:\n",
        "        zf.extractall(extract_here)\n",
        "\n",
        "    # Fallback class from the zip filename (handles zips like 'Fraud_MDA-...zip')\n",
        "    zip_class_hint = infer_class_from_zipname(os.path.basename(zippath).lower())\n",
        "\n",
        "    for root, _, files_in_dir in os.walk(extract_here):\n",
        "        root_lower = root.lower()\n",
        "        # Prefer internal path hint; else use zip name hint\n",
        "        cls_hint = infer_class_from_path(root_lower) or zip_class_hint\n",
        "\n",
        "        for fn in files_in_dir:\n",
        "            if not fn.lower().endswith(\".txt\"):\n",
        "                continue\n",
        "            year = parse_year_from_filename(fn)\n",
        "            if year is None or year < YEAR_CUTOFF:\n",
        "                continue\n",
        "\n",
        "            full = os.path.join(root, fn)\n",
        "            # Light read to ensure file is accessible\n",
        "            try:\n",
        "                with io.open(full, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    _ = f.read(512)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            if cls_hint in buckets:\n",
        "                buckets[cls_hint].append(full)\n",
        "            # If we still can't infer class, we skip (we only want labeled classes)\n",
        "\n",
        "    return buckets\n",
        "\n",
        "def sample_and_copy(files, dst_dir):\n",
        "    random.seed(RANDOM_SEED)\n",
        "    if len(files) > MAX_PER_CLASS:\n",
        "        files = random.sample(files, MAX_PER_CLASS)\n",
        "\n",
        "    ensure_dir(dst_dir)\n",
        "    used = set()\n",
        "    copied = 0\n",
        "    for src in files:\n",
        "        name = os.path.basename(src)\n",
        "        dest = os.path.join(dst_dir, name)\n",
        "        # Avoid collisions\n",
        "        if name in used or os.path.exists(dest):\n",
        "            stem, ext = os.path.splitext(name)\n",
        "            i = 1\n",
        "            while True:\n",
        "                alt = f\"{stem}__dup{i}{ext}\"\n",
        "                dest = os.path.join(dst_dir, alt)\n",
        "                if not os.path.exists(dest):\n",
        "                    name = alt\n",
        "                    break\n",
        "                i += 1\n",
        "        used.add(name)\n",
        "        shutil.copy2(src, dest)\n",
        "        copied += 1\n",
        "    return copied\n",
        "\n",
        "def by_year_counts(folder):\n",
        "    \"\"\"Return Counter of years for files in folder based on filename.\"\"\"\n",
        "    cnt = Counter()\n",
        "    if not os.path.isdir(folder):\n",
        "        return cnt\n",
        "    for fn in os.listdir(folder):\n",
        "        y = parse_year_from_filename(fn)\n",
        "        if y is not None:\n",
        "            cnt[y] += 1\n",
        "    return cnt\n",
        "\n",
        "def zip_dir(dir_path, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files_in_dir in os.walk(dir_path):\n",
        "            for fn in files_in_dir:\n",
        "                abs_p = os.path.join(root, fn)\n",
        "                rel_p = os.path.relpath(abs_p, dir_path)\n",
        "                zf.write(abs_p, rel_p)\n",
        "\n",
        "# =======================\n",
        "# Step 1: Upload ZIPs\n",
        "# =======================\n",
        "uploaded_paths = []\n",
        "if IN_COLAB:\n",
        "    print(\"📤 Upload one or more ZIP files...\")\n",
        "    uploaded = files.upload()  # user selects zips from laptop\n",
        "    for name, data in uploaded.items():\n",
        "        with open(name, \"wb\") as f:\n",
        "            f.write(data)\n",
        "        uploaded_paths.append(os.path.abspath(name))\n",
        "    if not uploaded_paths:\n",
        "        raise SystemExit(\"No files uploaded.\")\n",
        "else:\n",
        "    raise SystemExit(\"This notebook cell is intended for Google Colab (files.upload).\")\n",
        "\n",
        "# =======================\n",
        "# Step 2: Process ZIPs\n",
        "# =======================\n",
        "# Clean any previous output\n",
        "if os.path.isdir(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "ensure_dir(os.path.join(OUTPUT_DIR, \"fraud\"))\n",
        "ensure_dir(os.path.join(OUTPUT_DIR, \"non_fraud\"))\n",
        "\n",
        "totals = {c: [] for c in CLASSES}\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmp_root:\n",
        "    for zp in uploaded_paths:\n",
        "        try:\n",
        "            buckets = collect_candidates_from_zip(zp, tmp_root)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Failed to handle {os.path.basename(zp)}: {e}\")\n",
        "            continue\n",
        "        for c in CLASSES:\n",
        "            totals[c].extend(buckets.get(c, []))\n",
        "\n",
        "    # Deduplicate (within this run) and sample+copy\n",
        "    for c in CLASSES:\n",
        "        unique_files = list(dict.fromkeys(totals[c]))  # preserve order, remove dups\n",
        "        copied = sample_and_copy(unique_files, os.path.join(OUTPUT_DIR, c))\n",
        "        print(f\"{c:>10}: eligible={len(unique_files):4d}, copied={copied:3d} (max {MAX_PER_CLASS})\")\n",
        "\n",
        "print(\"\\n✅ Done sampling. Saved to:\", os.path.abspath(OUTPUT_DIR))\n",
        "\n",
        "# =======================\n",
        "# Step 3: By-year counts\n",
        "# =======================\n",
        "for c in CLASSES:\n",
        "    cnt = by_year_counts(os.path.join(OUTPUT_DIR, c))\n",
        "    if cnt:\n",
        "        print(f\"\\n📅 By-year counts for '{c}' (in sample):\")\n",
        "        for y in sorted(cnt):\n",
        "            print(f\"  {y}: {cnt[y]}\")\n",
        "    else:\n",
        "        print(f\"\\n📅 By-year counts for '{c}': (no files)\")\n",
        "\n",
        "# =======================\n",
        "# Step 4: Downloadable ZIP\n",
        "# =======================\n",
        "zip_name = \"mdna_sample.zip\"\n",
        "zip_dir(OUTPUT_DIR, zip_name)\n",
        "print(\"\\n📦 Created archive:\", os.path.abspath(zip_name))\n",
        "\n",
        "if IN_COLAB:\n",
        "    files.download(zip_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "0749YNOUcxqs",
        "outputId": "557c1f18-e017-4a54-f387-0ec565ed3ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 Upload one or more ZIP files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f542babc-f560-4905-822e-1122fb79ec99\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f542babc-f560-4905-822e-1122fb79ec99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fraud_MDA_cleaned.zip to Fraud_MDA_cleaned (1).zip\n",
            "Saving Non-fraud_MDA_cleaned.zip to Non-fraud_MDA_cleaned (1).zip\n",
            "     fraud: eligible= 218, copied=200 (max 200)\n",
            " non_fraud: eligible= 728, copied=200 (max 200)\n",
            "\n",
            "✅ Done sampling. Saved to: /content/mdna_sample\n",
            "\n",
            "📅 By-year counts for 'fraud' (in sample):\n",
            "  2006: 13\n",
            "  2007: 15\n",
            "  2008: 12\n",
            "  2009: 33\n",
            "  2010: 31\n",
            "  2011: 25\n",
            "  2012: 20\n",
            "  2013: 14\n",
            "  2014: 8\n",
            "  2015: 10\n",
            "  2016: 9\n",
            "  2017: 8\n",
            "  2018: 2\n",
            "\n",
            "📅 By-year counts for 'non_fraud' (in sample):\n",
            "  2006: 12\n",
            "  2007: 13\n",
            "  2008: 22\n",
            "  2009: 18\n",
            "  2010: 20\n",
            "  2011: 19\n",
            "  2012: 10\n",
            "  2013: 15\n",
            "  2014: 9\n",
            "  2015: 11\n",
            "  2016: 12\n",
            "  2017: 11\n",
            "  2018: 14\n",
            "  2019: 14\n",
            "\n",
            "📦 Created archive: /content/mdna_sample.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9e9db16-5606-4524-8aa0-8abb15c6e95f\", \"mdna_sample.zip\", 8707677)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Build mdna_samples.json from mdna_sample.zip ===\n",
        "import os, io, json, zipfile, shutil\n",
        "\n",
        "ZIP_NAME = \"mdna_sample.zip\"         # <-- must exist in current working dir\n",
        "EXTRACT_DIR = \"./mdna_sample_extracted\"\n",
        "OUTPUT_JSON = \"mdna_samples.json\"\n",
        "\n",
        "# 1) Ensure the zip exists (if not, let you upload it)\n",
        "if not os.path.isfile(ZIP_NAME):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(f\"⚠️ {ZIP_NAME} not found. Please upload it now.\")\n",
        "        uploaded = files.upload()\n",
        "        if ZIP_NAME not in uploaded:\n",
        "            raise FileNotFoundError(f\"'{ZIP_NAME}' was not uploaded.\")\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"{ZIP_NAME} not found and upload failed: {e}\")\n",
        "\n",
        "# 2) Fresh extract\n",
        "if os.path.isdir(EXTRACT_DIR):\n",
        "    shutil.rmtree(EXTRACT_DIR)\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, \"r\") as zf:\n",
        "    zf.extractall(EXTRACT_DIR)\n",
        "\n",
        "# 3) Walk extracted folders -> collect .txt into JSON\n",
        "samples = []\n",
        "per_class_counts = {\"fraud\": 0, \"non_fraud\": 0, \"unknown\": 0}\n",
        "\n",
        "def infer_class_from_path(p: str):\n",
        "    p = p.replace(\"\\\\\", \"/\").lower()\n",
        "    if \"/non_fraud/\" in p or \"/non-fraud/\" in p or \"/nonfraud/\" in p:\n",
        "        return \"non_fraud\"\n",
        "    if \"/fraud/\" in p:\n",
        "        return \"fraud\"\n",
        "    # If structure is mdna_sample/<class>/..., handle that too\n",
        "    parts = p.split(\"/\")\n",
        "    for name in (\"fraud\", \"non_fraud\", \"non-fraud\", \"nonfraud\"):\n",
        "        if name in parts:\n",
        "            return \"non_fraud\" if \"non\" in name else \"fraud\"\n",
        "    return \"unknown\"\n",
        "\n",
        "for root, _, files_in_dir in os.walk(EXTRACT_DIR):\n",
        "    for fn in files_in_dir:\n",
        "        if not fn.lower().endswith(\".txt\"):\n",
        "            continue\n",
        "        fpath = os.path.join(root, fn)\n",
        "        cls = infer_class_from_path(fpath)\n",
        "        try:\n",
        "            with io.open(fpath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                text = f.read().strip()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not text:\n",
        "            continue\n",
        "        label = \"Fraud\" if cls == \"fraud\" else (\"Non-Fraud\" if cls == \"non_fraud\" else None)\n",
        "        if label is None:\n",
        "            per_class_counts[\"unknown\"] += 1\n",
        "            continue\n",
        "        samples.append({\"text\": text, \"true_label\": label})\n",
        "        per_class_counts[cls] += 1\n",
        "\n",
        "# 4) Save JSON\n",
        "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(samples, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Saved {OUTPUT_JSON} with {len(samples)} samples.\")\n",
        "print(\"Counts:\", per_class_counts)\n",
        "\n",
        "# (Optional) peek a couple of records\n",
        "for i, s in enumerate(samples[:2]):\n",
        "    print(f\"\\nSample {i+1}: label={s['true_label']}\\n{text[:200]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdLykKfAdVUx",
        "outputId": "d173b361-871d-46b2-fdb8-e402fbc8796a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved mdna_samples.json with 400 samples.\n",
            "Counts: {'fraud': 200, 'non_fraud': 200, 'unknown': 0}\n",
            "\n",
            "Sample 1: label=Fraud\n",
            "ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS TopicPageOverview 29Financial Summary 32Critical Accounting Estimates 32Accounting Standards 40Consolidate...\n",
            "\n",
            "Sample 2: label=Fraud\n",
            "ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS TopicPageOverview 29Financial Summary 32Critical Accounting Estimates 32Accounting Standards 40Consolidate...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# ---------- 1) Load JSON (array or dict wrapper) ----------\n",
        "with open(\"mdna_samples.json\", \"r\") as f:\n",
        "    raw = json.load(f)\n",
        "\n",
        "# If file is a dict wrapper, pick the first list-like field\n",
        "if isinstance(raw, dict):\n",
        "    # common wrappers\n",
        "    for k in [\"data\", \"records\", \"items\", \"rows\", \"samples\"]:\n",
        "        if k in raw and isinstance(raw[k], list):\n",
        "            raw = raw[k]\n",
        "            break\n",
        "    # if still dict, try any list value\n",
        "    if isinstance(raw, dict):\n",
        "        for v in raw.values():\n",
        "            if isinstance(v, list):\n",
        "                raw = v\n",
        "                break\n",
        "\n",
        "if not isinstance(raw, list):\n",
        "    raise ValueError(\"Expected a list of records in mdna_samples.json\")\n",
        "\n",
        "# ---------- 2) Helpers to find label/text in messy schemas ----------\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\",\"Label\",\"true_label\",\"target\",\"class\",\"Class\",\"y\",\"tag\"]\n",
        "CANDIDATE_TEXT_FIELDS  = [\"text\",\"Text\",\"content\",\"document\",\"body\",\"mdna\",\"mdna_text\",\"md&a\",\"mdna_body\"]\n",
        "\n",
        "def find_field(rec, names):\n",
        "    for n in names:\n",
        "        if n in rec:\n",
        "            return rec[n]\n",
        "    # one-level nested search\n",
        "    for v in rec.values():\n",
        "        if isinstance(v, dict):\n",
        "            for n in names:\n",
        "                if n in v:\n",
        "                    return v[n]\n",
        "    return None\n",
        "\n",
        "def normalize_label(val):\n",
        "    if val is None: return \"unknown\"\n",
        "    s = str(val).strip().lower()\n",
        "    # unify common variants\n",
        "    s = s.replace(\"-\", \"_\").replace(\" \", \"_\")\n",
        "    if s in {\"nonfraud\",\"non_fraud\",\"not_fraud\",\"clean\"}:\n",
        "        return \"non_fraud\"\n",
        "    if s in {\"fraud\",\"is_fraud\",\"positive\"}:\n",
        "        return \"fraud\"\n",
        "    if s in {\"unknown\",\"na\",\"\", \"null\", \"none\"}:\n",
        "        return \"unknown\"\n",
        "    # last resort: if it looks like '0'/'1'\n",
        "    if s.isdigit():\n",
        "        return \"fraud\" if int(s)==1 else \"non_fraud\" if int(s)==0 else \"unknown\"\n",
        "    return s  # keep as-is; we'll validate later\n",
        "\n",
        "def normalize_text(val):\n",
        "    if val is None: return None\n",
        "    s = str(val).strip()\n",
        "    return s if s else None\n",
        "\n",
        "# ---------- 3) Build a clean list; map to ints ----------\n",
        "clean = []\n",
        "bad_schema = 0\n",
        "for rec in raw:\n",
        "    lbl_raw = find_field(rec, CANDIDATE_LABEL_FIELDS)\n",
        "    txt_raw = find_field(rec, CANDIDATE_TEXT_FIELDS)\n",
        "    lbl = normalize_label(lbl_raw)\n",
        "    txt = normalize_text(txt_raw)\n",
        "\n",
        "    if txt is None:\n",
        "        bad_schema += 1\n",
        "        continue\n",
        "\n",
        "    clean.append({\n",
        "        \"text\": txt,\n",
        "        \"label_text\": lbl,     # keep human-readable for audit\n",
        "    })\n",
        "\n",
        "# Counts BEFORE integer mapping\n",
        "pre_counts = Counter([r[\"label_text\"] for r in clean])\n",
        "print(\"Pre-normalized label counts:\", pre_counts, \"| dropped text-missing:\", bad_schema)\n",
        "\n",
        "# Only keep fraud/non_fraud; drop unknowns if any\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "final = []\n",
        "unknown_seen = 0\n",
        "for r in clean:\n",
        "    if r[\"label_text\"] in LABEL_MAP:\n",
        "        r[\"label\"] = LABEL_MAP[r[\"label_text\"]]\n",
        "        final.append({\"text\": r[\"text\"], \"label\": r[\"label\"]})\n",
        "    else:\n",
        "        unknown_seen += 1\n",
        "\n",
        "print(\"Kept:\", len(final), \"Unknown/dropped:\", unknown_seen)\n",
        "print(\"Final counts:\", Counter([r[\"label\"] for r in final]))  # expect {1:188, 0:191} for your file\n",
        "\n",
        "# ---------- 4) Save clean file ----------\n",
        "with open(\"mdna_samples_clean.json\", \"w\") as f:\n",
        "    json.dump(final, f, ensure_ascii=False, indent=2)\n",
        "print(\"✅ Saved mdna_samples_clean.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ2ZdEf3deqr",
        "outputId": "e7a48e6b-3f90-48d3-d41b-c58ab0bdc260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-normalized label counts: Counter({'fraud': 200, 'non_fraud': 200}) | dropped text-missing: 0\n",
            "Kept: 400 Unknown/dropped: 0\n",
            "Final counts: Counter({1: 200, 0: 200})\n",
            "✅ Saved mdna_samples_clean.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03lefzBBdgDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ mdna_transfer_from_fake_news.py — Enhanced to Improve Non-Fraud Detection Too\n",
        "\n",
        "import os, json, torch, numpy as np, random, re\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 6\n",
        "MAX_CHUNKS_PER_DOC = 7\n",
        "MODEL_PATH = \"./deberta-small-fake-news\"\n",
        "SAVE_PATH = \"./deberta-mdna-transfer\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Set Seeds for Reproducibility\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📚 Load and Clean Data\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw.get(\"data\") if isinstance(raw, dict) else raw\n",
        "\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\", \"Label\", \"true_label\"]\n",
        "CANDIDATE_TEXT_FIELDS = [\"text\", \"Text\", \"content\", \"document\"]\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "\n",
        "cleaned = []\n",
        "for rec in raw:\n",
        "    text = next((rec.get(f) for f in CANDIDATE_TEXT_FIELDS if rec.get(f)), None)\n",
        "    label_raw = next((rec.get(f) for f in CANDIDATE_LABEL_FIELDS if rec.get(f)), None)\n",
        "    if not text: continue\n",
        "    label = str(label_raw).strip().lower().replace(\" \", \"_\")\n",
        "    label = \"fraud\" if label in [\"fraud\", \"1\"] else \"non_fraud\"\n",
        "    cleaned.append({\"text\": text.strip(), \"label\": LABEL_MAP[label]})\n",
        "\n",
        "texts = [r[\"text\"] for r in cleaned]\n",
        "labels = [r[\"label\"] for r in cleaned]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=SEED\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# ✂️ Tokenize & Chunk Texts\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "\n",
        "\n",
        "def chunk_text(text, label):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        chunk = tokens[i:i+MAX_LEN] + [tokenizer.pad_token_id]*(MAX_LEN - len(tokens[i:i+MAX_LEN]))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in chunk]\n",
        "        chunks.append((chunk, mask, label))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "\n",
        "class ChunkedDataset(Dataset):\n",
        "    def __init__(self, texts, labels, cache_file):\n",
        "        if os.path.exists(cache_file):\n",
        "            self.samples = torch.load(cache_file)\n",
        "        else:\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                all_chunks = executor.map(lambda x: chunk_text(*x), zip(texts, labels))\n",
        "                self.samples = [item for sublist in all_chunks for item in sublist]\n",
        "                torch.save(self.samples, cache_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, mask, label = self.samples[idx]\n",
        "        return {\"input_ids\": torch.tensor(chunk), \"attention_mask\": torch.tensor(mask), \"labels\": torch.tensor(label)}\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "train_dataset = ChunkedDataset(train_texts, train_labels, \"train_chunks.pt\")\n",
        "val_dataset = ChunkedDataset(val_texts, val_labels, \"val_chunks.pt\")\n",
        "\n",
        "# -----------------------------\n",
        "# 🧠 Load Model & Partially Unfreeze Last 6 Layers\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    match = re.search(r'encoder\\\\.layer\\\\.(\\\\d+)', name)\n",
        "    if match:\n",
        "        layer = int(match.group(1))\n",
        "        if layer < model.config.num_hidden_layers - 6:\n",
        "            param.requires_grad = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📊 Class Weighting (Balanced)\n",
        "weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=np.array(labels))\n",
        "class_weights = torch.tensor(weights).float().to(DEVICE)\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        loss = torch.nn.CrossEntropyLoss(weight=class_weights)(outputs.logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Metrics\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds),\n",
        "        \"recall\": recall_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# ⚙️ Training Arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=SAVE_PATH,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    seed=SEED,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=2,\n",
        "    dataloader_num_workers=2,\n",
        "    max_grad_norm=1.0\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 🏋️‍♀️ Train\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "print(\"✅ Training complete and model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "hZ5VqqMmdf4o",
        "outputId": "a88395a3-1025-4b34-d18a-8434e0cfc4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3178380519.py:158: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='264' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [264/396 00:45 < 00:22, 5.81 it/s, Epoch 4/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.653920</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.639610</td>\n",
              "      <td>0.975248</td>\n",
              "      <td>0.772549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.409800</td>\n",
              "      <td>0.639887</td>\n",
              "      <td>0.690625</td>\n",
              "      <td>0.719149</td>\n",
              "      <td>0.836634</td>\n",
              "      <td>0.773455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.409800</td>\n",
              "      <td>0.709177</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.726087</td>\n",
              "      <td>0.826733</td>\n",
              "      <td>0.773148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.446000</td>\n",
              "      <td>0.975427</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.728070</td>\n",
              "      <td>0.821782</td>\n",
              "      <td>0.772093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ evaluate_chunks.py — Mean-Softmax, Max-Prob Aggregation, Threshold Tuning\n",
        "import json, torch, numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "MAX_CHUNKS_PER_DOC = 7\n",
        "AGG_METHOD = \"mean_softmax\"  # or \"max_prob\"\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# Load Data + Tokenizer + Model\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw[\"data\"] if isinstance(raw, dict) else raw\n",
        "\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "INV_LABEL = {0: \"non_fraud\", 1: \"fraud\"}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./deberta-mdna-transfer\").to(DEVICE)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./deberta-mdna-transfer\")\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------\n",
        "def chunk_text(text):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        chunk = tokens[i:i+MAX_LEN]\n",
        "        chunk += [tokenizer.pad_token_id] * (MAX_LEN - len(chunk))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in chunk]\n",
        "        chunks.append((chunk, mask))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "def aggregate(logits_list, method=\"mean_softmax\"):\n",
        "    logits = torch.stack(logits_list)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    if method == \"mean_softmax\":\n",
        "        return probs.mean(dim=0)\n",
        "    elif method == \"max_prob\":\n",
        "        max_idx = probs[:, 1].argmax()\n",
        "        return probs[max_idx]\n",
        "    else:\n",
        "        raise ValueError(\"Unknown aggregation method.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Predict document-level labels\n",
        "all_labels, all_probs = [], []\n",
        "for rec in tqdm(raw, desc=\"Evaluating...\"):\n",
        "    label_str = rec.get(\"label\", rec.get(\"true_label\", rec.get(\"Label\", \"\")))\n",
        "    label_cleaned = str(label_str).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "    label = LABEL_MAP[label_cleaned]\n",
        "    chunks = chunk_text(rec[\"text\"])\n",
        "    chunk_logits = []\n",
        "\n",
        "    for chunk, mask in chunks:\n",
        "        inputs = {\n",
        "            \"input_ids\": torch.tensor([chunk]).to(DEVICE),\n",
        "            \"attention_mask\": torch.tensor([mask]).to(DEVICE)\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            out = model(**inputs).logits.squeeze()\n",
        "        chunk_logits.append(out)\n",
        "\n",
        "    prob = aggregate(chunk_logits, method=AGG_METHOD)\n",
        "    all_labels.append(label)\n",
        "    all_probs.append(prob.cpu().numpy())\n",
        "\n",
        "# -----------------------------\n",
        "# Tune threshold using PR curve\n",
        "all_probs_np = np.array(all_probs)\n",
        "true = np.array(all_labels)\n",
        "probs_fraud = all_probs_np[:, 1]\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(true, probs_fraud)\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(f\"\\n🏁 Best threshold by F1: {best_thresh:.4f}\")\n",
        "print(f\"📈 Precision: {prec[best_idx]:.3f} | Recall: {rec[best_idx]:.3f} | F1: {f1_scores[best_idx]:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Report at best threshold\n",
        "preds = (probs_fraud >= best_thresh).astype(int)\n",
        "\n",
        "print(\"\\n📊 Classification Report (Tuned Threshold):\")\n",
        "print(classification_report(true, preds, target_names=[\"non_fraud\", \"fraud\"]))\n",
        "\n",
        "print(\"📌 Confusion Matrix:\")\n",
        "print(confusion_matrix(true, preds))\n",
        "\n",
        "# -----------------------------\n",
        "# ROC-AUC\n",
        "roc_auc = roc_auc_score(true, probs_fraud)\n",
        "print(f\"🎯 ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "0aO1kU5Pdf1y",
        "outputId": "35431dff-92e7-4864-ca5e-8681c1606d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating...: 100%|██████████| 400/400 [00:44<00:00,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏁 Best threshold by F1: 0.6402\n",
            "📈 Precision: 0.848 | Recall: 0.670 | F1: 0.749\n",
            "\n",
            "📊 Classification Report (Tuned Threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   non_fraud       0.73      0.88      0.80       200\n",
            "       fraud       0.85      0.67      0.75       200\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.79      0.78      0.77       400\n",
            "weighted avg       0.79      0.78      0.77       400\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[176  24]\n",
            " [ 66 134]]\n",
            "🎯 ROC-AUC Score: 0.6810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6p-mhBOTjJvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ mdna_transfer_from_fake_news.py — Enhanced to Improve Non-Fraud Detection Too\n",
        "# - Fixes Trainer API change (num_items_in_batch kwarg)\n",
        "# - Replaces deprecated `tokenizer=` with `processing_class=tokenizer`\n",
        "# - Uses Focal Loss + balanced chunk sampler to lift fraud recall\n",
        "\n",
        "import os, json, torch, numpy as np, random, re\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback, DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# -----------------------------\n",
        "# ⚙️ Config\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 6\n",
        "MAX_CHUNKS_PER_DOC = 7\n",
        "MODEL_PATH = \"./deberta-small-fake-news\"\n",
        "SAVE_PATH = \"./deberta-mdna-transfer\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "UNFREEZE_LAST_K = 6  # keep your original behavior\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Reproducibility\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📚 Load and Clean Data\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw.get(\"data\") if isinstance(raw, dict) else raw\n",
        "\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\", \"Label\", \"true_label\"]\n",
        "CANDIDATE_TEXT_FIELDS = [\"text\", \"Text\", \"content\", \"document\"]\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "\n",
        "cleaned = []\n",
        "for rec in raw:\n",
        "    text = next((rec.get(f) for f in CANDIDATE_TEXT_FIELDS if rec.get(f)), None)\n",
        "    label_raw = next((rec.get(f) for f in CANDIDATE_LABEL_FIELDS if rec.get(f) is not None), None)\n",
        "    if not text:\n",
        "        continue\n",
        "    label_norm = str(label_raw).strip().lower().replace(\" \", \"_\") if label_raw is not None else \"non_fraud\"\n",
        "    label_str = \"fraud\" if label_norm in [\"fraud\", \"1\", \"true\", \"yes\"] else \"non_fraud\"\n",
        "    cleaned.append({\"text\": text.strip(), \"label\": LABEL_MAP[label_str]})\n",
        "\n",
        "texts = [r[\"text\"] for r in cleaned]\n",
        "labels = [r[\"label\"] for r in cleaned]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, stratify=labels, random_state=SEED\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# ✂️ Tokenize & Chunk Texts\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)\n",
        "\n",
        "def chunk_text(text, label):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        window = tokens[i:i + MAX_LEN]\n",
        "        if len(window) < MAX_LEN:\n",
        "            window = window + [tokenizer.pad_token_id] * (MAX_LEN - len(window))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in window]\n",
        "        chunks.append((window, mask, label))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "class ChunkedDataset(Dataset):\n",
        "    def __init__(self, texts, labels, cache_file):\n",
        "        if os.path.exists(cache_file):\n",
        "            self.samples = torch.load(cache_file)\n",
        "        else:\n",
        "            with ThreadPoolExecutor() as executor:\n",
        "                all_chunks = executor.map(lambda x: chunk_text(*x), zip(texts, labels))\n",
        "                self.samples = [item for sublist in all_chunks for item in sublist]\n",
        "            torch.save(self.samples, cache_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk, mask, label = self.samples[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(chunk, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "train_dataset = ChunkedDataset(train_texts, train_labels, \"train_chunks.pt\")\n",
        "val_dataset   = ChunkedDataset(val_texts,   val_labels,   \"val_chunks.pt\")\n",
        "\n",
        "# -----------------------------\n",
        "# 🧠 Load Model & Partially Unfreeze Last K Layers\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=2).to(DEVICE)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    m = re.search(r'encoder\\.layer\\.(\\d+)', name)\n",
        "    if m:\n",
        "        layer_idx = int(m.group(1))\n",
        "        if layer_idx < model.config.num_hidden_layers - UNFREEZE_LAST_K:\n",
        "            param.requires_grad = False\n",
        "\n",
        "# -----------------------------\n",
        "# 📊 Class Weights (TRAIN only)\n",
        "class_weights_np = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array([0, 1]),\n",
        "    y=np.array(train_labels)\n",
        ")\n",
        "class_weights = torch.tensor(class_weights_np, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "# -----------------------------\n",
        "# 🔥 Focal Loss + Weighted Trainer (improves minority recall)\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, weight=None, gamma=1.5, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.ce = torch.nn.CrossEntropyLoss(weight=weight, reduction='none')\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        ce = self.ce(logits, target)  # [B]\n",
        "        with torch.no_grad():\n",
        "            pt = torch.softmax(logits, dim=-1).gather(1, target.unsqueeze(1)).squeeze(1).clamp_min(1e-6)\n",
        "        focal = (1.0 - pt) ** self.gamma * ce\n",
        "        return focal.mean() if self.reduction == \"mean\" else focal.sum()\n",
        "\n",
        "class WeightedFocalTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, gamma=1.5, sampler=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "        self.focal = FocalLoss(weight=class_weights, gamma=gamma)\n",
        "        self._sampler = sampler\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # accept extra kwargs (e.g., num_items_in_batch) from newer HF Trainer\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        loss = self.focal(outputs.logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    # Use balanced sampling at the CHUNK level for training\n",
        "    def get_train_dataloader(self):\n",
        "        if self._sampler is None:\n",
        "            return super().get_train_dataloader()\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.args.train_batch_size,\n",
        "            sampler=self._sampler,\n",
        "            collate_fn=self.data_collator,\n",
        "            num_workers=self.args.dataloader_num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# 🧪 Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds),\n",
        "        \"recall\":    recall_score(labels, preds),\n",
        "        \"f1\":        f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# 🧮 Balanced CHUNK sampler (helps minority recall)\n",
        "y_train_chunks = np.array([lbl for _, _, lbl in train_dataset.samples])\n",
        "class_sample_counts = np.bincount(y_train_chunks, minlength=2).astype(np.float32)\n",
        "# inverse-frequency weights per class\n",
        "weights_per_class = class_sample_counts.sum() / (2.0 * np.clip(class_sample_counts, 1, None))\n",
        "sample_weights = weights_per_class[y_train_chunks]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights.tolist(),\n",
        "                                num_samples=len(sample_weights),\n",
        "                                replacement=True)\n",
        "\n",
        "# -----------------------------\n",
        "# ⚙️ Training Arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=SAVE_PATH,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    seed=SEED,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=2,\n",
        "    dataloader_num_workers=2,\n",
        "    max_grad_norm=1.0\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "# -----------------------------\n",
        "# 🏋️‍♀️ Train\n",
        "trainer = WeightedFocalTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,  # <-- replaces deprecated `tokenizer=`\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    class_weights=class_weights,\n",
        "    gamma=1.5,\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# -----------------------------\n",
        "# 💾 Save\n",
        "model.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "print(\"✅ Training complete and model saved at:\", os.path.abspath(SAVE_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "QnEBukyejJsh",
        "outputId": "f101d010-990a-4b85-c070-9a51896be67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='396' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [396/396 01:07, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.326583</td>\n",
              "      <td>0.365625</td>\n",
              "      <td>0.487179</td>\n",
              "      <td>0.094059</td>\n",
              "      <td>0.157676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.030600</td>\n",
              "      <td>0.272891</td>\n",
              "      <td>0.571875</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>0.559406</td>\n",
              "      <td>0.622590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.030600</td>\n",
              "      <td>0.353981</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.715596</td>\n",
              "      <td>0.772277</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.177600</td>\n",
              "      <td>0.436334</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.801980</td>\n",
              "      <td>0.792176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.087400</td>\n",
              "      <td>0.480107</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.766990</td>\n",
              "      <td>0.782178</td>\n",
              "      <td>0.774510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.087400</td>\n",
              "      <td>0.522352</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.764151</td>\n",
              "      <td>0.801980</td>\n",
              "      <td>0.782609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete and model saved at: /content/deberta-mdna-transfer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ evaluate_chunks.py — Val/Test split • Top-K aggregation • F1/F2 thresholding • Saved artifacts\n",
        "import os, json, re, torch, numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, precision_recall_curve,\n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "MAX_LEN = 512\n",
        "STRIDE = 128\n",
        "MAX_CHUNKS_PER_DOC = 10      # a little higher recall than 7\n",
        "AGG_METHOD = \"topk_mean\"     # \"mean_softmax\" | \"max_prob\" | \"topk_mean\"\n",
        "TOPK = 3                     # used if AGG_METHOD == \"topk_mean\"\n",
        "MODEL_DIR = \"./deberta-mdna-transfer\"\n",
        "OUT_DIR = \"./eval_artifacts\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# Load Data (+ normalize fields)\n",
        "with open(\"mdna_samples.json\") as f:\n",
        "    raw = json.load(f)\n",
        "    raw = raw[\"data\"] if isinstance(raw, dict) else raw\n",
        "\n",
        "CANDIDATE_LABEL_FIELDS = [\"label\", \"Label\", \"true_label\"]\n",
        "CANDIDATE_TEXT_FIELDS = [\"text\", \"Text\", \"content\", \"document\"]\n",
        "LABEL_MAP = {\"non_fraud\": 0, \"fraud\": 1}\n",
        "\n",
        "docs = []\n",
        "for i, rec in enumerate(raw):\n",
        "    text = next((rec.get(k) for k in CANDIDATE_TEXT_FIELDS if rec.get(k)), None)\n",
        "    if not text:\n",
        "        continue\n",
        "    lab_raw = next((rec.get(k) for k in CANDIDATE_LABEL_FIELDS if rec.get(k) is not None), \"non_fraud\")\n",
        "    lab_norm = str(lab_raw).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "    lab_str = \"fraud\" if lab_norm in [\"fraud\", \"1\", \"true\", \"yes\"] else \"non_fraud\"\n",
        "    docs.append({\"id\": i, \"text\": text.strip(), \"label\": LABEL_MAP[lab_str]})\n",
        "\n",
        "texts = [d[\"text\"] for d in docs]\n",
        "labels = [d[\"label\"] for d in docs]\n",
        "\n",
        "# -----------------------------\n",
        "# Val/Test split (NOTE: may overlap with training docs if you didn't persist IDs)\n",
        "X_tmp, X_test, y_tmp, y_test, id_tmp, id_test = train_test_split(\n",
        "    texts, labels, [d[\"id\"] for d in docs],\n",
        "    test_size=0.25, stratify=labels, random_state=SEED\n",
        ")\n",
        "X_val, X_hold, y_val, y_hold, id_val, id_hold = train_test_split(\n",
        "    X_tmp, y_tmp, id_tmp, test_size=0.3333, stratify=y_tmp, random_state=SEED\n",
        ")\n",
        "# Now: ~25% val (X_val), ~25% test (X_test). We ignore X_hold.\n",
        "\n",
        "# -----------------------------\n",
        "# Model & tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "def chunk_text(text):\n",
        "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
        "    chunks, i = [], 0\n",
        "    while i < len(tokens) and len(chunks) < MAX_CHUNKS_PER_DOC:\n",
        "        window = tokens[i:i + MAX_LEN]\n",
        "        if len(window) < MAX_LEN:\n",
        "            window = window + [tokenizer.pad_token_id] * (MAX_LEN - len(window))\n",
        "        mask = [1 if t != tokenizer.pad_token_id else 0 for t in window]\n",
        "        chunks.append((window, mask))\n",
        "        i += STRIDE\n",
        "    return chunks\n",
        "\n",
        "def aggregate(logits_list, method=AGG_METHOD, topk=TOPK):\n",
        "    L = torch.stack(logits_list)                   # [num_chunks, 2]\n",
        "    P = torch.softmax(L, dim=-1)                   # probs\n",
        "    if method == \"mean_softmax\":\n",
        "        return P.mean(dim=0)                       # [2]\n",
        "    if method == \"max_prob\":\n",
        "        idx = torch.argmax(P[:, 1])\n",
        "        return P[idx]                              # [2]\n",
        "    if method == \"topk_mean\":\n",
        "        k = min(topk, P.shape[0])\n",
        "        vals, _ = torch.topk(P[:, 1], k)\n",
        "        p1 = vals.mean()\n",
        "        return torch.tensor([1 - p1, p1], device=P.device)\n",
        "    raise ValueError(\"Unknown aggregation method\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_probs(texts):\n",
        "    probs = []\n",
        "    for t in tqdm(texts, desc=\"Infer\"):\n",
        "        logits_list = []\n",
        "        for chunk, mask in chunk_text(t):\n",
        "            inputs = {\n",
        "                \"input_ids\": torch.tensor([chunk], dtype=torch.long, device=DEVICE),\n",
        "                \"attention_mask\": torch.tensor([mask], dtype=torch.long, device=DEVICE),\n",
        "            }\n",
        "            out = model(**inputs).logits.squeeze(0)   # [2]\n",
        "            logits_list.append(out)\n",
        "        if len(logits_list) == 0:\n",
        "            # empty text edge-case: predict non-fraud lightly\n",
        "            probs.append(np.array([0.55, 0.45], dtype=np.float32))\n",
        "        else:\n",
        "            p = aggregate(logits_list)\n",
        "            probs.append(p.detach().cpu().numpy())\n",
        "    return np.vstack(probs)   # [N, 2]\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Inference on VAL (for threshold tuning)\n",
        "val_probs = infer_probs(X_val)             # [N_val, 2]\n",
        "val_true  = np.array(y_val, dtype=int)\n",
        "val_p1    = val_probs[:, 1]\n",
        "\n",
        "# F1 threshold\n",
        "prec, rec, thr = precision_recall_curve(val_true, val_p1)\n",
        "f1 = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
        "i1 = int(np.nanargmax(f1))\n",
        "t_f1 = float(thr[max(i1, 0)])\n",
        "print(f\"\\n🏁 Best F1 threshold: {t_f1:.4f} | P={prec[i1]:.3f} R={rec[i1]:.3f} F1={f1[i1]:.3f}\")\n",
        "\n",
        "# F2 threshold (recall-leaning)\n",
        "beta = 2.0\n",
        "f2 = (1 + beta**2) * (prec * rec) / (beta**2 * prec + rec + 1e-8)\n",
        "i2 = int(np.nanargmax(f2))\n",
        "t_f2 = float(thr[max(i2, 0)])\n",
        "print(f\"🏁 Best F2 threshold: {t_f2:.4f} | P={prec[i2]:.3f} R={rec[i2]:.3f} F2={f2[i2]:.3f}\")\n",
        "\n",
        "# Pick which threshold to use downstream:\n",
        "BEST_T = t_f2   # prefer higher recall; change to t_f1 if you prefer balance\n",
        "np.savez(os.path.join(OUT_DIR, \"val_thresholds.npz\"), t_f1=t_f1, t_f2=t_f2)\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Inference on TEST (report only)\n",
        "test_probs = infer_probs(X_test)\n",
        "test_true  = np.array(y_test, dtype=int)\n",
        "test_p1    = test_probs[:, 1]\n",
        "test_pred  = (test_p1 >= BEST_T).astype(int)\n",
        "\n",
        "print(\"\\n📊 Classification Report (TEST @ tuned threshold):\")\n",
        "print(classification_report(test_true, test_pred, target_names=[\"non_fraud\", \"fraud\"], digits=3))\n",
        "\n",
        "print(\"📌 Confusion Matrix (TEST):\")\n",
        "print(confusion_matrix(test_true, test_pred))\n",
        "\n",
        "roc = roc_auc_score(test_true, test_p1)\n",
        "pr_auc = average_precision_score(test_true, test_p1)  # PR-AUC (fraud=positive)\n",
        "print(f\"🎯 ROC-AUC (TEST): {roc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Save artifacts\n",
        "np.savez(\n",
        "    os.path.join(OUT_DIR, \"test_doc_level_probs.npz\"),\n",
        "    probs=test_probs, labels=test_true, ids=np.array(id_test)\n",
        ")\n",
        "\n",
        "# PR curve figure\n",
        "plt.figure()\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(f\"PR Curve (val) — method={AGG_METHOD}, topk={TOPK}\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, f\"pr_curve_val_{AGG_METHOD}_k{TOPK}.png\"), dpi=160)\n",
        "plt.close()\n",
        "\n",
        "# Calibration-ish histogram\n",
        "plt.figure()\n",
        "plt.hist(test_p1[test_true==1], bins=20, alpha=0.6, label=\"fraud\")\n",
        "plt.hist(test_p1[test_true==0], bins=20, alpha=0.6, label=\"non_fraud\")\n",
        "plt.xlabel(\"Predicted P(fraud)\"); plt.ylabel(\"Count\")\n",
        "plt.title(\"Score distribution (TEST)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"score_hist_test.png\"), dpi=160)\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\n🗂 Saved artifacts in: {os.path.abspath(OUT_DIR)}\")\n",
        "print(f\"   - val_thresholds.npz (t_f1, t_f2)\")\n",
        "print(f\"   - test_doc_level_probs.npz (probs, labels, ids)\")\n",
        "print(f\"   - pr_curve_val_{AGG_METHOD}_k{TOPK}.png\")\n",
        "print(f\"   - score_hist_test.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJ9RVSkldNr",
        "outputId": "4eecfa68-acf4-468d-8548-397c43242d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Infer: 100%|██████████| 200/200 [00:25<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏁 Best F1 threshold: 0.5376 | P=0.795 R=0.890 F1=0.840\n",
            "🏁 Best F2 threshold: 0.5376 | P=0.795 R=0.890 F2=0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Infer: 100%|██████████| 100/100 [00:13<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Classification Report (TEST @ tuned threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   non_fraud      0.905     0.760     0.826        50\n",
            "       fraud      0.793     0.920     0.852        50\n",
            "\n",
            "    accuracy                          0.840       100\n",
            "   macro avg      0.849     0.840     0.839       100\n",
            "weighted avg      0.849     0.840     0.839       100\n",
            "\n",
            "📌 Confusion Matrix (TEST):\n",
            "[[38 12]\n",
            " [ 4 46]]\n",
            "🎯 ROC-AUC (TEST): 0.7732 | PR-AUC: 0.7482\n",
            "\n",
            "🗂 Saved artifacts in: /content/eval_artifacts\n",
            "   - val_thresholds.npz (t_f1, t_f2)\n",
            "   - test_doc_level_probs.npz (probs, labels, ids)\n",
            "   - pr_curve_val_topk_mean_k3.png\n",
            "   - score_hist_test.png\n"
          ]
        }
      ]
    }
  ]
}